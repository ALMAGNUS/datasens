{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§± Table : type_donnee\n",
      "\n",
      "ðŸ§± Table : source\n",
      "\n",
      "ðŸ§± Table : flux\n",
      "\n",
      "ðŸ§± Table : document\n",
      "\n",
      "ðŸ“Š Vue d'ensemble de la chaÃ®ne de sourcing :\n",
      "ðŸ“¦ Snapshot crÃ©Ã© : datasens_v20251101_123610.db\n",
      "\n",
      "ðŸ“˜ Historique des versions DataSens :\n",
      "\n",
      "- **2025-10-30 18:54:51** | `DB_SCHEMA` | CrÃ©ation des 18 tables principales\n",
      "- **2025-10-30 18:54:56** | `DB_SCHEMA` | CrÃ©ation des 18 tables principales\n",
      "- **2025-10-30 18:55:22** | `DB_SCHEMA` | CrÃ©ation des 18 tables principales\n",
      "- **2025-10-30 18:55:46** | `DB_SCHEMA` | CrÃ©ation des 18 tables principales\n",
      "- **2025-10-30 18:56:12** | `DB_SCHEMA` | CrÃ©ation des 18 tables principales\n",
      "- **2025-10-30 18:56:42** | `DB_SEED` | Insertion du jeu de donnÃ©es minimal\n",
      "- **2025-10-30 18:56:47** | `DB_SEED` | Insertion du jeu de donnÃ©es minimal\n",
      "- **2025-10-30 18:57:08** | `DB_SEED` | Insertion du jeu de donnÃ©es minimal\n",
      "- **2025-10-30 18:57:29** | `DB_SEED` | Insertion du jeu de donnÃ©es minimal\n",
      "- **2025-10-30 18:57:50** | `DB_SEED` | Insertion du jeu de donnÃ©es minimal\n",
      "- **2025-10-30 18:59:47** | `DB_BACKUP` | datasens_v20251030_185947.db - AprÃ¨s validation de la chaÃ®ne Type-Source-Flux-Document\n",
      "- **2025-10-30 18:59:53** | `DB_BACKUP` | datasens_v20251030_185953.db - AprÃ¨s validation de la chaÃ®ne Type-Source-Flux-Document\n",
      "- **2025-10-30 19:00:15** | `DB_BACKUP` | datasens_v20251030_190015.db - AprÃ¨s validation de la chaÃ®ne Type-Source-Flux-Document\n",
      "- **2025-10-30 19:00:37** | `DB_BACKUP` | datasens_v20251030_190037.db - AprÃ¨s validation de la chaÃ®ne Type-Source-Flux-Document\n",
      "- **2025-10-30 19:00:58** | `DB_BACKUP` | datasens_v20251030_190058.db - AprÃ¨s validation de la chaÃ®ne Type-Source-Flux-Document\n",
      "- **2025-11-01 12:36:10** | `DB_BACKUP` | datasens_v20251101_123610.db - AprÃ¨s validation de la chaÃ®ne Type-Source-Flux-Document\n",
      "\n",
      "\n",
      "ðŸ DataSens E1 terminÃ© avec succÃ¨s !\n"
     ]
    }
   ],
   "source": [
    "# DataSens E1_v1 â€” 05_snapshot_and_readme\n",
    "# Objectifs: inspection tables, vue join, snapshot versionnÃ©, historique\n",
    "# PrÃ©requis: 04_crud_tests\n",
    "# Sorties: datasens/versions/ + MAJ README_VERSIONNING.md\n",
    "# RÃ©fÃ©rence: docs/GUIDE_TECHNIQUE_E1.md\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[2] if (Path.cwd().name.startswith('datasens_')) else Path.cwd()\n",
    "DB_PATH = PROJECT_ROOT / \"datasens\" / \"datasens.db\"\n",
    "VERSION_FILE = PROJECT_ROOT / \"README_VERSIONNING.md\"\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Helpers\n",
    "\n",
    "def sql_df(query, params=None):\n",
    "    return pd.read_sql_query(query, conn, params=params)\n",
    "\n",
    "# Inspection tables clÃ©s\n",
    "for t in [\"type_donnee\", \"source\", \"flux\", \"document\"]:\n",
    "    print(f\"\\nðŸ§± Table : {t}\")\n",
    "    try:\n",
    "        display(sql_df(f\"SELECT * FROM {t} LIMIT 10;\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Vue chainÃ©e\n",
    "query_sources = \"\"\"\n",
    "SELECT\n",
    "    td.libelle          AS type_donnee,\n",
    "    s.nom               AS source_nom,\n",
    "    ROUND(s.fiabilite,2) AS source_fiabilite,\n",
    "    f.format            AS flux_format,\n",
    "    f.date_collecte     AS flux_date,\n",
    "    f.manifest_uri      AS flux_manifest,\n",
    "    d.titre             AS doc_titre,\n",
    "    d.date_publication  AS doc_date\n",
    "FROM type_donnee td\n",
    "LEFT JOIN source   s ON s.id_type_donnee = td.id_type_donnee\n",
    "LEFT JOIN flux     f ON f.id_source      = s.id_source\n",
    "LEFT JOIN document d ON d.id_flux        = f.id_flux\n",
    "ORDER BY td.libelle, s.nom, f.date_collecte, d.date_publication;\n",
    "\"\"\"\n",
    "print(\"\\nðŸ“Š Vue d'ensemble de la chaÃ®ne de sourcing :\")\n",
    "try:\n",
    "    display(sql_df(query_sources))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Snapshot versionnÃ©\n",
    "BACKUP_DIR = PROJECT_ROOT / \"datasens\" / \"versions\"\n",
    "BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_database_version(note=\"Validation\"):\n",
    "    import shutil\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_name = f\"datasens_v{timestamp}.db\"\n",
    "    backup_path = BACKUP_DIR / backup_name\n",
    "    shutil.copy(DB_PATH, backup_path)\n",
    "    with open(VERSION_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"- **{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}** | `DB_BACKUP` | {backup_name} - {note}\\n\")\n",
    "    print(f\"ðŸ“¦ Snapshot crÃ©Ã© : {backup_name}\")\n",
    "\n",
    "save_database_version(\"AprÃ¨s validation de la chaÃ®ne Type-Source-Flux-Document\")\n",
    "\n",
    "# Historique\n",
    "print(\"\\nðŸ“˜ Historique des versions DataSens :\\n\")\n",
    "try:\n",
    "    with open(VERSION_FILE, encoding=\"utf-8\") as f:\n",
    "        print(f.read())\n",
    "except UnicodeDecodeError:\n",
    "    with open(VERSION_FILE, encoding=\"cp1252\") as f:\n",
    "        print(f.read())\n",
    "\n",
    "print(\"\\nðŸ DataSens E1 terminÃ© avec succÃ¨s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes:\n",
    "> - AperÃ§u des tables clÃ©s (`type_donnee`, `source`, `flux`, `document`).\n",
    "> - La vue joinÃ©e illustre la traÃ§abilitÃ©: Type â†’ Source â†’ Flux â†’ Document.\n",
    "> - `save_database_version` crÃ©e un snapshot horodatÃ© de la base.\n",
    "> - Affichage de lâ€™historique complet pour audit.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
