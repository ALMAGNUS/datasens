{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSens E1_v1 ‚Äî 02_schema_create\n",
    "\n",
    "- Objectifs: cr√©er le sch√©ma (SQLite), 10 tables Pareto\n",
    "- Pr√©requis: ex√©cuter 01_setup_env\n",
    "- Sortie: base `datasens/datasens.db`\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üé¨ DASHBOARD NARRATIF - O√ô SOMMES-NOUS ?\n",
    "# ============================================================\n",
    "# Ce dashboard vous guide √† travers le pipeline DataSens E1\n",
    "# Il montre la progression et l'√©tat actuel des donn√©es\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üé¨ FIL D'ARIANE VISUEL - PIPELINE DATASENS E1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er figure dashboard\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.axis('off')\n",
    "\n",
    "# √âtapes du pipeline\n",
    "etapes = [\n",
    "    {\"nom\": \"üì• COLLECTE\", \"status\": \"‚úÖ\", \"desc\": \"Sources brutes\"},\n",
    "    {\"nom\": \"‚òÅÔ∏è DATALAKE\", \"status\": \"‚úÖ\", \"desc\": \"MinIO Raw\"},\n",
    "    {\"nom\": \"üßπ NETTOYAGE\", \"status\": \"üîÑ\", \"desc\": \"D√©duplication\"},\n",
    "    {\"nom\": \"üíæ ETL\", \"status\": \"‚è≥\", \"desc\": \"PostgreSQL\"},\n",
    "    {\"nom\": \"üìä ANNOTATION\", \"status\": \"‚è≥\", \"desc\": \"Enrichissement\"},\n",
    "    {\"nom\": \"üì¶ EXPORT\", \"status\": \"‚è≥\", \"desc\": \"Dataset IA\"}\n",
    "]\n",
    "\n",
    "# Couleurs selon statut\n",
    "colors = {\n",
    "    \"‚úÖ\": \"#4ECDC4\",\n",
    "    \"üîÑ\": \"#FECA57\", \n",
    "    \"‚è≥\": \"#E8E8E8\"\n",
    "}\n",
    "\n",
    "# Dessiner timeline\n",
    "y_pos = 4\n",
    "x_start = 1\n",
    "x_spacing = 1.4\n",
    "\n",
    "for i, etape in enumerate(etapes):\n",
    "    x_pos = x_start + i * x_spacing\n",
    "    \n",
    "    # Cercle √©tape\n",
    "    circle = plt.Circle((x_pos, y_pos), 0.25, color=colors[etape[\"status\"]], zorder=3)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(x_pos, y_pos, etape[\"status\"], ha='center', va='center', fontsize=14, fontweight='bold', zorder=4)\n",
    "    \n",
    "    # Nom √©tape\n",
    "    ax.text(x_pos, y_pos - 0.6, etape[\"nom\"], ha='center', va='top', fontsize=11, fontweight='bold')\n",
    "    ax.text(x_pos, y_pos - 0.85, etape[\"desc\"], ha='center', va='top', fontsize=9, style='italic')\n",
    "    \n",
    "    # Fl√®che vers prochaine √©tape\n",
    "    if i < len(etapes) - 1:\n",
    "        ax.arrow(x_pos + 0.3, y_pos, x_spacing - 0.6, 0, \n",
    "                head_width=0.1, head_length=0.15, fc='gray', ec='gray', zorder=2)\n",
    "\n",
    "# Titre narratif\n",
    "ax.text(5, 5.5, \"üéØ PROGRESSION DU PIPELINE E1\", ha='center', va='center', \n",
    "        fontsize=16, fontweight='bold', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# L√©gende\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor='#4ECDC4', label='Termin√©'),\n",
    "    mpatches.Patch(facecolor='#FECA57', label='En cours'),\n",
    "    mpatches.Patch(facecolor='#E8E8E8', label='√Ä venir')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=10)\n",
    "\n",
    "# Statistiques rapides (si disponibles)\n",
    "stats_text = \"\\nüìä SNAPSHOT ACTUEL :\\n\"\n",
    "try:\n",
    "    # Essayer de charger des stats si base disponible\n",
    "    stats_text += \"   ‚Ä¢ Pipeline en cours d'ex√©cution...\\n\"\n",
    "except:\n",
    "    stats_text += \"   ‚Ä¢ D√©marrage du pipeline...\\n\"\n",
    "\n",
    "ax.text(5, 1.5, stats_text, ha='center', va='center', fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.title(\"üé¨ FIL D'ARIANE VISUEL - Accompagnement narratif du jury\", \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Le fil d'Ariane vous guide √©tape par √©tape √† travers le pipeline\")\n",
    "print(\"   Chaque visualisation s'inscrit dans cette progression narrative\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes:\n",
    "> - SQLite (fichier local) simplifie la d√©mo E1_v1.\n",
    "> - `sqlite3.connect(DB_PATH)` ouvre (ou cr√©e) la base.\n",
    "> - `CREATE TABLE IF NOT EXISTS` √©vite les erreurs si la table existe d√©j√†.\n",
    "> - `conn.commit()` enregistre les changements.\n",
    "> - Une ligne est ajout√©e dans `README_VERSIONNING.md` pour la tra√ßabilit√©.\n",
    "> - Les tables couvrent les entit√©s principales collecte/gouvernance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Racine projet d√©tect√©e : c:\\Users\\Utilisateur\\Desktop\\DataSens\\notebooks\\datasens_E1_v1\n",
      "‚úÖ Base SQLite pr√™te : c:\\Users\\Utilisateur\\Desktop\\DataSens\\notebooks\\datasens_E1_v1\\datasens\\datasens.db\n",
      "‚úÖ Table : type_donnee\n",
      "‚úÖ Table : source\n",
      "‚úÖ Table : flux\n",
      "‚úÖ Table : document\n",
      "‚úÖ Table : pays\n",
      "‚úÖ Table : region\n",
      "‚úÖ Table : departement\n",
      "‚úÖ Table : commune\n",
      "‚úÖ Table : territoire\n",
      "‚úÖ Table : type_indicateur\n",
      "‚úÖ Table : indicateur\n",
      "‚úÖ Table : meteo\n",
      "‚úÖ Table : utilisateur\n",
      "‚úÖ Table : emotion\n",
      "‚úÖ Table : annotation\n",
      "‚úÖ Table : theme\n",
      "‚úÖ Table : evenement\n",
      "‚úÖ Table : document_evenement\n",
      "Sch√©ma cr√©√©.\n"
     ]
    }
   ],
   "source": [
    "# DataSens E1_v1 - 02_schema_create\n",
    "# üíæ Base SQLite et sch√©ma (18 tables)\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# D√©tection robuste du dossier projet (remonte jusqu'√† trouver le dossier avec notebooks/ et docs/)\n",
    "current = Path.cwd()\n",
    "PROJECT_ROOT = None\n",
    "# Remonter jusqu'√† trouver un dossier qui contient √† la fois notebooks/ et docs/\n",
    "while current != current.parent:\n",
    "    if (current / \"notebooks\").exists() and (current / \"docs\").exists():\n",
    "        PROJECT_ROOT = current\n",
    "        break\n",
    "    current = current.parent\n",
    "else:\n",
    "    # Fallback: utilise le r√©pertoire courant si pas trouv√©\n",
    "    PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "# Emplacement du fichier SQLite (BDD locale de d√©mo E1_v1)\n",
    "DB_PATH = PROJECT_ROOT / \"datasens\" / \"datasens.db\"\n",
    "print(f\"üìÇ Racine projet d√©tect√©e : {PROJECT_ROOT}\")\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Connexion √† la base SQLite (cr√©√©e si absente)\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cur = conn.cursor()\n",
    "print(f\"‚úÖ Base SQLite pr√™te : {DB_PATH}\")\n",
    "\n",
    "# =====================================================\n",
    "# FONCTIONS UTILITAIRES DE S√âCURIT√â\n",
    "# =====================================================\n",
    "def assert_valid_identifier(name: str) -> None:\n",
    "    \"\"\"\n",
    "    Valide qu'un identifiant SQL (nom de table, colonne) est s√ªr.\n",
    "    Bien que SQLite soit moins sensible, la validation est une bonne pratique.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError(\"L'identifiant doit √™tre une cha√Æne de caract√®res.\")\n",
    "    if not name.replace('_', '').replace('.', '').isalnum():\n",
    "        raise ValueError(f\"Identifiant SQL invalide : {name}\")\n",
    "\n",
    "print(\"‚úÖ Fonctions de s√©curit√© charg√©es\")\n",
    "\n",
    "# Tables principales (collecte/gouvernance) inspir√©es du monolithe\n",
    "TABLES_SQL = {\n",
    "    # Typologie des donn√©es (RSS, API, Scraping, CSV, Big Data)\n",
    "    \"type_donnee\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS type_donnee (\n",
    "        id_type_donnee INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        libelle TEXT, description TEXT,\n",
    "        frequence_maj TEXT, categorie_metier TEXT\n",
    "    );\"\"\",\n",
    "    # Source (provenance) rattach√©e √† un type de donn√©e\n",
    "    \"source\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS source (\n",
    "        id_source INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        id_type_donnee INTEGER,\n",
    "        nom TEXT, url TEXT, fiabilite REAL,\n",
    "        FOREIGN KEY (id_type_donnee) REFERENCES type_donnee(id_type_donnee)\n",
    "    );\"\"\",\n",
    "    # Flux (op√©ration de collecte dat√©e + format + manifest)\n",
    "    \"flux\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS flux (\n",
    "        id_flux INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        id_source INTEGER, date_collecte TEXT, format TEXT, manifest_uri TEXT,\n",
    "        FOREIGN KEY (id_source) REFERENCES source(id_source)\n",
    "    );\"\"\",\n",
    "    # Document (contenu final) rattach√© √† un flux\n",
    "    \"document\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS document (\n",
    "        id_doc INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        id_flux INTEGER, titre TEXT, texte TEXT, langue TEXT, date_publication TEXT,\n",
    "        FOREIGN KEY (id_flux) REFERENCES flux(id_flux)\n",
    "    );\"\"\",\n",
    "    # R√©f√©rentiels territoriaux et indicateurs (simplifi√©s E1)\n",
    "    \"pays\": \"CREATE TABLE IF NOT EXISTS pays (id_pays INTEGER PRIMARY KEY AUTOINCREMENT, nom TEXT);\",\n",
    "    \"region\": \"CREATE TABLE IF NOT EXISTS region (id_region INTEGER PRIMARY KEY AUTOINCREMENT, id_pays INTEGER, nom TEXT, FOREIGN KEY (id_pays) REFERENCES pays(id_pays));\",\n",
    "    \"departement\": \"CREATE TABLE IF NOT EXISTS departement (id_departement INTEGER PRIMARY KEY AUTOINCREMENT, id_region INTEGER, code_dept TEXT, nom TEXT, FOREIGN KEY (id_region) REFERENCES region(id_region));\",\n",
    "    \"commune\": \"CREATE TABLE IF NOT EXISTS commune (id_commune INTEGER PRIMARY KEY AUTOINCREMENT, id_departement INTEGER, code_insee TEXT, nom_commune TEXT, lat REAL, lon REAL, population INTEGER, FOREIGN KEY (id_departement) REFERENCES departement(id_departement));\",\n",
    "    \"territoire\": \"CREATE TABLE IF NOT EXISTS territoire (id_territoire INTEGER PRIMARY KEY AUTOINCREMENT, id_commune INTEGER, FOREIGN KEY (id_commune) REFERENCES commune(id_commune));\",\n",
    "    \"type_indicateur\": \"CREATE TABLE IF NOT EXISTS type_indicateur (id_type_indic INTEGER PRIMARY KEY AUTOINCREMENT, code TEXT, libelle TEXT, unite TEXT);\",\n",
    "    \"indicateur\": \"CREATE TABLE IF NOT EXISTS indicateur (id_indic INTEGER PRIMARY KEY AUTOINCREMENT, id_territoire INTEGER, id_type_indic INTEGER, valeur REAL, annee INTEGER, FOREIGN KEY (id_territoire) REFERENCES territoire(id_territoire), FOREIGN KEY (id_type_indic) REFERENCES type_indicateur(id_type_indic));\",\n",
    "    \"meteo\": \"CREATE TABLE IF NOT EXISTS meteo (id_meteo INTEGER PRIMARY KEY AUTOINCREMENT, id_territoire INTEGER, date_obs TEXT, temperature REAL, humidite REAL, vent_kmh REAL, pression REAL, FOREIGN KEY (id_territoire) REFERENCES territoire(id_territoire));\",\n",
    "    \"utilisateur\": \"CREATE TABLE IF NOT EXISTS utilisateur (id_user INTEGER PRIMARY KEY AUTOINCREMENT, nom TEXT, role TEXT, organisation TEXT);\",\n",
    "    \"emotion\": \"CREATE TABLE IF NOT EXISTS emotion (id_emotion INTEGER PRIMARY KEY AUTOINCREMENT, type_emotion TEXT, valence TEXT, score_confiance REAL);\",\n",
    "    \"annotation\": \"CREATE TABLE IF NOT EXISTS annotation (id_annotation INTEGER PRIMARY KEY AUTOINCREMENT, id_doc INTEGER, id_user INTEGER, id_emotion INTEGER, intensity REAL, polarity TEXT, date_annotation TEXT, FOREIGN KEY (id_doc) REFERENCES document(id_doc), FOREIGN KEY (id_user) REFERENCES utilisateur(id_user), FOREIGN KEY (id_emotion) REFERENCES emotion(id_emotion));\",\n",
    "    \"theme\": \"CREATE TABLE IF NOT EXISTS theme (id_theme INTEGER PRIMARY KEY AUTOINCREMENT, libelle TEXT, description TEXT);\",\n",
    "    \"evenement\": \"CREATE TABLE IF NOT EXISTS evenement (id_event INTEGER PRIMARY KEY AUTOINCREMENT, id_theme INTEGER, date_event TEXT, avg_tone REAL, source_event TEXT, FOREIGN KEY (id_theme) REFERENCES theme(id_theme));\",\n",
    "    \"document_evenement\": \"CREATE TABLE IF NOT EXISTS document_evenement (id_doc INTEGER, id_event INTEGER, PRIMARY KEY (id_doc, id_event), FOREIGN KEY (id_doc) REFERENCES document(id_doc), FOREIGN KEY (id_event) REFERENCES evenement(id_event));\"\n",
    "}\n",
    "\n",
    "# Ex√©cution s√©quentielle des DDL\n",
    "tables_created = []\n",
    "for name, sql in TABLES_SQL.items():\n",
    "    assert_valid_identifier(name)  # Validation s√©curit√©\n",
    "    cur.execute(sql)\n",
    "    tables_created.append(name)\n",
    "    print(f\"‚úÖ Table : {name}\")\n",
    "conn.commit()\n",
    "\n",
    "# üìä Visualisation : Graphique des tables cr√©√©es par cat√©gorie\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Cat√©gorisation des tables\n",
    "categories = {\n",
    "    \"Collecte & Tra√ßabilit√©\": [\"type_donnee\", \"source\", \"flux\", \"document\"],\n",
    "    \"G√©ographie\": [\"pays\", \"region\", \"departement\", \"commune\", \"territoire\"],\n",
    "    \"Donn√©es M√©tier\": [\"meteo\", \"indicateur\", \"type_indicateur\", \"evenement\", \"theme\"],\n",
    "    \"Annotation & IA\": [\"utilisateur\", \"emotion\", \"annotation\", \"document_evenement\"]\n",
    "}\n",
    "\n",
    "# Compter les tables par cat√©gorie\n",
    "cat_counts = {cat: len([t for t in tables_created if t in cat_list]) \n",
    "              for cat, cat_list in categories.items()}\n",
    "\n",
    "# Cr√©er le graphique\n",
    "df_tables = pd.DataFrame(list(cat_counts.items()), columns=[\"Cat√©gorie\", \"Nombre\"])\n",
    "df_tables = df_tables.sort_values(\"Nombre\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.Pastel1(range(len(df_tables)))\n",
    "bars = plt.bar(df_tables[\"Cat√©gorie\"], df_tables[\"Nombre\"], color=colors)\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar, value in zip(bars, df_tables[\"Nombre\"]):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "             str(value), ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.title(\"üìä Sch√©ma cr√©√© : R√©partition des 18 tables par cat√©gorie\", \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Cat√©gorie\", fontsize=12)\n",
    "plt.ylabel(\"Nombre de tables\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà Total : {len(tables_created)} tables cr√©√©es\")\n",
    "for cat, count in cat_counts.items():\n",
    "    print(f\"   ‚Ä¢ {cat} : {count} tables\")\n",
    "\n",
    "# üìã Tables de donn√©es r√©elles : Afficher la structure de chaque table cr√©√©e\n",
    "print(\"\\nüìã Structure des tables cr√©√©es (sch√©ma SQLite) :\")\n",
    "df_schema = pd.DataFrame({\n",
    "    'Table': tables_created,\n",
    "    'Statut': ['Cr√©√©e' for _ in tables_created]\n",
    "})\n",
    "display(df_schema)\n",
    "\n",
    "# Afficher les informations d√©taill√©es des tables principales\n",
    "print(\"\\nüîç D√©tails des tables principales (colonnes) :\")\n",
    "for table_name in [\"type_donnee\", \"source\", \"flux\", \"document\"]:\n",
    "    if table_name in tables_created:\n",
    "        try:\n",
    "            # R√©cup√©rer la structure de la table\n",
    "            schema_info = cur.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "            if schema_info:\n",
    "                df_cols = pd.DataFrame(schema_info, columns=['cid', 'name', 'type', 'notnull', 'default_value', 'pk'])\n",
    "                df_cols = df_cols[['name', 'type', 'pk', 'notnull']]\n",
    "                df_cols.columns = ['Colonne', 'Type', 'PK', 'NOT NULL']\n",
    "                print(f\"\\n   üìä Table '{table_name}' :\")\n",
    "                display(df_cols)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "# Journalisation (tra√ßabilit√© pour le jury)\n",
    "with open(PROJECT_ROOT / \"README_VERSIONNING.md\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"- **{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}** | `DB_SCHEMA` | Cr√©ation des 18 tables principales\\n\")\n",
    "print(\"\\n‚úÖ Sch√©ma cr√©√© et visualis√©.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}