{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSens logging setup (marker:datasens_logging)\n",
    "import logging, os\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('logs/datasens.log', encoding='utf-8')\n",
    "    ]\n",
    ")\n",
    "logging.info('D√©marrage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSens E1_v2 ‚Äî 01_setup_env\n",
    "\n",
    "- Objectifs: configuration environnement, connexions MinIO + PostgreSQL, arborescence, logging\n",
    "- Pr√©requis: Docker Compose lanc√© (MinIO + PostgreSQL), Python + venv, `pip install -r requirements.txt`\n",
    "- Ordre global E1_v2: 01 ‚Üí 02 ‚Üí 03 ‚Üí 04 ‚Üí 05\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md\n",
    "\n",
    "> **E1_v2** : Collecte r√©elle avec sources r√©duites mais fonctionnelles (18 tables PostgreSQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üé¨ DASHBOARD NARRATIF - O√ô SOMMES-NOUS ?\n",
    "# ============================================================\n",
    "# Ce dashboard vous guide √† travers le pipeline DataSens E1\n",
    "# Il montre la progression et l'√©tat actuel des donn√©es\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üé¨ FIL D'ARIANE VISUEL - PIPELINE DATASENS E1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er figure dashboard\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.axis('off')\n",
    "\n",
    "# √âtapes du pipeline\n",
    "etapes = [\n",
    "    {\"nom\": \"üì• COLLECTE\", \"status\": \"‚úÖ\", \"desc\": \"Sources brutes\"},\n",
    "    {\"nom\": \"‚òÅÔ∏è DATALAKE\", \"status\": \"‚úÖ\", \"desc\": \"MinIO Raw\"},\n",
    "    {\"nom\": \"üßπ NETTOYAGE\", \"status\": \"üîÑ\", \"desc\": \"D√©duplication\"},\n",
    "    {\"nom\": \"üíæ ETL\", \"status\": \"‚è≥\", \"desc\": \"PostgreSQL\"},\n",
    "    {\"nom\": \"üìä ANNOTATION\", \"status\": \"‚è≥\", \"desc\": \"Enrichissement\"},\n",
    "    {\"nom\": \"üì¶ EXPORT\", \"status\": \"‚è≥\", \"desc\": \"Dataset IA\"}\n",
    "]\n",
    "\n",
    "# Couleurs selon statut\n",
    "colors = {\n",
    "    \"‚úÖ\": \"#4ECDC4\",\n",
    "    \"üîÑ\": \"#FECA57\", \n",
    "    \"‚è≥\": \"#E8E8E8\"\n",
    "}\n",
    "\n",
    "# Dessiner timeline\n",
    "y_pos = 4\n",
    "x_start = 1\n",
    "x_spacing = 1.4\n",
    "\n",
    "for i, etape in enumerate(etapes):\n",
    "    x_pos = x_start + i * x_spacing\n",
    "    \n",
    "    # Cercle √©tape\n",
    "    circle = plt.Circle((x_pos, y_pos), 0.25, color=colors[etape[\"status\"]], zorder=3)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(x_pos, y_pos, etape[\"status\"], ha='center', va='center', fontsize=14, fontweight='bold', zorder=4)\n",
    "    \n",
    "    # Nom √©tape\n",
    "    ax.text(x_pos, y_pos - 0.6, etape[\"nom\"], ha='center', va='top', fontsize=11, fontweight='bold')\n",
    "    ax.text(x_pos, y_pos - 0.85, etape[\"desc\"], ha='center', va='top', fontsize=9, style='italic')\n",
    "    \n",
    "    # Fl√®che vers prochaine √©tape\n",
    "    if i < len(etapes) - 1:\n",
    "        ax.arrow(x_pos + 0.3, y_pos, x_spacing - 0.6, 0, \n",
    "                head_width=0.1, head_length=0.15, fc='gray', ec='gray', zorder=2)\n",
    "\n",
    "# Titre narratif\n",
    "ax.text(5, 5.5, \"üéØ PROGRESSION DU PIPELINE E1\", ha='center', va='center', \n",
    "        fontsize=16, fontweight='bold', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# L√©gende\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor='#4ECDC4', label='Termin√©'),\n",
    "    mpatches.Patch(facecolor='#FECA57', label='En cours'),\n",
    "    mpatches.Patch(facecolor='#E8E8E8', label='√Ä venir')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=10)\n",
    "\n",
    "# Statistiques rapides (si disponibles)\n",
    "stats_text = \"\\nüìä SNAPSHOT ACTUEL :\\n\"\n",
    "try:\n",
    "    # Essayer de charger des stats si base disponible\n",
    "    stats_text += \"   ‚Ä¢ Pipeline en cours d'ex√©cution...\\n\"\n",
    "except:\n",
    "    stats_text += \"   ‚Ä¢ D√©marrage du pipeline...\\n\"\n",
    "\n",
    "ax.text(5, 1.5, stats_text, ha='center', va='center', fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.title(\"üé¨ FIL D'ARIANE VISUEL - Accompagnement narratif du jury\", \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Le fil d'Ariane vous guide √©tape par √©tape √† travers le pipeline\")\n",
    "print(\"   Chaque visualisation s'inscrit dans cette progression narrative\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes:\n",
    "> - Configuration des connexions **MinIO (DataLake)** et **PostgreSQL (SGBD)**\n",
    "> - Cr√©ation de l'arborescence `data/raw/` avec sous-dossiers par type de source\n",
    "> - Syst√®me de logging pour tracer toutes les op√©rations\n",
    "> - Fonctions utilitaires (timestamp UTC, hash SHA256 pour d√©duplication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:51:48] INFO - Syst√®me de logging initialis√©\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Racine projet d√©tect√©e : c:\\Users\\Utilisateur\\Desktop\\DataSens\n",
      "‚úÖ .env charg√©: c:\\Users\\Utilisateur\\Desktop\\DataSens\\.env\n",
      "\n",
      "üîê Configuration MinIO (DataLake) :\n",
      "   ‚Ä¢ Endpoint : http://localhost:9000\n",
      "   ‚Ä¢ Bucket   : datasens-raw\n",
      "\n",
      "üóÑÔ∏è Configuration PostgreSQL (SGBD) :\n",
      "   ‚Ä¢ Host     : localhost:5432\n",
      "   ‚Ä¢ Database : datasens\n",
      "   ‚Ä¢ User     : ds_user\n",
      "\n",
      "üîë Cl√©s API :\n",
      "   ‚Ä¢ Kaggle        : ‚úÖ Configur√©e\n",
      "   ‚Ä¢ OpenWeatherMap: ‚úÖ Configur√©e\n",
      "   ‚Ä¢ NewsAPI       : ‚úÖ Configur√©e\n",
      "\n",
      "‚úÖ Arborescence cr√©√©e: c:\\Users\\Utilisateur\\Desktop\\DataSens\\data\\raw\n",
      "   ‚Ä¢ 9 sous-dossiers pr√™ts\n",
      "üìÑ Log: c:\\Users\\Utilisateur\\Desktop\\DataSens\\logs\\collecte_20251101_125148.log\n",
      "\n",
      "üîß Utilitaires : ts()=20251101T125148Z, sha256()=9f86d081884c7d65...\n",
      "\n",
      "‚úÖ Configuration termin√©e !\n"
     ]
    }
   ],
   "source": [
    "# DataSens E1_v2 - 01_setup_env\n",
    "# üîß Configuration environnement : MinIO + PostgreSQL + Arborescence + Logging\n",
    "\n",
    "import datetime as dt\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "from datetime import UTC, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# D√©tection robuste du dossier projet\n",
    "current = Path.cwd()\n",
    "PROJECT_ROOT = None\n",
    "while current != current.parent:\n",
    "    if (current / \"notebooks\").exists() and (current / \"docs\").exists():\n",
    "        PROJECT_ROOT = current\n",
    "        break\n",
    "    current = current.parent\n",
    "else:\n",
    "    PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "print(f\"üìÇ Racine projet d√©tect√©e : {PROJECT_ROOT}\")\n",
    "\n",
    "# Chargement .env\n",
    "env_path = PROJECT_ROOT / '.env'\n",
    "loaded = load_dotenv(env_path)\n",
    "if loaded:\n",
    "    print(f'‚úÖ .env charg√©: {env_path}')\n",
    "else:\n",
    "    print(f'‚ö†Ô∏è .env non trouv√©: {env_path}')\n",
    "\n",
    "# Configuration MinIO (DataLake)\n",
    "MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"http://localhost:9002\")\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", \"admin\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", \"admin123\")\n",
    "MINIO_BUCKET = os.getenv(\"MINIO_BUCKET\", \"datasens-raw\")\n",
    "\n",
    "# Configuration PostgreSQL (SGBD)\n",
    "PG_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.getenv(\"POSTGRES_PORT\", \"5433\"))\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\", \"postgres\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\", \"postgres\")\n",
    "PG_PASS = os.getenv(\"POSTGRES_PASS\", \"postgres\")\n",
    "PG_URL = f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "\n",
    "# Cl√©s API (optionnelles)\n",
    "KAGGLE_USERNAME = os.getenv(\"KAGGLE_USERNAME\")\n",
    "KAGGLE_KEY = os.getenv(\"KAGGLE_KEY\")\n",
    "OWM_API_KEY = os.getenv(\"OWM_API_KEY\")\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "GDELT_BASE = os.getenv(\"GDELT_BASE\", \"http://data.gdeltproject.org/gkg/\")\n",
    "\n",
    "print(\"\\nüîê Configuration MinIO (DataLake) :\")\n",
    "print(f\"   ‚Ä¢ Endpoint : {MINIO_ENDPOINT}\")\n",
    "print(f\"   ‚Ä¢ Bucket   : {MINIO_BUCKET}\")\n",
    "\n",
    "print(\"\\nüóÑÔ∏è Configuration PostgreSQL (SGBD) :\")\n",
    "print(f\"   ‚Ä¢ Host     : {PG_HOST}:{PG_PORT}\")\n",
    "print(f\"   ‚Ä¢ Database : {PG_DB}\")\n",
    "print(f\"   ‚Ä¢ User     : {PG_USER}\")\n",
    "\n",
    "print(\"\\nüîë Cl√©s API :\")\n",
    "print(f\"   ‚Ä¢ Kaggle        : {'‚úÖ Configur√©e' if KAGGLE_USERNAME else '‚ùå Manquante'}\")\n",
    "print(f\"   ‚Ä¢ OpenWeatherMap: {'‚úÖ Configur√©e' if OWM_API_KEY else '‚ùå Manquante'}\")\n",
    "print(f\"   ‚Ä¢ NewsAPI       : {'‚úÖ Configur√©e' if NEWSAPI_KEY else '‚ùå Manquante'}\")\n",
    "\n",
    "# Arborescence\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "LOGS_DIR = PROJECT_ROOT / 'logs'\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "folders = [\"kaggle\", \"api/owm\", \"api/newsapi\", \"rss\", \"scraping/multi\", \n",
    "           \"scraping/viepublique\", \"scraping/datagouv\", \"gdelt\", \"manifests\"]\n",
    "for sub in folders:\n",
    "    (RAW_DIR / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Arborescence cr√©√©e: {RAW_DIR}\")\n",
    "print(f\"   ‚Ä¢ {len(folders)} sous-dossiers pr√™ts\")\n",
    "\n",
    "# Logging\n",
    "stamp = datetime.now(UTC).strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = LOGS_DIR / f\"collecte_{stamp}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logging.info(\"Syst√®me de logging initialis√©\")\n",
    "print(f\"üìÑ Log: {log_file}\")\n",
    "\n",
    "# Fonctions utilitaires\n",
    "def ts() -> str:\n",
    "    \"\"\"Timestamp UTC ISO compact (YYYYMMDDTHHMMSSZ)\"\"\"\n",
    "    return dt.datetime.now(tz=dt.UTC).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "def sha256_hash(s: str) -> str:\n",
    "    \"\"\"Hash SHA256 pour d√©duplication\"\"\"\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "print(f\"\\nüîß Utilitaires : ts()={ts()}, sha256()={sha256_hash('test')[:16]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration termin√©e !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Test des connexions...\n",
      "================================================================================\n",
      "‚úÖ MinIO : Bucket 'datasens-raw' existe d√©j√†\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ MinIO : Bucket \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMINIO_BUCKET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m existe d√©j√†\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Lister les objets existants\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(minio_client\u001b[38;5;241m.\u001b[39mlist_objects(MINIO_BUCKET, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ‚Ä¢ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(objects))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m objets existants dans le bucket\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\minio\\api.py:3322\u001b[0m, in \u001b[0;36mMinio._list_objects\u001b[1;34m(self, bucket_name, continuation_token, delimiter, encoding_type, fetch_owner, include_user_meta, max_keys, prefix, start_after, version_id_marker, use_api_v1, include_version, extra_headers, extra_query_params)\u001b[0m\n\u001b[0;32m   3319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version_id_marker:\n\u001b[0;32m   3320\u001b[0m     query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion-id-marker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m version_id_marker\n\u001b[1;32m-> 3322\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\n\u001b[0;32m   3323\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3324\u001b[0m     bucket_name,\n\u001b[0;32m   3325\u001b[0m     query_params\u001b[38;5;241m=\u001b[39mcast(DictType, query),\n\u001b[0;32m   3326\u001b[0m     headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m   3327\u001b[0m )\n\u001b[0;32m   3329\u001b[0m objects, is_truncated, start_after, version_id_marker \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3330\u001b[0m     parse_list_objects(response)\n\u001b[0;32m   3331\u001b[0m )\n\u001b[0;32m   3333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_version:\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\minio\\api.py:443\u001b[0m, in \u001b[0;36mMinio._execute\u001b[1;34m(self, method, bucket_name, object_name, body, headers, query_params, preload_content, no_body_trace)\u001b[0m\n\u001b[0;32m    440\u001b[0m region \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_region(bucket_name)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url_open(\n\u001b[0;32m    444\u001b[0m         method,\n\u001b[0;32m    445\u001b[0m         region,\n\u001b[0;32m    446\u001b[0m         bucket_name\u001b[38;5;241m=\u001b[39mbucket_name,\n\u001b[0;32m    447\u001b[0m         object_name\u001b[38;5;241m=\u001b[39mobject_name,\n\u001b[0;32m    448\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    449\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    450\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m    451\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    452\u001b[0m         no_body_trace\u001b[38;5;241m=\u001b[39mno_body_trace,\n\u001b[0;32m    453\u001b[0m     )\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3Error \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryHead\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\minio\\api.py:305\u001b[0m, in \u001b[0;36mMinio._url_open\u001b[1;34m(self, method, region, bucket_name, object_name, body, headers, query_params, preload_content, no_body_trace)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m         http_headers\u001b[38;5;241m.\u001b[39madd(key, value)\n\u001b[1;32m--> 305\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    306\u001b[0m     method,\n\u001b[0;32m    307\u001b[0m     urlunsplit(url),\n\u001b[0;32m    308\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    309\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhttp_headers,\n\u001b[0;32m    310\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    311\u001b[0m )\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_stream:\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_stream\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP/1.1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py:459\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    457\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    461\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test des connexions MinIO et PostgreSQL\n",
    "\n",
    "print(\"üîå Test des connexions...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Connexion MinIO\n",
    "try:\n",
    "    from minio import Minio\n",
    "    from minio.error import S3Error\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        MINIO_ENDPOINT.replace(\"http://\", \"\").replace(\"https://\", \"\"),\n",
    "        access_key=MINIO_ACCESS_KEY,\n",
    "        secret_key=MINIO_SECRET_KEY,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # Cr√©er le bucket s'il n'existe pas\n",
    "    if not minio_client.bucket_exists(MINIO_BUCKET):\n",
    "        minio_client.make_bucket(MINIO_BUCKET)\n",
    "        print(f\"‚úÖ MinIO : Bucket '{MINIO_BUCKET}' cr√©√©\")\n",
    "    else:\n",
    "        print(f\"‚úÖ MinIO : Bucket '{MINIO_BUCKET}' existe d√©j√†\")\n",
    "    \n",
    "    # Lister les objets existants\n",
    "    objects = list(minio_client.list_objects(MINIO_BUCKET, recursive=False))\n",
    "    print(f\"   ‚Ä¢ {len(list(objects))} objets existants dans le bucket\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå MinIO : Erreur de connexion - {e}\")\n",
    "    print(\"   üí° V√©rifiez que Docker Compose est lanc√© : docker compose up -d\")\n",
    "    minio_client = None\n",
    "\n",
    "# Connexion PostgreSQL\n",
    "try:\n",
    "    from sqlalchemy import create_engine, text\n",
    "    \n",
    "    engine = create_engine(PG_URL, future=True)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT 1 as test\"))\n",
    "        test_value = result.scalar()\n",
    "    \n",
    "    if test_value == 1:\n",
    "        print(f\"‚úÖ PostgreSQL : Connexion r√©ussie ({PG_HOST}:{PG_PORT}/{PG_DB})\")\n",
    "        \n",
    "        # Compter les tables existantes\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"\"\"\n",
    "                SELECT COUNT(*) FROM information_schema.tables \n",
    "                WHERE table_schema = 'public'\n",
    "            \"\"\"))\n",
    "            nb_tables = result.scalar()\n",
    "            print(f\"   ‚Ä¢ {nb_tables} tables existantes dans la base\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è PostgreSQL : Connexion OK mais test inattendu\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå PostgreSQL : Erreur de connexion - {e}\")\n",
    "    print(\"   üí° V√©rifiez que Docker Compose est lanc√© : docker compose up -d\")\n",
    "    engine = None\n",
    "\n",
    "print(\"\\n‚úÖ Tests de connexion termin√©s !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT= C:\\Users\\Utilisateur\\Desktop\n",
      "LOGS= C:\\Users\\Utilisateur\\Desktop\\logs\n",
      "DATA(raw)= C:\\Users\\Utilisateur\\Desktop\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# Override to root-level directories\n",
    "try:\n",
    "    ROOT = ROOT\n",
    "except NameError:\n",
    "    from pathlib import Path\n",
    "    ROOT = Path.cwd().resolve().parents[2]\n",
    "LOGS = ROOT / 'logs'\n",
    "DATA = ROOT / 'data' / 'raw'\n",
    "print('ROOT=', ROOT)\n",
    "print('LOGS=', LOGS)\n",
    "print('DATA(raw)=', DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è .env non trouv√©: C:\\Users\\Utilisateur\\Desktop\\.env\n",
      "üìÑ Exemple d√©j√† pr√©sent: C:\\Users\\Utilisateur\\Desktop\\.env.example\n"
     ]
    }
   ],
   "source": [
    "# Charger .env depuis la racine et cr√©er un .env.example si absent\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# D√©finir ROOT si non d√©fini\n",
    "if 'ROOT' not in globals():\n",
    "    ROOT = Path.cwd().resolve().parents[2]\n",
    "\n",
    "env_path = ROOT / '.env'\n",
    "loaded = load_dotenv(env_path)\n",
    "if loaded:\n",
    "    print('‚úÖ .env charg√©:', env_path)\n",
    "else:\n",
    "    print('‚ö†Ô∏è .env non trouv√©:', env_path)\n",
    "    example = ROOT / '.env.example'\n",
    "    if not example.exists():\n",
    "        example.write_text(\"\"\"\n",
    "# PostgreSQL\n",
    "POSTGRES_HOST=localhost\n",
    "POSTGRES_PORT=5432\n",
    "POSTGRES_DB=datasens\n",
    "POSTGRES_USER=ds_user\n",
    "POSTGRES_PASS=ds_pass\n",
    "\n",
    "# API Keys (optionnelles pour d√©mo)\n",
    "OWM_API_KEY=\n",
    "KAGGLE_USERNAME=\n",
    "KAGGLE_KEY=\n",
    "\n",
    "# Git (optionnel)\n",
    "GIT_USER_NAME=\n",
    "GIT_USER_EMAIL=\n",
    "\"\"\".strip()+\"\\n\", encoding='utf-8')\n",
    "        print('üìÑ Exemple cr√©√©:', example)\n",
    "    else:\n",
    "        print('üìÑ Exemple d√©j√† pr√©sent:', example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSens E1_v2 ‚Äî 01_setup_env\n",
    "\n",
    "- Objectifs: arborescence raw, logging, .env\n",
    "- Pr√©requis: Python, venv activ√©, `pip install -r requirements.txt`\n",
    "- Ordre global E1_v2: 01 ‚Üí 02 ‚Üí 03 ‚Üí 04 ‚Üí 05\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:20:39] INFO - Syst√®me de logging initialis√©\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arborescence raw cr√©√©e: c:\\Users\\Utilisateur\\Desktop\\DataSens\\notebooks\\datasens_E1_v2\\data\\raw\n",
      "üìÑ Log: c:\\Users\\Utilisateur\\Desktop\\DataSens\\notebooks\\logs\\collecte_20251101_112039.log\n"
     ]
    }
   ],
   "source": [
    "# DataSens E1_v2 - 01_setup_env\n",
    "# Config .env, arborescence raw, logging\n",
    "import logging\n",
    "from datetime import UTC, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "DATA = ROOT / \"data\" / \"raw\"\n",
    "for sub in [\"kaggle\",\"api/owm\",\"api/newsapi\",\"rss\",\"scraping/multi\",\"scraping/viepublique\",\"scraping/datagouv\",\"gdelt\",\"manifests\"]:\n",
    "    (DATA / sub).mkdir(parents=True, exist_ok=True)\n",
    "print(\"‚úÖ Arborescence raw cr√©√©e:\", DATA)\n",
    "\n",
    "# Logging\n",
    "LOGS = ROOT.parent / \"logs\"\n",
    "LOGS.mkdir(parents=True, exist_ok=True)\n",
    "stamp = datetime.now(UTC).strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = LOGS / f\"collecte_{stamp}.log\"\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s - %(message)s', datefmt='%H:%M:%S', handlers=[logging.FileHandler(log_file, encoding='utf-8'), logging.StreamHandler()])\n",
    "logging.info(\"Syst√®me de logging initialis√©\")\n",
    "print(\"üìÑ Log:\", log_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
