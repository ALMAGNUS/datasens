{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSens E1_v2 — 05_snapshot_and_readme\n",
    "\n",
    "- Objectifs: Manifest JSON complet, snapshot PostgreSQL, versioning, bilan final\n",
    "- Prérequis: 04_quality_checks exécuté\n",
    "- Sorties: `data/raw/manifests/manifest_*.json` + snapshot DB + `README_VERSIONNING.md`\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md\n",
    "\n",
    "> **E1_v2** : Finalisation avec traçabilité complète et snapshot versionné\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes:\n",
    "> - Génère un manifest JSON (traçabilité: version, timestamp, sources).\n",
    "> - Met à jour `README_VERSIONNING.md` pour garder l’historique.\n",
    "> - À adapter selon les sources réellement activées (OWM, RSS, NewsAPI, GDELT…).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSens E1_v2 - 05_snapshot_and_readme\n",
    "# 📦 Manifest + Snapshot + Versioning + Bilan final\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import UTC, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Récupérer variables\n",
    "if 'PROJECT_ROOT' not in globals():\n",
    "    current = Path.cwd()\n",
    "    PROJECT_ROOT = None\n",
    "    while current != current.parent:\n",
    "        if (current / \"notebooks\").exists() and (current / \"docs\").exists():\n",
    "            PROJECT_ROOT = current\n",
    "            break\n",
    "        current = current.parent\n",
    "    else:\n",
    "        PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "if 'PG_URL' not in globals():\n",
    "    PG_URL = os.getenv(\"DATASENS_PG_URL\", \"postgresql+psycopg2://postgres:postgres@localhost:5433/postgres\")\n",
    "\n",
    "engine = create_engine(PG_URL, future=True)\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "VERSIONS_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"manifests\"\n",
    "VERSION_FILE = PROJECT_ROOT / \"README_VERSIONNING.md\"\n",
    "\n",
    "print(\"📦 FINALISATION E1_V2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================\n",
    "# 1. MANIFEST JSON (Traçabilité complète)\n",
    "# ============================================================\n",
    "print(\"\\n📄 1. GENERATION MANIFEST JSON\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Statistiques complètes\n",
    "    stats_sources = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            s.nom AS source,\n",
    "            COUNT(DISTINCT f.id_flux) AS nb_flux,\n",
    "            COUNT(DISTINCT d.id_doc) AS nb_documents\n",
    "        FROM source s\n",
    "        LEFT JOIN flux f ON s.id_source = f.id_source\n",
    "        LEFT JOIN document d ON f.id_flux = d.id_flux\n",
    "        GROUP BY s.nom\n",
    "        ORDER BY nb_documents DESC\n",
    "    \"\"\", conn)\n",
    "\n",
    "VERSIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "manifest = {\n",
    "    \"run_id\": datetime.now(UTC).strftime(\"%Y%m%dT%H%M%SZ\"),\n",
    "    \"notebook_version\": \"E1_v2\",\n",
    "    \"created_utc\": datetime.now(UTC).isoformat(),\n",
    "    \"sources_collected\": stats_sources[\"source\"].tolist(),\n",
    "    \"statistics\": {\n",
    "        \"total_documents\": int(stats_sources[\"nb_documents\"].sum()),\n",
    "        \"total_flux\": int(stats_sources[\"nb_flux\"].sum()),\n",
    "        \"sources_count\": len(stats_sources)\n",
    "    },\n",
    "    \"pg_db\": PG_URL.split(\"/\")[-1] if \"/\" in PG_URL else \"postgres\",\n",
    "    \"minio_bucket\": os.getenv(\"MINIO_BUCKET\", \"datasens-raw\")\n",
    "}\n",
    "\n",
    "manifest_path = VERSIONS_DIR / f\"manifest_{manifest['run_id']}.json\"\n",
    "manifest_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ Manifest créé : {manifest_path}\")\n",
    "print(f\"\\n📊 Contenu du manifest :\")\n",
    "print(json.dumps(manifest, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Afficher le manifest comme DataFrame\n",
    "df_manifest = pd.DataFrame([manifest])\n",
    "print(\"\\n📋 Manifest (format tableau) :\")\n",
    "display(pd.DataFrame([{\n",
    "    \"Run ID\": manifest[\"run_id\"],\n",
    "    \"Version\": manifest[\"notebook_version\"],\n",
    "    \"Total Documents\": manifest[\"statistics\"][\"total_documents\"],\n",
    "    \"Total Flux\": manifest[\"statistics\"][\"total_flux\"],\n",
    "    \"Sources\": len(manifest[\"sources_collected\"])\n",
    "}]))\n",
    "\n",
    "# ============================================================\n",
    "# 2. SNAPSHOT POSTGRESQL (Optionnel - instruction manuelle)\n",
    "# ============================================================\n",
    "print(\"\\n💾 2. SNAPSHOT POSTGRESQL\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"💡 Pour créer un snapshot PostgreSQL, exécutez dans le terminal :\")\n",
    "print(f\"   docker exec datasens_pg pg_dump -U postgres postgres > data/raw/manifests/pg_snapshot_{manifest['run_id']}.sql\")\n",
    "print(\"\\n   Ou via SQLAlchemy (export CSV des tables principales) :\")\n",
    "\n",
    "# Export CSV des tables principales pour backup léger\n",
    "VERSIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "snapshot_dir = VERSIONS_DIR / f\"snapshot_{manifest['run_id']}\"\n",
    "snapshot_dir.mkdir(exist_ok=True)\n",
    "\n",
    "tables_to_export = [\"type_donnee\", \"source\", \"flux\", \"document\"]\n",
    "for table in tables_to_export:\n",
    "    try:\n",
    "        df_snap = pd.read_sql_query(f\"SELECT * FROM {table}\", engine)\n",
    "        snap_file = snapshot_dir / f\"{table}.csv\"\n",
    "        df_snap.to_csv(snap_file, index=False)\n",
    "        print(f\"   ✅ {table}: {len(df_snap)} lignes → {snap_file.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ {table}: {e}\")\n",
    "\n",
    "print(f\"\\n📂 Snapshot CSV : {snapshot_dir}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. VERSIONING\n",
    "# ============================================================\n",
    "print(\"\\n📘 3. VERSIONING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "VERSION_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "entry = f\"- **{datetime.now(UTC).strftime('%Y-%m-%d %H:%M:%S UTC')}** | `E1_V2_COMPLETE` | Collecte réelle {manifest['statistics']['total_documents']} documents, {manifest['statistics']['sources_count']} sources actives\\n\"\n",
    "\n",
    "with open(VERSION_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(entry)\n",
    "\n",
    "print(f\"✅ Versionning mis à jour : {VERSION_FILE}\")\n",
    "\n",
    "# Afficher les dernières entrées\n",
    "if VERSION_FILE.exists():\n",
    "    print(\"\\n📋 Dernières 5 entrées de l'historique :\")\n",
    "    with open(VERSION_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[-5:]:\n",
    "            print(f\"   {line.strip()}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. BILAN FINAL AVEC VISUALISATIONS\n",
    "# ============================================================\n",
    "print(\"\\n📊 4. BILAN FINAL E1_V2\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Vue complète chaîne de traçabilité\n",
    "    df_chain = pd.read_sql_query(\"\"\"\n",
    "        SELECT\n",
    "            td.libelle AS type_donnee,\n",
    "            s.nom AS source,\n",
    "            COUNT(DISTINCT f.id_flux) AS nb_flux,\n",
    "            COUNT(DISTINCT d.id_doc) AS nb_documents,\n",
    "            ROUND(s.fiabilite * 100, 1) AS fiabilite_pct\n",
    "        FROM type_donnee td\n",
    "        LEFT JOIN source s ON s.id_type_donnee = td.id_type_donnee\n",
    "        LEFT JOIN flux f ON f.id_source = s.id_source\n",
    "        LEFT JOIN document d ON d.id_flux = f.id_flux\n",
    "        GROUP BY td.libelle, s.nom, s.fiabilite\n",
    "        ORDER BY nb_documents DESC\n",
    "    \"\"\", conn)\n",
    "\n",
    "print(\"\\n📋 Vue complète chaîne de traçabilité (Type → Source → Flux → Document) :\")\n",
    "display(df_chain)\n",
    "\n",
    "# Graphique final\n",
    "if len(df_chain) > 0:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.barh(df_chain[\"source\"], df_chain[\"nb_documents\"], color=plt.cm.Set3(range(len(df_chain))))\n",
    "    for i, (bar, value) in enumerate(zip(bars, df_chain[\"nb_documents\"])):\n",
    "        plt.text(bar.get_width() + max(df_chain[\"nb_documents\"]) * 0.01, bar.get_y() + bar.get_height()/2,\n",
    "                f\"{int(value):,}\", ha='left', va='center', fontweight='bold', fontsize=9)\n",
    "    plt.title(\"📊 Documents collectés par source\", fontsize=12, fontweight='bold')\n",
    "    plt.xlabel(\"Nombre de documents\", fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if len(df_chain[\"type_donnee\"].unique()) > 0:\n",
    "        type_counts = df_chain.groupby(\"type_donnee\")[\"nb_documents\"].sum()\n",
    "        plt.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "        plt.title(\"📊 Répartition par type de donnée\", fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Tableau récapitulatif final\n",
    "print(\"\\n📋 Tableau récapitulatif final :\")\n",
    "display(df_chain)\n",
    "\n",
    "print(f\"\\n✅ E1_V2 TERMINE :\")\n",
    "print(f\"   • {manifest['statistics']['total_documents']:,} documents collectés\")\n",
    "print(f\"   • {manifest['statistics']['total_flux']} flux de collecte\")\n",
    "print(f\"   • {manifest['statistics']['sources_count']} sources actives\")\n",
    "print(f\"   • Manifest : {manifest_path.name}\")\n",
    "print(f\"\\n🎯 Prêt pour E2 (Enrichissement IA) !\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
