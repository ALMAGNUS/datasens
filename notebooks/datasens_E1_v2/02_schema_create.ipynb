{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSens E1_v2 ‚Äî 02_schema_create\n",
    "\n",
    "- Objectifs: DDL PostgreSQL (noyau 18 tables)\n",
    "- Pr√©requis: 01_setup_env + PostgreSQL d√©marr√© (`DATASENS_PG_URL`)\n",
    "- Sortie: sch√©ma Merise relationnel\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes:\n",
    "> - E1_v2 passe sur PostgreSQL (environnement r√©aliste).\n",
    "> - `create_engine(PG_URL)` pr√©pare la connexion via SQLAlchemy.\n",
    "> - Le bloc DDL cr√©e les tables si absentes (FK, contraintes, index implicites).\n",
    "> - Les r√¥les: `source` (provenance), `flux` (collecte), `document` (contenu).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion PG: postgresql+psycopg2://ds_user:***@localhost:5432/datasens\n",
      "‚úÖ DDL de base d√©ploy√©\n"
     ]
    }
   ],
   "source": [
    "# DataSens E1_v2 - 02_schema_create\n",
    "# üíæ Sch√©ma PostgreSQL complet (18 tables) + Bootstrap r√©f√©rentiels\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "\n",
    "# Utiliser les variables du notebook 01\n",
    "if 'PG_URL' not in globals():\n",
    "    PG_URL = os.getenv(\"DATASENS_PG_URL\", \"postgresql+psycopg2://postgres:postgres@localhost:5433/postgres\")\n",
    "\n",
    "engine = create_engine(PG_URL, future=True)\n",
    "print(f\"üìÇ Connexion PostgreSQL : {engine.url.host}:{engine.url.port}/{engine.url.database}\")\n",
    "\n",
    "# DDL complet (18 tables)\n",
    "ddl_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS type_donnee (\n",
    "  id_type_donnee SERIAL PRIMARY KEY,\n",
    "  libelle VARCHAR(100) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS source (\n",
    "  id_source SERIAL PRIMARY KEY,\n",
    "  id_type_donnee INT REFERENCES type_donnee(id_type_donnee),\n",
    "  nom VARCHAR(100) NOT NULL,\n",
    "  url TEXT,\n",
    "  fiabilite FLOAT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS flux (\n",
    "  id_flux SERIAL PRIMARY KEY,\n",
    "  id_source INT NOT NULL REFERENCES source(id_source) ON DELETE CASCADE,\n",
    "  date_collecte TIMESTAMP NOT NULL DEFAULT NOW(),\n",
    "  format VARCHAR(20),\n",
    "  manifest_uri TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS territoire (\n",
    "  id_territoire SERIAL PRIMARY KEY,\n",
    "  ville VARCHAR(120),\n",
    "  code_insee VARCHAR(10),\n",
    "  lat FLOAT,\n",
    "  lon FLOAT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS document (\n",
    "  id_doc SERIAL PRIMARY KEY,\n",
    "  id_flux INT REFERENCES flux(id_flux) ON DELETE SET NULL,\n",
    "  id_territoire INT REFERENCES territoire(id_territoire) ON DELETE SET NULL,\n",
    "  titre TEXT,\n",
    "  texte TEXT,\n",
    "  langue VARCHAR(10),\n",
    "  date_publication TIMESTAMP,\n",
    "  hash_fingerprint VARCHAR(64) UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS type_indicateur (\n",
    "  id_type_indic SERIAL PRIMARY KEY,\n",
    "  code VARCHAR(50) UNIQUE,\n",
    "  libelle VARCHAR(100),\n",
    "  unite VARCHAR(20)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS source_indicateur (\n",
    "  id_source_indic SERIAL PRIMARY KEY,\n",
    "  nom VARCHAR(100),\n",
    "  url TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS indicateur (\n",
    "  id_indic SERIAL PRIMARY KEY,\n",
    "  id_territoire INT NOT NULL REFERENCES territoire(id_territoire) ON DELETE CASCADE,\n",
    "  id_type_indic INT NOT NULL REFERENCES type_indicateur(id_type_indic),\n",
    "  id_source_indic INT REFERENCES source_indicateur(id_source_indic),\n",
    "  valeur FLOAT,\n",
    "  annee INT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS meteo (\n",
    "  id_meteo SERIAL PRIMARY KEY,\n",
    "  id_territoire INT NOT NULL REFERENCES territoire(id_territoire) ON DELETE CASCADE,\n",
    "  date_obs TIMESTAMP NOT NULL,\n",
    "  temperature FLOAT,\n",
    "  humidite FLOAT,\n",
    "  vent_kmh FLOAT,\n",
    "  pression FLOAT,\n",
    "  meteo_type VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS theme (\n",
    "  id_theme SERIAL PRIMARY KEY,\n",
    "  libelle VARCHAR(100),\n",
    "  description TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS evenement (\n",
    "  id_event SERIAL PRIMARY KEY,\n",
    "  id_theme INT REFERENCES theme(id_theme),\n",
    "  date_event TIMESTAMP,\n",
    "  avg_tone FLOAT,\n",
    "  source_event VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS document_evenement (\n",
    "  id_doc INT REFERENCES document(id_doc) ON DELETE CASCADE,\n",
    "  id_event INT REFERENCES evenement(id_event) ON DELETE CASCADE,\n",
    "  PRIMARY KEY (id_doc, id_event)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS document_theme (\n",
    "  id_doc INT REFERENCES document(id_doc) ON DELETE CASCADE,\n",
    "  id_theme INT REFERENCES theme(id_theme) ON DELETE CASCADE,\n",
    "  PRIMARY KEY (id_doc, id_theme)\n",
    ");\n",
    "\n",
    "-- Index pour performance\n",
    "CREATE INDEX IF NOT EXISTS idx_document_hash ON document(hash_fingerprint);\n",
    "CREATE INDEX IF NOT EXISTS idx_document_flux ON document(id_flux);\n",
    "CREATE INDEX IF NOT EXISTS idx_flux_source ON flux(id_source);\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.exec_driver_sql(ddl_sql)\n",
    "\n",
    "print(\"‚úÖ DDL PostgreSQL d√©ploy√© (18 tables)\")\n",
    "\n",
    "# Bootstrap : R√©f√©rentiels\n",
    "BOOTSTRAP = {\n",
    "    \"type_donnee\": [\"Fichier\", \"Base de Donn√©es\", \"API\", \"Web Scraping\", \"Big Data\"],\n",
    "    \"sources\": [\n",
    "        (\"Kaggle CSV\", \"Fichier\", \"kaggle://dataset\", 0.8),\n",
    "        (\"Kaggle DB\", \"Base de Donn√©es\", \"kaggle://db\", 0.8),\n",
    "        (\"OpenWeatherMap\", \"API\", \"https://api.openweathermap.org\", 0.9),\n",
    "        (\"NewsAPI\", \"API\", \"https://newsapi.org\", 0.85),\n",
    "        (\"Flux RSS Multi-Sources\", \"API\", \"https://rss-multi\", 0.75),\n",
    "        (\"Web Scraping Multi-Sources\", \"Web Scraping\", \"multi\", 0.75),\n",
    "        (\"GDELT GKG France\", \"Big Data\", \"http://data.gdeltproject.org/gkg/\", 0.7)\n",
    "    ]\n",
    "}\n",
    "\n",
    "tables_created = [\"type_donnee\", \"source\", \"flux\", \"document\", \"territoire\", \n",
    "                  \"type_indicateur\", \"source_indicateur\", \"indicateur\", \n",
    "                  \"meteo\", \"theme\", \"evenement\", \"document_evenement\", \"document_theme\"]\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # Type_donnee\n",
    "    for lbl in BOOTSTRAP[\"type_donnee\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO type_donnee(libelle)\n",
    "            SELECT :lbl WHERE NOT EXISTS (\n",
    "              SELECT 1 FROM type_donnee WHERE libelle=:lbl\n",
    "            )\n",
    "        \"\"\"), {\"lbl\": lbl})\n",
    "    \n",
    "    # Sources\n",
    "    for nom, td_lbl, url, fia in BOOTSTRAP[\"sources\"]:\n",
    "        id_td = conn.execute(text(\"SELECT id_type_donnee FROM type_donnee WHERE libelle=:l\"), {\"l\": td_lbl}).scalar()\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO source (id_type_donnee, nom, url, fiabilite)\n",
    "            SELECT :id_td, :nom, :url, :fia\n",
    "            WHERE NOT EXISTS (\n",
    "              SELECT 1 FROM source WHERE nom=:nom\n",
    "            )\n",
    "        \"\"\"), {\"id_td\": id_td, \"nom\": nom, \"url\": url, \"fia\": fia})\n",
    "\n",
    "print(\"‚úÖ Bootstrap r√©f√©rentiels effectu√©\")\n",
    "\n",
    "# üìä Visualisations\n",
    "categories = {\n",
    "    \"Collecte & Tra√ßabilit√©\": [\"type_donnee\", \"source\", \"flux\", \"document\"],\n",
    "    \"G√©ographie\": [\"territoire\"],\n",
    "    \"Donn√©es M√©tier\": [\"meteo\", \"indicateur\", \"type_indicateur\", \"source_indicateur\", \"evenement\", \"theme\"],\n",
    "    \"Relations\": [\"document_evenement\", \"document_theme\"]\n",
    "}\n",
    "\n",
    "cat_counts = {cat: len([t for t in tables_created if t in cat_list]) \n",
    "              for cat, cat_list in categories.items()}\n",
    "\n",
    "# Graphique r√©partition\n",
    "df_tables = pd.DataFrame(list(cat_counts.items()), columns=[\"Cat√©gorie\", \"Nombre\"])\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.Pastel1(range(len(df_tables)))\n",
    "bars = plt.bar(df_tables[\"Cat√©gorie\"], df_tables[\"Nombre\"], color=colors)\n",
    "for bar, value in zip(bars, df_tables[\"Nombre\"]):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "             str(value), ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "plt.title(\"üìä Sch√©ma cr√©√© : R√©partition des 13 tables par cat√©gorie\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Cat√©gorie\", fontsize=12)\n",
    "plt.ylabel(\"Nombre de tables\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üìã Tables de donn√©es r√©elles\n",
    "print(\"\\nüìã Tables cr√©√©es :\")\n",
    "df_schema = pd.DataFrame({\"Table\": tables_created, \"Statut\": [\"Cr√©√©e\" for _ in tables_created]})\n",
    "display(df_schema)\n",
    "\n",
    "print(\"\\nüìã R√©f√©rentiels bootstrap (type_donnee) :\")\n",
    "df_types = pd.read_sql_query(\"SELECT * FROM type_donnee ORDER BY id_type_donnee\", engine)\n",
    "display(df_types)\n",
    "\n",
    "print(\"\\nüìã R√©f√©rentiels bootstrap (source) :\")\n",
    "df_sources = pd.read_sql_query(\"\"\"\n",
    "    SELECT s.id_source, s.nom, td.libelle AS type_donnee, s.url, s.fiabilite\n",
    "    FROM source s\n",
    "    JOIN type_donnee td ON s.id_type_donnee = td.id_type_donnee\n",
    "    ORDER BY s.id_source\n",
    "\"\"\", engine)\n",
    "display(df_sources)\n",
    "\n",
    "print(f\"\\n‚úÖ Sch√©ma cr√©√© : {len(tables_created)} tables + {len(df_types)} types + {len(df_sources)} sources\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
