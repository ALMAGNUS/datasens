{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è DataSens E2 ‚Äî Notebook 2 : Cr√©ation du Sch√©ma PostgreSQL\n",
    "\n",
    "**üéØ Objectif** : Cr√©er le sch√©ma PostgreSQL complet (36 tables Merise E2) avec contraintes, index et donn√©es de r√©f√©rence\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Contenu de ce notebook\n",
    "\n",
    "1. Rappel MCD/MLD (sch√©mas Mermaid) - 36 tables E2\n",
    "2. DDL PostgreSQL : CREATE TABLE pour les 36 tables E2\n",
    "3. Index et contraintes (FK, UNIQUE, CHECK, ON DELETE)\n",
    "4. Insertion des r√©f√©rentiels (type_donnee, type_meteo, type_indicateur, valence, type_emotion, etc.)\n",
    "5. Corrections MPD optionnelles (r√©f√©rence vers scripts `tests/fix_mpd_*.sql` pour passer √† 40 tables)\n",
    "6. Contr√¥les : listes des tables, counts par table\n",
    "\n",
    "---\n",
    "\n",
    "## üîí RGPD & Gouvernance\n",
    "\n",
    "‚ö†Ô∏è **Rappel important** :\n",
    "- Pas de donn√©es personnelles directes (hash SHA-256 si n√©cessaire)\n",
    "- Respect robots.txt pour le scraping\n",
    "- Droits d'usage document√©s par source\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Note sur les Sources\n",
    "\n",
    "**Sources E1 test√©es** : Kaggle CSV, OpenWeatherMap API, RSS Multi-sources, Web Scraping (Vie-publique, data.gouv), GDELT GKG  \n",
    "**Sources payantes/obsol√®tes** : Voir `docs/SOURCES_STATUS.md` pour liste compl√®te (ex: NewsAPI payant $449/mois, SignalConso API obsol√®te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ Rappel MCD/MLD (Mod√®le Conceptuel/Logique de Donn√©es)\n",
    "\n",
    "### 36 Tables cibles E2 (Architecture compl√®te)\n",
    "\n",
    "**Collecte** (4 tables) :\n",
    "- `type_donnee`, `source`, `flux`, `archive_flux`\n",
    "\n",
    "**Documents & Annotations** (9 tables) :\n",
    "- `document`, `annotation`, `annotation_emotion`, `meta_annotation`, `emotion`, `type_emotion`, `valence`, `modele_ia`, `utilisateur`\n",
    "\n",
    "**G√©ographie** (5 tables) :\n",
    "- `pays`, `region`, `departement`, `commune`, `territoire`\n",
    "\n",
    "**Contexte** (5 tables) :\n",
    "- `type_meteo`, `meteo`, `type_indicateur`, `source_indicateur`, `indicateur`\n",
    "\n",
    "**Th√®mes & √âv√©nements** (5 tables) :\n",
    "- `theme_category`, `theme`, `evenement`, `document_theme`, `document_evenement`\n",
    "\n",
    "**Barom√®tres** (2 tables) :\n",
    "- `source_barometre`, `document_baro`\n",
    "\n",
    "**Pipeline & Qualit√©** (5 tables) :\n",
    "- `pipeline`, `etape_etl`, `exec_etape`, `qc_rule`, `qc_result`\n",
    "\n",
    "**Gouvernance** (2 tables) :\n",
    "- `table_audit`, `table_version`\n",
    "\n",
    "**Collecte** :\n",
    "- `type_donnee` : Cat√©gorisation des sources (Fichier, Base de donn√©es, API, Web Scraping, Big Data)\n",
    "- `source` : Sources r√©elles (Kaggle, OpenWeatherMap, MonAvisCitoyen, etc.)\n",
    "- `flux` : Tra√ßabilit√© des collectes (date, format, manifest_uri)\n",
    "\n",
    "**Corpus** :\n",
    "- `document` : Documents bruts collect√©s (titre, texte, langue, hash_fingerprint)\n",
    "- `territoire` : G√©olocalisation (ville, code_insee, lat, lon)\n",
    "\n",
    "**Contexte** :\n",
    "- `type_meteo` : Types de conditions m√©t√©o (clair, nuageux, pluie...)\n",
    "- `meteo` : Relev√©s m√©t√©o (temp√©rature, humidit√©, pression, vent)\n",
    "- `type_indicateur` : Types d'indicateurs (population, revenu, etc.)\n",
    "- `source_indicateur` : Sources des indicateurs (INSEE, IGN...)\n",
    "- `indicateur` : Valeurs d'indicateurs par territoire\n",
    "\n",
    "**Th√®mes/√©v√©nements** :\n",
    "- `theme` : Th√®mes documentaires (politique, √©conomie, environnement...)\n",
    "- `evenement` : √âv√©nements temporels (date_event, avg_tone)\n",
    "- `document_evenement` : Relation N-N documents ‚Üî √©v√©nements\n",
    "\n",
    "**Gouvernance pipeline** :\n",
    "- `pipeline` : Description des pipelines ETL\n",
    "- `etape_etl` : √âtapes du pipeline avec ordre d'ex√©cution\n",
    "\n",
    "**Utilisateurs (trace)** :\n",
    "- `utilisateur` : Utilisateurs du syst√®me (pour futures annotations)\n",
    "\n",
    "**Qualit√© (min)** :\n",
    "- `qc_rule` : R√®gles de contr√¥le qualit√© (placeholder)\n",
    "- `qc_result` : R√©sultats des contr√¥les qualit√© (optionnel)\n",
    "\n",
    "---\n",
    "\n",
    "### Sch√©ma Mermaid (simplifi√©)\n",
    "\n",
    "```mermaid\n",
    "erDiagram\n",
    "    TYPE_DONNEE ||--o{ SOURCE : \"a pour\"\n",
    "    SOURCE ||--o{ FLUX : \"g√©n√®re\"\n",
    "    FLUX ||--o{ DOCUMENT : \"contient\"\n",
    "    TERRITOIRE ||--o{ DOCUMENT : \"g√©olocalise\"\n",
    "    TERRITOIRE ||--o{ METEO : \"mesure\"\n",
    "    TERRITOIRE ||--o{ INDICATEUR : \"agr√®ge\"\n",
    "    THEME ||--o{ EVENEMENT : \"classe\"\n",
    "    DOCUMENT ||--o{ DOCUMENT_EVENEMENT : \"ref√®re\"\n",
    "    EVENEMENT ||--o{ DOCUMENT_EVENEMENT : \"associe\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from minio import Minio\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Charger .env\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == \"notebooks\" else NOTEBOOK_DIR\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "# Connexion PostgreSQL\n",
    "PG_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.getenv(\"POSTGRES_PORT\", \"5432\"))\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\", \"datasens\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\", \"ds_user\")\n",
    "PG_PASS = os.getenv(\"POSTGRES_PASS\", \"ds_pass\")\n",
    "\n",
    "PG_URL = f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "engine = create_engine(PG_URL, future=True)\n",
    "\n",
    "# Configuration MinIO (DataLake)\n",
    "MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"http://localhost:9000\")\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", \"miniouser\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", \"miniosecret\")\n",
    "MINIO_BUCKET = os.getenv(\"MINIO_BUCKET\", \"datasens-raw\")\n",
    "\n",
    "print(\"üîå Connexion PostgreSQL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìç {PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "print(f\"üë§ {PG_USER}\")\n",
    "\n",
    "# Test connexion PostgreSQL\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"‚úÖ PostgreSQL : Connexion OK\")\n",
    "\n",
    "# Test connexion MinIO\n",
    "try:\n",
    "    minio_client = Minio(\n",
    "        MINIO_ENDPOINT.replace(\"http://\", \"\").replace(\"https://\", \"\"),\n",
    "        access_key=MINIO_ACCESS_KEY,\n",
    "        secret_key=MINIO_SECRET_KEY,\n",
    "        secure=MINIO_ENDPOINT.startswith(\"https\")\n",
    "    )\n",
    "\n",
    "    # Fonction helper MinIO\n",
    "    def ensure_bucket(bucket: str = MINIO_BUCKET):\n",
    "        if not minio_client.bucket_exists(bucket):\n",
    "            minio_client.make_bucket(bucket)\n",
    "\n",
    "    def minio_upload(local_path: Path, dest_key: str) -> str:\n",
    "        ensure_bucket(MINIO_BUCKET)\n",
    "        minio_client.fput_object(MINIO_BUCKET, dest_key, str(local_path))\n",
    "        return f\"s3://{MINIO_BUCKET}/{dest_key}\"\n",
    "\n",
    "    ensure_bucket()\n",
    "    print(f\"‚úÖ MinIO : DataLake OK ‚Üí bucket: {MINIO_BUCKET}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MinIO : Erreur connexion ({e}) - V√©rifier docker-compose up -d\")\n",
    "    minio_client = None\n",
    "    def minio_upload(local_path: Path, dest_key: str) -> str:\n",
    "        return f\"local://{local_path}\"\n",
    "\n",
    "print(\"\\n‚úÖ Configuration termin√©e !\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê DDL PostgreSQL : Cr√©ation des 36 tables E2\n",
    "\n",
    "Cr√©ation des tables avec contraintes d'int√©grit√© r√©f√©rentielle.  \n",
    "**Ordre de cr√©ation** : Respect des d√©pendances FK (r√©f√©rentiels ‚Üí m√©tier ‚Üí liaisons).\n",
    "\n",
    "**Note** : Les sources obsol√®tes/payantes ne sont **pas** impl√©ment√©es.  \n",
    "**Sources E1 test√©es** : Kaggle CSV, OpenWeatherMap API, RSS Multi-sources, Web Scraping (Vie-publique, data.gouv), GDELT GKG  \n",
    "**Voir** `docs/SOURCES_STATUS.md` pour statut complet des sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDL complet : 36 tables E2\n",
    "# Bas√© sur MCD/MLD/MPD valid√©s - Ordre respecte d√©pendances FK\n",
    "# Chargement depuis fichier SQL pour lisibilit√©\n",
    "\n",
    "ddl_file = PROJECT_ROOT / \"tests\" / \"ddl_36_tables_e2.sql\"\n",
    "\n",
    "if ddl_file.exists():\n",
    "    with open(ddl_file, encoding='utf-8') as f:\n",
    "        ddl_sql = f.read()\n",
    "    print(f\"‚úÖ DDL charg√© depuis {ddl_file.name}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Fichier DDL non trouv√©: {ddl_file}\")\n",
    "    print(\"   ‚Üí Cr√©ation DDL inline (18 tables E1 seulement)...\")\n",
    "    # Fallback DDL minimal (18 tables E1)\n",
    "    ddl_sql = \"\"\"\n",
    "-- =====================================================\n",
    "-- COLLECTE : Type de donn√©es, sources, flux\n",
    "-- =====================================================\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS type_donnee (\n",
    "  id_type_donnee SERIAL PRIMARY KEY,\n",
    "  libelle VARCHAR(100) NOT NULL UNIQUE,\n",
    "  description TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS source (\n",
    "  id_source SERIAL PRIMARY KEY,\n",
    "  id_type_donnee INT REFERENCES type_donnee(id_type_donnee) ON DELETE RESTRICT,\n",
    "  nom VARCHAR(100) NOT NULL,\n",
    "  url TEXT,\n",
    "  fiabilite FLOAT CHECK (fiabilite >= 0 AND fiabilite <= 1)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS flux (\n",
    "  id_flux SERIAL PRIMARY KEY,\n",
    "  id_source INT NOT NULL REFERENCES source(id_source) ON DELETE CASCADE,\n",
    "  date_collecte TIMESTAMP NOT NULL DEFAULT NOW(),\n",
    "  format VARCHAR(20),\n",
    "  manifest_uri TEXT\n",
    ");\n",
    "\n",
    "-- =====================================================\n",
    "-- CORPUS : Documents et territoires\n",
    "-- =====================================================\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS territoire (\n",
    "  id_territoire SERIAL PRIMARY KEY,\n",
    "  ville VARCHAR(120),\n",
    "  code_insee VARCHAR(10),\n",
    "  lat FLOAT,\n",
    "  lon FLOAT,\n",
    "  CONSTRAINT unique_code_insee UNIQUE (code_insee)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS document (\n",
    "  id_doc SERIAL PRIMARY KEY,\n",
    "  id_flux INT REFERENCES flux(id_flux) ON DELETE SET NULL,\n",
    "  id_territoire INT REFERENCES territoire(id_territoire) ON DELETE SET NULL,\n",
    "  titre TEXT,\n",
    "  texte TEXT,\n",
    "  langue VARCHAR(10),\n",
    "  date_publication TIMESTAMP,\n",
    "  hash_fingerprint VARCHAR(64) UNIQUE\n",
    ");\n",
    "\n",
    "-- =====================================================\n",
    "-- CONTEXTE : M√©t√©o et indicateurs\n",
    "-- =====================================================\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS type_meteo (\n",
    "  id_type_meteo SERIAL PRIMARY KEY,\n",
    "  code VARCHAR(20) UNIQUE NOT NULL,\n",
    "  libelle VARCHAR(100) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS meteo (\n",
    "  id_meteo SERIAL PRIMARY KEY,\n",
    "  id_territoire INT NOT NULL REFERENCES territoire(id_territoire) ON DELETE CASCADE,\n",
    "  id_type_meteo INT REFERENCES type_meteo(id_type_meteo) ON DELETE SET NULL,\n",
    "  date_obs TIMESTAMP NOT NULL,\n",
    "  temperature FLOAT,\n",
    "  humidite FLOAT CHECK (humidite >= 0 AND humidite <= 100),\n",
    "  vent_kmh FLOAT CHECK (vent_kmh >= 0),\n",
    "  pression FLOAT CHECK (pression > 0),\n",
    "  meteo_type VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS type_indicateur (\n",
    "  id_type_indic SERIAL PRIMARY KEY,\n",
    "  code VARCHAR(50) UNIQUE NOT NULL,\n",
    "  libelle VARCHAR(100),\n",
    "  unite VARCHAR(20)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS source_indicateur (\n",
    "  id_source_indic SERIAL PRIMARY KEY,\n",
    "  nom VARCHAR(100) NOT NULL,\n",
    "  url TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS indicateur (\n",
    "  id_indic SERIAL PRIMARY KEY,\n",
    "  id_territoire INT NOT NULL REFERENCES territoire(id_territoire) ON DELETE CASCADE,\n",
    "  id_type_indic INT NOT NULL REFERENCES type_indicateur(id_type_indic) ON DELETE RESTRICT,\n",
    "  id_source_indic INT REFERENCES source_indicateur(id_source_indic) ON DELETE SET NULL,\n",
    "  valeur FLOAT,\n",
    "  annee INT CHECK (annee >= 1900 AND annee <= 2100)\n",
    ");\n",
    "\n",
    "-- =====================================================\n",
    "-- TH√àMES/√âV√âNEMENTS\n",
    "-- =====================================================\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS theme (\n",
    "  id_theme SERIAL PRIMARY KEY,\n",
    "  libelle VARCHAR(100) NOT NULL,\n",
    "  description TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS evenement (\n",
    "  id_event SERIAL PRIMARY KEY,\n",
    "  id_theme INT REFERENCES theme(id_theme) ON DELETE SET NULL,\n",
    "  date_event TIMESTAMP,\n",
    "  avg_tone FLOAT CHECK (avg_tone >= -100 AND avg_tone <= 100),\n",
    "  source_event VARCHAR(50)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS document_evenement (\n",
    "  id_doc INT NOT NULL REFERENCES document(id_doc) ON DELETE CASCADE,\n",
    "  id_event INT NOT NULL REFERENCES evenement(id_event) ON DELETE CASCADE,\n",
    "  PRIMARY KEY (id_doc, id_event)\n",
    ");\n",
    "\n",
    "-- =====================================================\n",
    "-- GOUVERNANCE PIPELINE\n",
    "-- =====================================================\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS pipeline (\n",
    "  id_pipeline SERIAL PRIMARY KEY,\n",
    "  nom VARCHAR(100) NOT NULL,\n",
    "  description TEXT,\n",
    "  version VARCHAR(20)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS etape_etl (\n",
    "  id_etape SERIAL PRIMARY KEY,\n",
    "  id_pipeline INT NOT NULL REFERENCES pipeline(id_pipeline) ON DELETE CASCADE,\n",
    "  ordre INT NOT NULL CHECK (ordre > 0),\n",
    "  nom_etape VARCHAR(100) NOT NULL,\n",
    "  type_etape VARCHAR(20) CHECK (type_etape IN ('EXTRACT', 'TRANSFORM', 'LOAD')),\n",
    "  description TEXT,\n",
    "  CONSTRAINT unique_pipeline_ordre UNIQUE (id_pipeline, ordre)\n",
    ");\n",
    "\n",
    "-- =====================================================\n",
    "-- UTILISATEURS (trace)\n",
    "-- =====================================================\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS utilisateur (\n",
    "  id_user SERIAL PRIMARY KEY,\n",
    "  nom VARCHAR(100),\n",
    "  role VARCHAR(50),\n",
    "  organisation VARCHAR(100),\n",
    "  date_creation TIMESTAMP DEFAULT NOW()\n",
    ");\n",
    "\n",
    "-- =====================================================\n",
    "-- QUALIT√â (min)\n",
    "-- =====================================================\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS qc_rule (\n",
    "  id_qc_rule SERIAL PRIMARY KEY,\n",
    "  nom_regle VARCHAR(100) NOT NULL,\n",
    "  description TEXT,\n",
    "  expression_sql TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS qc_result (\n",
    "  id_qc_result SERIAL PRIMARY KEY,\n",
    "  id_qc_rule INT REFERENCES qc_rule(id_qc_rule) ON DELETE CASCADE,\n",
    "  id_flux INT REFERENCES flux(id_flux) ON DELETE CASCADE,\n",
    "  date_check TIMESTAMP DEFAULT NOW(),\n",
    "  statut VARCHAR(20) CHECK (statut IN ('PASS', 'FAIL', 'WARNING')),\n",
    "  message TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìê Ex√©cution DDL PostgreSQL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Option : Supprimer toutes les tables existantes avant de les recr√©er\n",
    "# ‚ö†Ô∏è D√©commenter DROP_TABLES = True si vous voulez reset complet (perte de donn√©es)\n",
    "DROP_TABLES = True  # ‚ö†Ô∏è ACTIV√â : Va supprimer toutes les tables existantes et les recr√©er\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    if DROP_TABLES:\n",
    "        print(\"‚ö†Ô∏è Suppression des tables existantes...\")\n",
    "        # Supprimer toutes les tables en cascade (attention : perte de donn√©es !)\n",
    "        drop_sql = \"\"\"\n",
    "        DROP TABLE IF EXISTS qc_result CASCADE;\n",
    "        DROP TABLE IF EXISTS qc_rule CASCADE;\n",
    "        DROP TABLE IF EXISTS utilisateur CASCADE;\n",
    "        DROP TABLE IF EXISTS etape_etl CASCADE;\n",
    "        DROP TABLE IF EXISTS pipeline CASCADE;\n",
    "        DROP TABLE IF EXISTS document_evenement CASCADE;\n",
    "        DROP TABLE IF EXISTS evenement CASCADE;\n",
    "        DROP TABLE IF EXISTS theme CASCADE;\n",
    "        DROP TABLE IF EXISTS indicateur CASCADE;\n",
    "        DROP TABLE IF EXISTS source_indicateur CASCADE;\n",
    "        DROP TABLE IF EXISTS type_indicateur CASCADE;\n",
    "        DROP TABLE IF EXISTS meteo CASCADE;\n",
    "        DROP TABLE IF EXISTS type_meteo CASCADE;\n",
    "        DROP TABLE IF EXISTS document CASCADE;\n",
    "        DROP TABLE IF EXISTS territoire CASCADE;\n",
    "        DROP TABLE IF EXISTS flux CASCADE;\n",
    "        DROP TABLE IF EXISTS source CASCADE;\n",
    "        DROP TABLE IF EXISTS type_donnee CASCADE;\n",
    "        \"\"\"\n",
    "        conn.exec_driver_sql(drop_sql)\n",
    "        print(\"‚úÖ Tables supprim√©es\")\n",
    "\n",
    "    # Cr√©er les tables (ex√©cution s√©quentielle pour meilleure gestion d'erreurs)\n",
    "    statements = [s.strip() for s in ddl_sql.split(';') if s.strip() and not s.strip().startswith('--')]\n",
    "    for stmt in statements:\n",
    "        if stmt:\n",
    "            try:\n",
    "                conn.exec_driver_sql(stmt + ';')\n",
    "            except Exception as e:\n",
    "                # Ignorer erreurs \"already exists\" pour IF NOT EXISTS\n",
    "                if 'already exists' not in str(e).lower():\n",
    "                    print(f\"‚ö†Ô∏è Erreur cr√©ation: {stmt[:50]}... ‚Üí {e}\")\n",
    "\n",
    "print(\"‚úÖ Tables E2 cr√©√©es avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Index et contraintes additionnelles\n",
    "\n",
    "Cr√©ation des index pour optimiser les requ√™tes (hash_fingerprint, dates, cl√©s √©trang√®res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index pour performance\n",
    "indexes_sql = \"\"\"\n",
    "-- Index sur hash_fingerprint pour d√©duplication rapide\n",
    "CREATE INDEX IF NOT EXISTS idx_document_hash_fingerprint ON document(hash_fingerprint);\n",
    "\n",
    "-- Index sur dates pour requ√™tes temporelles\n",
    "CREATE INDEX IF NOT EXISTS idx_document_date_publication ON document(date_publication);\n",
    "CREATE INDEX IF NOT EXISTS idx_flux_date_collecte ON flux(date_collecte);\n",
    "CREATE INDEX IF NOT EXISTS idx_meteo_date_obs ON meteo(date_obs);\n",
    "CREATE INDEX IF NOT EXISTS idx_evenement_date_event ON evenement(date_event);\n",
    "\n",
    "-- Index sur cl√©s √©trang√®res fr√©quentes\n",
    "CREATE INDEX IF NOT EXISTS idx_document_id_flux ON document(id_flux);\n",
    "CREATE INDEX IF NOT EXISTS idx_document_id_territoire ON document(id_territoire);\n",
    "CREATE INDEX IF NOT EXISTS idx_flux_id_source ON flux(id_source);\n",
    "CREATE INDEX IF NOT EXISTS idx_meteo_id_territoire ON meteo(id_territoire);\n",
    "CREATE INDEX IF NOT EXISTS idx_indicateur_id_territoire ON indicateur(id_territoire);\n",
    "\n",
    "-- Index composite pour recherche par territoire + date\n",
    "CREATE INDEX IF NOT EXISTS idx_meteo_territoire_date ON meteo(id_territoire, date_obs DESC);\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîó Cr√©ation des index\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.exec_driver_sql(indexes_sql)\n",
    "\n",
    "print(\"‚úÖ Index cr√©√©s avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Insertion des r√©f√©rentiels\n",
    "\n",
    "Insertion des donn√©es de r√©f√©rence n√©cessaires pour normaliser les donn√©es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donn√©es de r√©f√©rence √† ins√©rer\n",
    "referentiels = {\n",
    "    \"type_donnee\": [\n",
    "        (\"Fichier plat\", \"CSV, JSON, Parquet...\"),\n",
    "        (\"Base de donn√©es\", \"SQLite, PostgreSQL, MySQL...\"),\n",
    "        (\"API\", \"REST API, GraphQL...\"),\n",
    "        (\"Web Scraping\", \"HTML scraping, RSS...\"),\n",
    "        (\"Big Data\", \"GDELT, fichiers volumineux...\"),\n",
    "    ],\n",
    "    \"type_meteo\": [\n",
    "        (\"CLEAR\", \"Ciel clair\"),\n",
    "        (\"CLOUDS\", \"Nuageux\"),\n",
    "        (\"RAIN\", \"Pluie\"),\n",
    "        (\"SNOW\", \"Neige\"),\n",
    "        (\"THUNDERSTORM\", \"Orage\"),\n",
    "        (\"FOG\", \"Brouillard\"),\n",
    "    ],\n",
    "    \"type_indicateur\": [\n",
    "        (\"POPULATION\", \"Population totale\", \"habitants\"),\n",
    "        (\"REVENU_MEDIAN\", \"Revenu m√©dian\", \"‚Ç¨\"),\n",
    "        (\"TAUX_CHOMAGE\", \"Taux de ch√¥mage\", \"%\"),\n",
    "        (\"SUPERFICIE\", \"Superficie\", \"km¬≤\"),\n",
    "    ],\n",
    "    \"source_indicateur\": [\n",
    "        (\"INSEE\", \"https://www.insee.fr/\"),\n",
    "        (\"IGN\", \"https://www.ign.fr/\"),\n",
    "        (\"data.gouv.fr\", \"https://www.data.gouv.fr/\"),\n",
    "    ],\n",
    "    \"theme_category\": [\n",
    "        (\"Soci√©t√©\", \"Th√®mes li√©s √† la soci√©t√©\"),\n",
    "        (\"Politique\", \"Th√®mes politiques\"),\n",
    "        (\"√âconomie\", \"Th√®mes √©conomiques\"),\n",
    "        (\"Environnement\", \"Th√®mes environnementaux\"),\n",
    "        (\"Sant√©\", \"Th√®mes de sant√©\"),\n",
    "    ],\n",
    "    \"theme\": [\n",
    "        (\"Politique\", \"√âv√©nements et analyses politiques\"),\n",
    "        (\"√âconomie\", \"Actualit√©s √©conomiques\"),\n",
    "        (\"Soci√©t√©\", \"Faits de soci√©t√©\"),\n",
    "        (\"Environnement\", \"√âcologie, climat, biodiversit√©\"),\n",
    "        (\"Sant√©\", \"Sant√© publique, m√©dical\"),\n",
    "        (\"Sport\", \"√âv√©nements sportifs\"),\n",
    "        (\"Culture\", \"Arts, spectacles, culture\"),\n",
    "        (\"Technologie\", \"Innovation, num√©rique\"),\n",
    "    ],\n",
    "    \"valence\": [\n",
    "        (\"Positive\", \"√âmotions positives (joie, espoir, satisfaction)\"),\n",
    "        (\"Neutre\", \"√âmotions neutres (indiff√©rence, calme)\"),\n",
    "        (\"Negative\", \"√âmotions n√©gatives (col√®re, tristesse, peur)\"),\n",
    "    ],\n",
    "    \"type_emotion\": [\n",
    "        (\"Joie\", \"Sentiment de bonheur\", \"Positive\"),\n",
    "        (\"Col√®re\", \"Sentiment de frustration ou agressivit√©\", \"Negative\"),\n",
    "        (\"Tristesse\", \"Sentiment de peine\", \"Negative\"),\n",
    "        (\"Peur\", \"Sentiment d'anxi√©t√©\", \"Negative\"),\n",
    "        (\"Espoir\", \"Sentiment d'optimisme\", \"Positive\"),\n",
    "        (\"Neutre\", \"Pas d'√©motion particuli√®re\", \"Neutre\"),\n",
    "    ],\n",
    "    \"pays\": [\n",
    "        (\"France\",),\n",
    "    ],\n",
    "    \"source_barometre\": [\n",
    "        (\"INSEE Barom√®tre Social\", \"https://www.insee.fr/\"),\n",
    "        (\"Data.gouv.fr\", \"https://www.data.gouv.fr/\"),\n",
    "    ],\n",
    "    \"qc_rule\": [\n",
    "        (\"No duplicates\", \"V√©rifier absence de doublons via hash_fingerprint\", \"SELECT COUNT(*) FROM document GROUP BY hash_fingerprint HAVING COUNT(*) > 1\"),\n",
    "        (\"No NULL titles\", \"Tous les documents doivent avoir un titre\", \"SELECT COUNT(*) FROM document WHERE titre IS NULL\"),\n",
    "        (\"Date range valid\", \"Les dates de publication doivent √™tre raisonnables\", \"SELECT COUNT(*) FROM document WHERE date_publication < '1900-01-01' OR date_publication > NOW()\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"üìù Insertion des r√©f√©rentiels\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # V√©rifier et corriger la structure de type_donnee si n√©cessaire\n",
    "    try:\n",
    "        # V√©rifier si la colonne description existe\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT column_name\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_name = 'type_donnee' AND column_name = 'description'\n",
    "        \"\"\")).fetchone()\n",
    "\n",
    "        if not result:\n",
    "            # Ajouter la colonne description si elle n'existe pas\n",
    "            print(\"‚ö†Ô∏è Colonne 'description' manquante dans type_donnee, ajout en cours...\")\n",
    "            conn.execute(text(\"ALTER TABLE type_donnee ADD COLUMN IF NOT EXISTS description TEXT\"))\n",
    "            print(\"‚úÖ Colonne 'description' ajout√©e\")\n",
    "\n",
    "        # V√©rifier si la contrainte UNIQUE sur libelle existe\n",
    "        constraint_exists = conn.execute(text(\"\"\"\n",
    "            SELECT 1\n",
    "            FROM information_schema.table_constraints\n",
    "            WHERE table_name = 'type_donnee'\n",
    "              AND constraint_type = 'UNIQUE'\n",
    "              AND constraint_name LIKE '%libelle%'\n",
    "        \"\"\")).fetchone()\n",
    "\n",
    "        if not constraint_exists:\n",
    "            # V√©rifier si un index unique existe\n",
    "            index_exists = conn.execute(text(\"\"\"\n",
    "                SELECT 1\n",
    "                FROM pg_indexes\n",
    "                WHERE tablename = 'type_donnee'\n",
    "                  AND indexdef LIKE '%libelle%'\n",
    "                  AND indexdef LIKE '%UNIQUE%'\n",
    "            \"\"\")).fetchone()\n",
    "\n",
    "            if not index_exists:\n",
    "                print(\"‚ö†Ô∏è Contrainte UNIQUE manquante sur libelle, ajout en cours...\")\n",
    "                conn.execute(text(\"ALTER TABLE type_donnee ADD CONSTRAINT type_donnee_libelle_unique UNIQUE (libelle)\"))\n",
    "                print(\"‚úÖ Contrainte UNIQUE sur libelle ajout√©e\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è V√©rification structure: {e}\")\n",
    "\n",
    "    # type_donnee - Insertion avec gestion robuste des conflits\n",
    "    inserted_count = 0\n",
    "    for libelle, desc in referentiels[\"type_donnee\"]:\n",
    "        try:\n",
    "            # Essayer d'abord avec ON CONFLICT\n",
    "            result = conn.execute(text(\"\"\"\n",
    "                INSERT INTO type_donnee (libelle, description)\n",
    "                VALUES (:libelle, :desc)\n",
    "                ON CONFLICT (libelle) DO NOTHING\n",
    "                RETURNING id_type_donnee\n",
    "            \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "            if result.scalar():\n",
    "                inserted_count += 1\n",
    "        except Exception:\n",
    "            # Si ON CONFLICT √©choue, v√©rifier si l'entr√©e existe d√©j√†\n",
    "            existing = conn.execute(text(\"\"\"\n",
    "                SELECT id_type_donnee\n",
    "                FROM type_donnee\n",
    "                WHERE libelle = :libelle\n",
    "            \"\"\"), {\"libelle\": libelle}).fetchone()\n",
    "            if not existing:\n",
    "                # Si n'existe pas, ins√©rer sans ON CONFLICT\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO type_donnee (libelle, description)\n",
    "                    VALUES (:libelle, :desc)\n",
    "                \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "                inserted_count += 1\n",
    "\n",
    "    print(f\"‚úÖ type_donnee : {inserted_count} entr√©es ins√©r√©es (total: {len(referentiels['type_donnee'])})\")\n",
    "\n",
    "    # type_meteo\n",
    "    for code, libelle in referentiels[\"type_meteo\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO type_meteo (code, libelle)\n",
    "            VALUES (:code, :libelle)\n",
    "            ON CONFLICT (code) DO NOTHING\n",
    "        \"\"\"), {\"code\": code, \"libelle\": libelle})\n",
    "    print(f\"‚úÖ type_meteo : {len(referentiels['type_meteo'])} entr√©es\")\n",
    "\n",
    "    # type_indicateur\n",
    "    for code, libelle, unite in referentiels[\"type_indicateur\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO type_indicateur (code, libelle, unite)\n",
    "            VALUES (:code, :libelle, :unite)\n",
    "            ON CONFLICT (code) DO NOTHING\n",
    "        \"\"\"), {\"code\": code, \"libelle\": libelle, \"unite\": unite})\n",
    "    print(f\"‚úÖ type_indicateur : {len(referentiels['type_indicateur'])} entr√©es\")\n",
    "\n",
    "    # source_indicateur\n",
    "    for nom, url in referentiels[\"source_indicateur\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO source_indicateur (nom, url)\n",
    "            VALUES (:nom, :url)\n",
    "            ON CONFLICT DO NOTHING\n",
    "        \"\"\"), {\"nom\": nom, \"url\": url})\n",
    "    print(f\"‚úÖ source_indicateur : {len(referentiels['source_indicateur'])} entr√©es\")\n",
    "\n",
    "    # theme\n",
    "    for libelle, desc in referentiels[\"theme\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO theme (libelle, description)\n",
    "            VALUES (:libelle, :desc)\n",
    "            ON CONFLICT DO NOTHING\n",
    "        \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "    print(f\"‚úÖ theme : {len(referentiels['theme'])} entr√©es\")\n",
    "\n",
    "    # qc_rule\n",
    "    for nom, desc, expr in referentiels[\"qc_rule\"]:\n",
    "        try:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO qc_rule (nom_regle, description, expression_sql)\n",
    "                VALUES (:nom, :desc, :expr)\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom, \"desc\": desc, \"expr\": expr})\n",
    "        except Exception:\n",
    "            # Si colonne expression_sql n'existe pas (E2), utiliser colonnes E2\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO qc_rule (code, libelle, definition)\n",
    "                VALUES (:nom, :desc, :expr)\n",
    "                ON CONFLICT (code) DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom.lower().replace(' ', '_'), \"desc\": nom, \"expr\": desc})\n",
    "    print(f\"‚úÖ qc_rule : {len(referentiels['qc_rule'])} entr√©es\")\n",
    "\n",
    "    # Nouveaux r√©f√©rentiels E2\n",
    "    if \"valence\" in referentiels:\n",
    "        for label, desc in referentiels[\"valence\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO valence (label, description)\n",
    "                VALUES (:label, :desc)\n",
    "                ON CONFLICT (label) DO NOTHING\n",
    "            \"\"\"), {\"label\": label, \"desc\": desc})\n",
    "        print(f\"‚úÖ valence : {len(referentiels['valence'])} entr√©es\")\n",
    "\n",
    "    if \"type_emotion\" in referentiels:\n",
    "        for libelle, desc, valence_label in referentiels[\"type_emotion\"]:\n",
    "            id_valence = conn.execute(text(\"SELECT id_valence FROM valence WHERE label = :label\"), {\"label\": valence_label}).scalar()\n",
    "            if id_valence:\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO type_emotion (id_valence, libelle, description)\n",
    "                    VALUES (:id_valence, :libelle, :desc)\n",
    "                    ON CONFLICT (libelle) DO NOTHING\n",
    "                \"\"\"), {\"id_valence\": id_valence, \"libelle\": libelle, \"desc\": desc})\n",
    "        print(f\"‚úÖ type_emotion : {len(referentiels['type_emotion'])} entr√©es\")\n",
    "\n",
    "    if \"pays\" in referentiels:\n",
    "        for nom in referentiels[\"pays\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO pays (nom)\n",
    "                VALUES (:nom)\n",
    "                ON CONFLICT (nom) DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom})\n",
    "        print(f\"‚úÖ pays : {len(referentiels['pays'])} entr√©es\")\n",
    "\n",
    "    if \"theme_category\" in referentiels:\n",
    "        for libelle, desc in referentiels[\"theme_category\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO theme_category (libelle, description)\n",
    "                VALUES (:libelle, :desc)\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "        print(f\"‚úÖ theme_category : {len(referentiels['theme_category'])} entr√©es\")\n",
    "\n",
    "    if \"source_barometre\" in referentiels:\n",
    "        for nom, url in referentiels[\"source_barometre\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO source_barometre (nom, url)\n",
    "                VALUES (:nom, :url)\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom, \"url\": url})\n",
    "        print(f\"‚úÖ source_barometre : {len(referentiels['source_barometre'])} entr√©es\")\n",
    "\n",
    "    # theme avec FK vers theme_category\n",
    "    if \"theme\" in referentiels and \"theme_category\" in referentiels:\n",
    "        for libelle, desc in referentiels[\"theme\"]:\n",
    "            # Trouver une cat√©gorie par d√©faut\n",
    "            id_cat = conn.execute(text(\"SELECT id_theme_cat FROM theme_category LIMIT 1\")).scalar()\n",
    "            if id_cat:\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO theme (id_theme_cat, libelle, description)\n",
    "                    VALUES (:id_cat, :libelle, :desc)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                \"\"\"), {\"id_cat\": id_cat, \"libelle\": libelle, \"desc\": desc})\n",
    "        print(f\"‚úÖ theme (E2) : {len(referentiels['theme'])} entr√©es\")\n",
    "\n",
    "print(\"\\n‚úÖ Tous les r√©f√©rentiels ins√©r√©s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Contr√¥les : V√©rification des tables cr√©√©es\n",
    "\n",
    "Liste des tables et comptage des entr√©es par table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"üìä Liste des tables PostgreSQL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Lister toutes les tables\n",
    "query_tables = \"\"\"\n",
    "SELECT table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'public'\n",
    "  AND table_type = 'BASE TABLE'\n",
    "ORDER BY table_name;\n",
    "\"\"\"\n",
    "\n",
    "df_tables = pd.read_sql(query_tables, engine)\n",
    "print(f\"\\n‚úÖ {len(df_tables)} tables cr√©√©es :\\n\")\n",
    "for table in df_tables['table_name']:\n",
    "    print(f\"   ‚Ä¢ {table}\")\n",
    "\n",
    "# Compter les entr√©es par table\n",
    "print(\"\\nüìà Nombre d'entr√©es par table :\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "counts = {}\n",
    "for table in df_tables['table_name']:\n",
    "    try:\n",
    "        count = pd.read_sql(f\"SELECT COUNT(*) as count FROM {table}\", engine).iloc[0]['count']\n",
    "        counts[table] = count\n",
    "    except Exception as e:\n",
    "        counts[table] = f\"Erreur: {e}\"\n",
    "\n",
    "df_counts = pd.DataFrame(list(counts.items()), columns=['Table', 'Count'])\n",
    "print(df_counts.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ Sch√©ma PostgreSQL E2 cr√©√© avec succ√®s !\")\n",
    "print(f\"   üìä {len(df_tables)} tables cr√©√©es\")\n",
    "print(\"\\nüí° **Corrections MPD optionnelles** :\")\n",
    "print(\"   Pour passer √† 40 tables avec tables de liaison N-N, ex√©cutez :\")\n",
    "print(\"   ‚Ä¢ tests/fix_mpd_complete.sql (script ma√Ætre)\")\n",
    "print(\"   ‚Ä¢ Voir tests/README_MPD_FIXES.md pour d√©tails\")\n",
    "print(\"\\n   ‚û°Ô∏è Passez au notebook 03_ingest_sources.ipynb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
