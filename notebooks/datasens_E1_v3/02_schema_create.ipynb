{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSens E1_v3 ‚Äî 02_schema_create\n",
    "\n",
    "- Objectifs: Cr√©er le sch√©ma PostgreSQL complet **36/37 tables** (T01-T36 + T37) selon MPD.sql\n",
    "- Pr√©requis: 01_setup_env ex√©cut√© + PostgreSQL d√©marr√©\n",
    "- Sortie: Sch√©ma complet avec contraintes, index, r√©f√©rentiels + visualisations\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md + docs/datasens_MPD.sql\n",
    "\n",
    "> **E1_v3** : Architecture compl√®te selon MPD.sql (T01-T36 + T37 archive_flux)\n",
    "> - Domaine Collecte : T01-T03 + T37\n",
    "> - Documents & Annotations : T04-T12\n",
    "> - G√©ographie : T13-T17\n",
    "> - M√©t√©o : T18-T19\n",
    "> - Indicateurs/Barom√®tres : T20-T22 + T28-T29\n",
    "> - Th√®mes & √âv√©nements : T23-T27\n",
    "> - Pipeline & Qualit√© : T30-T34\n",
    "> - Audit/Versionning : T35-T36\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes:\n",
    "> - **Chargement depuis docs/datasens_MPD.sql** : DDL complet avec toutes les contraintes\n",
    "> - **Pr√©fixe T01-T37** : Nomenclature selon MPD (t01_type_donnee, t02_source, etc.)\n",
    "> - **Bootstrap r√©f√©rentiels** : type_donnee (5 types), valence (3), pays (France)\n",
    "> - **Visualisations** : Graphique r√©partition par domaine + tables pandas pour le jury\n",
    "> - **R√©f√©rences** : docs/datasens_MPD.sql, docs/datasens_tables_dictionary.md\n",
    "- `pays`, `region`, `departement`, `commune`, `territoire`\n",
    "\n",
    "**Contexte** (5 tables) :\n",
    "- `type_meteo`, `meteo`, `type_indicateur`, `source_indicateur`, `indicateur`\n",
    "\n",
    "**Th√®mes & √âv√©nements** (5 tables) :\n",
    "- `theme_category`, `theme`, `evenement`, `document_theme`, `document_evenement`\n",
    "\n",
    "**Barom√®tres** (2 tables) :\n",
    "- `source_barometre`, `document_baro`\n",
    "\n",
    "**Pipeline & Qualit√©** (5 tables) :\n",
    "- `pipeline`, `etape_etl`, `exec_etape`, `qc_rule`, `qc_result`\n",
    "\n",
    "**Gouvernance** (2 tables) :\n",
    "- `table_audit`, `table_version`\n",
    "\n",
    "**Collecte** :\n",
    "- `type_donnee` : Cat√©gorisation des sources (Fichier, Base de donn√©es, API, Web Scraping, Big Data)\n",
    "- `source` : Sources r√©elles (Kaggle, OpenWeatherMap, MonAvisCitoyen, etc.)\n",
    "- `flux` : Tra√ßabilit√© des collectes (date, format, manifest_uri)\n",
    "\n",
    "**Corpus** :\n",
    "- `document` : Documents bruts collect√©s (titre, texte, langue, hash_fingerprint)\n",
    "- `territoire` : G√©olocalisation (ville, code_insee, lat, lon)\n",
    "\n",
    "**Contexte** :\n",
    "- `type_meteo` : Types de conditions m√©t√©o (clair, nuageux, pluie...)\n",
    "- `meteo` : Relev√©s m√©t√©o (temp√©rature, humidit√©, pression, vent)\n",
    "- `type_indicateur` : Types d'indicateurs (population, revenu, etc.)\n",
    "- `source_indicateur` : Sources des indicateurs (INSEE, IGN...)\n",
    "- `indicateur` : Valeurs d'indicateurs par territoire\n",
    "\n",
    "**Th√®mes/√©v√©nements** :\n",
    "- `theme` : Th√®mes documentaires (politique, √©conomie, environnement...)\n",
    "- `evenement` : √âv√©nements temporels (date_event, avg_tone)\n",
    "- `document_evenement` : Relation N-N documents ‚Üî √©v√©nements\n",
    "\n",
    "**Gouvernance pipeline** :\n",
    "- `pipeline` : Description des pipelines ETL\n",
    "- `etape_etl` : √âtapes du pipeline avec ordre d'ex√©cution\n",
    "\n",
    "**Utilisateurs (trace)** :\n",
    "- `utilisateur` : Utilisateurs du syst√®me (pour futures annotations)\n",
    "\n",
    "**Qualit√© (min)** :\n",
    "- `qc_rule` : R√®gles de contr√¥le qualit√© (placeholder)\n",
    "- `qc_result` : R√©sultats des contr√¥les qualit√© (optionnel)\n",
    "\n",
    "---\n",
    "\n",
    "### Sch√©ma Mermaid (simplifi√©)\n",
    "\n",
    "```mermaid\n",
    "erDiagram\n",
    "    TYPE_DONNEE ||--o{ SOURCE : \"a pour\"\n",
    "    SOURCE ||--o{ FLUX : \"g√©n√®re\"\n",
    "    FLUX ||--o{ DOCUMENT : \"contient\"\n",
    "    TERRITOIRE ||--o{ DOCUMENT : \"g√©olocalise\"\n",
    "    TERRITOIRE ||--o{ METEO : \"mesure\"\n",
    "    TERRITOIRE ||--o{ INDICATEUR : \"agr√®ge\"\n",
    "    THEME ||--o{ EVENEMENT : \"classe\"\n",
    "    DOCUMENT ||--o{ DOCUMENT_EVENEMENT : \"ref√®re\"\n",
    "    EVENEMENT ||--o{ DOCUMENT_EVENEMENT : \"associe\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSens E1_v3 - 02_schema_create\n",
    "# üíæ Sch√©ma PostgreSQL complet 36/37 tables selon MPD.sql + Bootstrap + Visualisations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Utiliser les variables du notebook 01\n",
    "if 'PROJECT_ROOT' not in globals():\n",
    "    current = Path.cwd()\n",
    "    PROJECT_ROOT = None\n",
    "    while current != current.parent:\n",
    "        if (current / \"notebooks\").exists() and (current / \"docs\").exists():\n",
    "            PROJECT_ROOT = current\n",
    "            break\n",
    "        current = current.parent\n",
    "    else:\n",
    "        PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "if 'PG_URL' not in globals():\n",
    "    PG_URL = os.getenv(\"DATASENS_PG_URL\", \"postgresql+psycopg2://postgres:postgres@localhost:5433/postgres\")\n",
    "\n",
    "engine = create_engine(PG_URL, future=True)\n",
    "print(f\"üìÇ Connexion PostgreSQL : {engine.url.host}:{engine.url.port}/{engine.url.database}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê DDL PostgreSQL : Cr√©ation des 36 tables E2\n",
    "\n",
    "Cr√©ation des tables avec contraintes d'int√©grit√© r√©f√©rentielle.  \n",
    "**Ordre de cr√©ation** : Respect des d√©pendances FK (r√©f√©rentiels ‚Üí m√©tier ‚Üí liaisons).\n",
    "\n",
    "**Note** : Les sources obsol√®tes/payantes ne sont **pas** impl√©ment√©es.  \n",
    "**Sources E1 test√©es** : Kaggle CSV, OpenWeatherMap API, RSS Multi-sources, Web Scraping (Vie-publique, data.gouv), GDELT GKG  \n",
    "**Voir** `docs/SOURCES_STATUS.md` pour statut complet des sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDL complet : 36/37 tables E1_v3\n",
    "# Bas√© sur MCD/MLD/MPD valid√©s - Ordre respecte d√©pendances FK\n",
    "# Chargement depuis docs/datasens_MPD.sql (architecture compl√®te)\n",
    "\n",
    "ddl_file = PROJECT_ROOT / \"docs\" / \"datasens_MPD.sql\"\n",
    "\n",
    "if ddl_file.exists():\n",
    "    with open(ddl_file, encoding='utf-8') as f:\n",
    "        ddl_sql = f.read()\n",
    "    print(f\"‚úÖ DDL charg√© depuis {ddl_file.name}\")\n",
    "    print(f\"   üìÑ Fichier : {ddl_file}\")\n",
    "else:\n",
    "    print(f\"‚ùå Fichier DDL non trouv√©: {ddl_file}\")\n",
    "    print(\"   üí° V√©rifiez que docs/datasens_MPD.sql existe\")\n",
    "    raise FileNotFoundError(f\"MPD.sql introuvable : {ddl_file}\")\n",
    "\n",
    "print(\"\\n‚úÖ DDL charg√© depuis MPD.sql - Pr√™t pour cr√©ation des 36/37 tables\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Option : Supprimer toutes les tables existantes avant de les recr√©er\n",
    "DROP_TABLES = os.getenv(\"DROP_TABLES\", \"false\").lower() == \"true\"  # S√©curit√© : false par d√©faut\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    if DROP_TABLES:\n",
    "        print(\"‚ö†Ô∏è Suppression des tables existantes...\")\n",
    "        # Supprimer toutes les tables selon MPD (ordre inverse des d√©pendances)\n",
    "        drop_order = [\n",
    "            \"t34_qc_result\", \"t33_qc_rule\", \"t32_exec_etape\", \"t31_etape_etl\", \"t30_pipeline\",\n",
    "            \"t29_document_baro\", \"t28_source_barometre\",\n",
    "            \"t27_document_evenement\", \"t26_document_theme\", \"t25_evenement\", \"t24_theme\", \"t23_theme_category\",\n",
    "            \"t22_indicateur\", \"t21_source_indicateur\", \"t20_type_indicateur\",\n",
    "            \"t19_meteo\", \"t18_type_meteo\",\n",
    "            \"t17_territoire\", \"t16_commune\", \"t15_departement\", \"t14_region\", \"t13_pays\",\n",
    "            \"t07_meta_annotation\", \"t06_annotation_emotion\", \"t05_annotation\", \"t08_emotion\", \"t09_type_emotion\", \n",
    "            \"t10_valence\", \"t11_modele_ia\", \"t12_utilisateur\",\n",
    "            \"t04_document\",\n",
    "            \"t37_archive_flux\", \"t03_flux\", \"t02_source\", \"t01_type_donnee\",\n",
    "            \"t36_table_version\", \"t35_table_audit\"\n",
    "        ]\n",
    "        for table in drop_order:\n",
    "            try:\n",
    "                conn.execute(text(f\"DROP TABLE IF EXISTS datasens.{table} CASCADE\"))\n",
    "                conn.execute(text(f\"DROP TABLE IF EXISTS {table} CASCADE\"))\n",
    "            except:\n",
    "                pass\n",
    "        # Supprimer le type enum\n",
    "        conn.execute(text(\"DROP TYPE IF EXISTS polarity_enum CASCADE\"))\n",
    "        print(\"‚úÖ Tables supprim√©es\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è DROP_TABLES=false ‚Üí Tables existantes conserv√©es (utiliser IF NOT EXISTS)\")\n",
    "\n",
    "    # Cr√©er le sch√©ma datasens si n√©cessaire\n",
    "    conn.execute(text(\"CREATE SCHEMA IF NOT EXISTS datasens\"))\n",
    "    conn.execute(text(\"SET search_path TO datasens, public\"))\n",
    "    \n",
    "    # Ex√©cuter le DDL complet depuis MPD.sql\n",
    "    # Le MPD.sql contient d√©j√† les CREATE TABLE avec IF NOT EXISTS, donc on peut l'ex√©cuter directement\n",
    "    # S√©parer les statements (en ignorant les commentaires et lignes vides)\n",
    "    statements = []\n",
    "    current_stmt = []\n",
    "    \n",
    "    for line in ddl_sql.split('\\n'):\n",
    "        line_stripped = line.strip()\n",
    "        # Ignorer commentaires et lignes vides\n",
    "        if not line_stripped or line_stripped.startswith('--'):\n",
    "            continue\n",
    "        current_stmt.append(line)\n",
    "        # Si la ligne se termine par ';', c'est la fin d'un statement\n",
    "        if line_stripped.endswith(';'):\n",
    "            stmt = '\\n'.join(current_stmt)\n",
    "            if stmt.strip():\n",
    "                statements.append(stmt)\n",
    "            current_stmt = []\n",
    "    \n",
    "    # Si on a encore du texte dans current_stmt, l'ajouter\n",
    "    if current_stmt:\n",
    "        stmt = '\\n'.join(current_stmt)\n",
    "        if stmt.strip():\n",
    "            statements.append(stmt)\n",
    "    \n",
    "    # Ex√©cuter chaque statement\n",
    "    created_tables = 0\n",
    "    for i, stmt in enumerate(statements, 1):\n",
    "        try:\n",
    "            conn.execute(text(stmt))\n",
    "            # Compter les CREATE TABLE\n",
    "            if 'CREATE TABLE' in stmt.upper():\n",
    "                created_tables += 1\n",
    "        except Exception as e:\n",
    "            # Ignorer erreurs \"already exists\" pour IF NOT EXISTS\n",
    "            if 'already exists' not in str(e).lower() and 'duplicate' not in str(e).lower():\n",
    "                print(f\"‚ö†Ô∏è Erreur statement {i}: {str(e)[:100]}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Sch√©ma E1_v3 cr√©√© : {created_tables} tables cr√©√©es\")\n",
    "print(\"   üìä Architecture compl√®te selon MPD.sql (T01-T36 + T37)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Index et contraintes additionnelles\n",
    "\n",
    "Cr√©ation des index pour optimiser les requ√™tes (hash_fingerprint, dates, cl√©s √©trang√®res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index pour performance\n",
    "indexes_sql = \"\"\"\n",
    "-- Index sur hash_fingerprint pour d√©duplication rapide\n",
    "CREATE INDEX IF NOT EXISTS idx_document_hash_fingerprint ON document(hash_fingerprint);\n",
    "\n",
    "-- Index sur dates pour requ√™tes temporelles\n",
    "CREATE INDEX IF NOT EXISTS idx_document_date_publication ON document(date_publication);\n",
    "CREATE INDEX IF NOT EXISTS idx_flux_date_collecte ON flux(date_collecte);\n",
    "CREATE INDEX IF NOT EXISTS idx_meteo_date_obs ON meteo(date_obs);\n",
    "CREATE INDEX IF NOT EXISTS idx_evenement_date_event ON evenement(date_event);\n",
    "\n",
    "-- Index sur cl√©s √©trang√®res fr√©quentes\n",
    "CREATE INDEX IF NOT EXISTS idx_document_id_flux ON document(id_flux);\n",
    "CREATE INDEX IF NOT EXISTS idx_document_id_territoire ON document(id_territoire);\n",
    "CREATE INDEX IF NOT EXISTS idx_flux_id_source ON flux(id_source);\n",
    "CREATE INDEX IF NOT EXISTS idx_meteo_id_territoire ON meteo(id_territoire);\n",
    "CREATE INDEX IF NOT EXISTS idx_indicateur_id_territoire ON indicateur(id_territoire);\n",
    "\n",
    "-- Index composite pour recherche par territoire + date\n",
    "CREATE INDEX IF NOT EXISTS idx_meteo_territoire_date ON meteo(id_territoire, date_obs DESC);\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîó Cr√©ation des index\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.exec_driver_sql(indexes_sql)\n",
    "\n",
    "print(\"‚úÖ Index cr√©√©s avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Insertion des r√©f√©rentiels\n",
    "\n",
    "Insertion des donn√©es de r√©f√©rence n√©cessaires pour normaliser les donn√©es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù Bootstrap des r√©f√©rentiels selon MPD.sql\n",
    "# Le MPD.sql contient d√©j√† des INSERT dans la section 9, mais on les ex√©cute ici pour s'assurer\n",
    "\n",
    "print(\"üìù Bootstrap des r√©f√©rentiels\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # V√©rifier et ins√©rer les r√©f√©rentiels de base selon MPD.sql\n",
    "    # T10_VALENCE (d√©j√† dans MPD.sql mais on v√©rifie)\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO t10_valence (label, description)\n",
    "        VALUES ('positive','valence positive'), ('neutre','valence neutre'), ('negative','valence n√©gative')\n",
    "        ON CONFLICT (label) DO NOTHING\n",
    "    \"\"\"))\n",
    "    \n",
    "    # T01_TYPE_DONNEE (selon MPD.sql section 9) - Classification professionnelle m√©diam√©trie\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO t01_type_donnee (libelle, description, frequence_maj, categorie_metier)\n",
    "        VALUES\n",
    "          -- 1. Donn√©es de classification ou Nomenclatures (Reference Data)\n",
    "          ('Nomenclature','Syst√®me de cat√©gorisation/classification servant de r√©f√©rence aux autres donn√©es (unit√©s de mesure, codes pays ISO, CSP...)','mensuelle','classification'),\n",
    "          -- 2. Donn√©es de r√©f√©rences ou donn√©es ma√Ætres (Master Data)\n",
    "          ('Donn√©es Ma√Ætres','Donn√©es partag√©es par un ensemble de processus et d''applications (clients, produits, r√©f√©rentiels...)','quotidienne','reference'),\n",
    "          -- 3. Donn√©es op√©rationnelles (Operational Data)\n",
    "          ('Donn√©es Op√©rationnelles','Donn√©es li√©es √† des op√©rations et activit√©s (transactions, demandes, tickets...)','secondes','operationnelle'),\n",
    "          -- 4. Donn√©es d√©cisionnelles (Analytical Data)\n",
    "          ('Donn√©es D√©cisionnelles','Donn√©es consolid√©es permettant de faire des analyses √† des fins de prise de d√©cisions (faits de vente, dimensions...)','quotidienne','decisionnelle'),\n",
    "          -- 5. M√©tadonn√©es (Metadata)\n",
    "          ('M√©tadonn√©es','Donn√©es sur les donn√©es (descriptives, structurelles, administratives, usages, r√©f√©rence, statistiques, l√©gales...)','variable','metadonnees')\n",
    "        ON CONFLICT DO NOTHING\n",
    "    \"\"\"))\n",
    "    \n",
    "    # T13_PAYS (France)\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO t13_pays (nom) VALUES ('France') ON CONFLICT DO NOTHING\n",
    "    \"\"\"))\n",
    "    \n",
    "    # V√©rifier les entr√©es ins√©r√©es\n",
    "    nb_valence = conn.execute(text(\"SELECT COUNT(*) FROM t10_valence\")).scalar()\n",
    "    nb_types = conn.execute(text(\"SELECT COUNT(*) FROM t01_type_donnee\")).scalar()\n",
    "    nb_pays = conn.execute(text(\"SELECT COUNT(*) FROM t13_pays\")).scalar()\n",
    "    \n",
    "    print(f\"‚úÖ Bootstrap r√©f√©rentiels :\")\n",
    "    print(f\"   ‚Ä¢ T10_valence : {nb_valence} entr√©es\")\n",
    "    print(f\"   ‚Ä¢ T01_type_donnee : {nb_types} entr√©es\")\n",
    "    print(f\"   ‚Ä¢ T13_pays : {nb_pays} entr√©es\")\n",
    "    \n",
    "    # Afficher le contenu des r√©f√©rentiels\n",
    "    print(\"\\nüìã Table t01_type_donnee :\")\n",
    "    df_type_donnee = pd.read_sql_query(\"SELECT * FROM t01_type_donnee\", engine)\n",
    "    display(df_type_donnee)\n",
    "    \n",
    "    print(\"\\nüìã Table t10_valence :\")\n",
    "    df_valence = pd.read_sql_query(\"SELECT * FROM t10_valence\", engine)\n",
    "    display(df_valence)\n",
    "\n",
    "print(\"\\n‚úÖ Bootstrap des r√©f√©rentiels termin√© !\")\n",
    "\n",
    "# Ancien code de r√©f√©rentiels (gard√© pour r√©f√©rence si besoin d'enrichissement)\n",
    "referentiels_old = {\n",
    "    \"type_donnee\": [\n",
    "        (\"Nomenclature\", \"Syst√®me de cat√©gorisation/classification servant de r√©f√©rence\"),\n",
    "        (\"Donn√©es Ma√Ætres\", \"Donn√©es partag√©es par un ensemble de processus et d'applications\"),\n",
    "        (\"Donn√©es Op√©rationnelles\", \"Donn√©es li√©es √† des op√©rations et activit√©s\"),\n",
    "        (\"Donn√©es D√©cisionnelles\", \"Donn√©es consolid√©es pour analyses et prise de d√©cisions\"),\n",
    "        (\"M√©tadonn√©es\", \"Donn√©es sur les donn√©es (descriptives, structurelles, administratives...)\"),\n",
    "    ],\n",
    "    \"type_meteo\": [\n",
    "        (\"CLEAR\", \"Ciel clair\"),\n",
    "        (\"CLOUDS\", \"Nuageux\"),\n",
    "        (\"RAIN\", \"Pluie\"),\n",
    "        (\"SNOW\", \"Neige\"),\n",
    "        (\"THUNDERSTORM\", \"Orage\"),\n",
    "        (\"FOG\", \"Brouillard\"),\n",
    "    ],\n",
    "    \"type_indicateur\": [\n",
    "        (\"POPULATION\", \"Population totale\", \"habitants\"),\n",
    "        (\"REVENU_MEDIAN\", \"Revenu m√©dian\", \"‚Ç¨\"),\n",
    "        (\"TAUX_CHOMAGE\", \"Taux de ch√¥mage\", \"%\"),\n",
    "        (\"SUPERFICIE\", \"Superficie\", \"km¬≤\"),\n",
    "    ],\n",
    "    \"source_indicateur\": [\n",
    "        (\"INSEE\", \"https://www.insee.fr/\"),\n",
    "        (\"IGN\", \"https://www.ign.fr/\"),\n",
    "        (\"data.gouv.fr\", \"https://www.data.gouv.fr/\"),\n",
    "    ],\n",
    "    \"theme_category\": [\n",
    "        (\"Soci√©t√©\", \"Th√®mes li√©s √† la soci√©t√©\"),\n",
    "        (\"Politique\", \"Th√®mes politiques\"),\n",
    "        (\"√âconomie\", \"Th√®mes √©conomiques\"),\n",
    "        (\"Environnement\", \"Th√®mes environnementaux\"),\n",
    "        (\"Sant√©\", \"Th√®mes de sant√©\"),\n",
    "    ],\n",
    "    \"theme\": [\n",
    "        (\"Politique\", \"√âv√©nements et analyses politiques\"),\n",
    "        (\"√âconomie\", \"Actualit√©s √©conomiques\"),\n",
    "        (\"Soci√©t√©\", \"Faits de soci√©t√©\"),\n",
    "        (\"Environnement\", \"√âcologie, climat, biodiversit√©\"),\n",
    "        (\"Sant√©\", \"Sant√© publique, m√©dical\"),\n",
    "        (\"Sport\", \"√âv√©nements sportifs\"),\n",
    "        (\"Culture\", \"Arts, spectacles, culture\"),\n",
    "        (\"Technologie\", \"Innovation, num√©rique\"),\n",
    "    ],\n",
    "    \"valence\": [\n",
    "        (\"Positive\", \"√âmotions positives (joie, espoir, satisfaction)\"),\n",
    "        (\"Neutre\", \"√âmotions neutres (indiff√©rence, calme)\"),\n",
    "        (\"Negative\", \"√âmotions n√©gatives (col√®re, tristesse, peur)\"),\n",
    "    ],\n",
    "    \"type_emotion\": [\n",
    "        (\"Joie\", \"Sentiment de bonheur\", \"Positive\"),\n",
    "        (\"Col√®re\", \"Sentiment de frustration ou agressivit√©\", \"Negative\"),\n",
    "        (\"Tristesse\", \"Sentiment de peine\", \"Negative\"),\n",
    "        (\"Peur\", \"Sentiment d'anxi√©t√©\", \"Negative\"),\n",
    "        (\"Espoir\", \"Sentiment d'optimisme\", \"Positive\"),\n",
    "        (\"Neutre\", \"Pas d'√©motion particuli√®re\", \"Neutre\"),\n",
    "    ],\n",
    "    \"pays\": [\n",
    "        (\"France\",),\n",
    "    ],\n",
    "    \"source_barometre\": [\n",
    "        (\"INSEE Barom√®tre Social\", \"https://www.insee.fr/\"),\n",
    "        (\"Data.gouv.fr\", \"https://www.data.gouv.fr/\"),\n",
    "    ],\n",
    "    \"qc_rule\": [\n",
    "        (\"No duplicates\", \"V√©rifier absence de doublons via hash_fingerprint\", \"SELECT COUNT(*) FROM document GROUP BY hash_fingerprint HAVING COUNT(*) > 1\"),\n",
    "        (\"No NULL titles\", \"Tous les documents doivent avoir un titre\", \"SELECT COUNT(*) FROM document WHERE titre IS NULL\"),\n",
    "        (\"Date range valid\", \"Les dates de publication doivent √™tre raisonnables\", \"SELECT COUNT(*) FROM document WHERE date_publication < '1900-01-01' OR date_publication > NOW()\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"üìù Insertion des r√©f√©rentiels\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # V√©rifier et corriger la structure de type_donnee si n√©cessaire\n",
    "    try:\n",
    "        # V√©rifier si la colonne description existe\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT column_name\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_name = 'type_donnee' AND column_name = 'description'\n",
    "        \"\"\")).fetchone()\n",
    "\n",
    "        if not result:\n",
    "            # Ajouter la colonne description si elle n'existe pas\n",
    "            print(\"‚ö†Ô∏è Colonne 'description' manquante dans type_donnee, ajout en cours...\")\n",
    "            conn.execute(text(\"ALTER TABLE type_donnee ADD COLUMN IF NOT EXISTS description TEXT\"))\n",
    "            print(\"‚úÖ Colonne 'description' ajout√©e\")\n",
    "\n",
    "        # V√©rifier si la contrainte UNIQUE sur libelle existe\n",
    "        constraint_exists = conn.execute(text(\"\"\"\n",
    "            SELECT 1\n",
    "            FROM information_schema.table_constraints\n",
    "            WHERE table_name = 'type_donnee'\n",
    "              AND constraint_type = 'UNIQUE'\n",
    "              AND constraint_name LIKE '%libelle%'\n",
    "        \"\"\")).fetchone()\n",
    "\n",
    "        if not constraint_exists:\n",
    "            # V√©rifier si un index unique existe\n",
    "            index_exists = conn.execute(text(\"\"\"\n",
    "                SELECT 1\n",
    "                FROM pg_indexes\n",
    "                WHERE tablename = 'type_donnee'\n",
    "                  AND indexdef LIKE '%libelle%'\n",
    "                  AND indexdef LIKE '%UNIQUE%'\n",
    "            \"\"\")).fetchone()\n",
    "\n",
    "            if not index_exists:\n",
    "                print(\"‚ö†Ô∏è Contrainte UNIQUE manquante sur libelle, ajout en cours...\")\n",
    "                conn.execute(text(\"ALTER TABLE type_donnee ADD CONSTRAINT type_donnee_libelle_unique UNIQUE (libelle)\"))\n",
    "                print(\"‚úÖ Contrainte UNIQUE sur libelle ajout√©e\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è V√©rification structure: {e}\")\n",
    "\n",
    "    # type_donnee - Insertion avec gestion robuste des conflits\n",
    "    inserted_count = 0\n",
    "    for libelle, desc in referentiels[\"type_donnee\"]:\n",
    "        try:\n",
    "            # Essayer d'abord avec ON CONFLICT\n",
    "            result = conn.execute(text(\"\"\"\n",
    "                INSERT INTO type_donnee (libelle, description)\n",
    "                VALUES (:libelle, :desc)\n",
    "                ON CONFLICT (libelle) DO NOTHING\n",
    "                RETURNING id_type_donnee\n",
    "            \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "            if result.scalar():\n",
    "                inserted_count += 1\n",
    "        except Exception:\n",
    "            # Si ON CONFLICT √©choue, v√©rifier si l'entr√©e existe d√©j√†\n",
    "            existing = conn.execute(text(\"\"\"\n",
    "                SELECT id_type_donnee\n",
    "                FROM type_donnee\n",
    "                WHERE libelle = :libelle\n",
    "            \"\"\"), {\"libelle\": libelle}).fetchone()\n",
    "            if not existing:\n",
    "                # Si n'existe pas, ins√©rer sans ON CONFLICT\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO type_donnee (libelle, description)\n",
    "                    VALUES (:libelle, :desc)\n",
    "                \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "                inserted_count += 1\n",
    "\n",
    "    print(f\"‚úÖ type_donnee : {inserted_count} entr√©es ins√©r√©es (total: {len(referentiels['type_donnee'])})\")\n",
    "\n",
    "    # type_meteo\n",
    "    for code, libelle in referentiels[\"type_meteo\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO type_meteo (code, libelle)\n",
    "            VALUES (:code, :libelle)\n",
    "            ON CONFLICT (code) DO NOTHING\n",
    "        \"\"\"), {\"code\": code, \"libelle\": libelle})\n",
    "    print(f\"‚úÖ type_meteo : {len(referentiels['type_meteo'])} entr√©es\")\n",
    "\n",
    "    # type_indicateur\n",
    "    for code, libelle, unite in referentiels[\"type_indicateur\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO type_indicateur (code, libelle, unite)\n",
    "            VALUES (:code, :libelle, :unite)\n",
    "            ON CONFLICT (code) DO NOTHING\n",
    "        \"\"\"), {\"code\": code, \"libelle\": libelle, \"unite\": unite})\n",
    "    print(f\"‚úÖ type_indicateur : {len(referentiels['type_indicateur'])} entr√©es\")\n",
    "\n",
    "    # source_indicateur\n",
    "    for nom, url in referentiels[\"source_indicateur\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO source_indicateur (nom, url)\n",
    "            VALUES (:nom, :url)\n",
    "            ON CONFLICT DO NOTHING\n",
    "        \"\"\"), {\"nom\": nom, \"url\": url})\n",
    "    print(f\"‚úÖ source_indicateur : {len(referentiels['source_indicateur'])} entr√©es\")\n",
    "\n",
    "    # theme\n",
    "    for libelle, desc in referentiels[\"theme\"]:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO theme (libelle, description)\n",
    "            VALUES (:libelle, :desc)\n",
    "            ON CONFLICT DO NOTHING\n",
    "        \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "    print(f\"‚úÖ theme : {len(referentiels['theme'])} entr√©es\")\n",
    "\n",
    "    # qc_rule\n",
    "    for nom, desc, expr in referentiels[\"qc_rule\"]:\n",
    "        try:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO qc_rule (nom_regle, description, expression_sql)\n",
    "                VALUES (:nom, :desc, :expr)\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom, \"desc\": desc, \"expr\": expr})\n",
    "        except Exception:\n",
    "            # Si colonne expression_sql n'existe pas (E2), utiliser colonnes E2\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO qc_rule (code, libelle, definition)\n",
    "                VALUES (:nom, :desc, :expr)\n",
    "                ON CONFLICT (code) DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom.lower().replace(' ', '_'), \"desc\": nom, \"expr\": desc})\n",
    "    print(f\"‚úÖ qc_rule : {len(referentiels['qc_rule'])} entr√©es\")\n",
    "\n",
    "    # Nouveaux r√©f√©rentiels E2\n",
    "    if \"valence\" in referentiels:\n",
    "        for label, desc in referentiels[\"valence\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO valence (label, description)\n",
    "                VALUES (:label, :desc)\n",
    "                ON CONFLICT (label) DO NOTHING\n",
    "            \"\"\"), {\"label\": label, \"desc\": desc})\n",
    "        print(f\"‚úÖ valence : {len(referentiels['valence'])} entr√©es\")\n",
    "\n",
    "    if \"type_emotion\" in referentiels:\n",
    "        for libelle, desc, valence_label in referentiels[\"type_emotion\"]:\n",
    "            id_valence = conn.execute(text(\"SELECT id_valence FROM valence WHERE label = :label\"), {\"label\": valence_label}).scalar()\n",
    "            if id_valence:\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO type_emotion (id_valence, libelle, description)\n",
    "                    VALUES (:id_valence, :libelle, :desc)\n",
    "                    ON CONFLICT (libelle) DO NOTHING\n",
    "                \"\"\"), {\"id_valence\": id_valence, \"libelle\": libelle, \"desc\": desc})\n",
    "        print(f\"‚úÖ type_emotion : {len(referentiels['type_emotion'])} entr√©es\")\n",
    "\n",
    "    if \"pays\" in referentiels:\n",
    "        for nom in referentiels[\"pays\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO pays (nom)\n",
    "                VALUES (:nom)\n",
    "                ON CONFLICT (nom) DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom})\n",
    "        print(f\"‚úÖ pays : {len(referentiels['pays'])} entr√©es\")\n",
    "\n",
    "    if \"theme_category\" in referentiels:\n",
    "        for libelle, desc in referentiels[\"theme_category\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO t23_theme_category (libelle, description)\n",
    "                VALUES (:libelle, :desc)\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\"), {\"libelle\": libelle, \"desc\": desc})\n",
    "        print(f\"‚úÖ theme_category (E1_v3) : {len(referentiels['theme_category'])} cat√©gories ins√©r√©es\")\n",
    "\n",
    "    if \"source_barometre\" in referentiels:\n",
    "        for nom, url in referentiels[\"source_barometre\"]:\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO source_barometre (nom, url)\n",
    "                VALUES (:nom, :url)\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\"), {\"nom\": nom, \"url\": url})\n",
    "        print(f\"‚úÖ source_barometre : {len(referentiels['source_barometre'])} entr√©es\")\n",
    "\n",
    "    # theme avec FK vers theme_category (mapping selon datasens_barometer_themes.md)\n",
    "    if \"theme\" in referentiels and \"theme_category\" in referentiels:\n",
    "        # Mapping des th√®mes vers leurs cat√©gories\n",
    "        theme_to_category = {\n",
    "            \"Confiance institutionnelle\": \"Soci√©t√© & Confiance\",\n",
    "            \"Pouvoir d'achat\": \"√âconomie & Pouvoir d'achat\",\n",
    "            \"Changement climatique\": \"√âcologie & Climat\",\n",
    "            \"Sant√© mentale\": \"Sant√© & Bien-√™tre\",\n",
    "            \"Diversit√© et √©galit√©\": \"Inclusion & √âgalit√©\",\n",
    "            \"Intelligence artificielle\": \"Innovation & Num√©rique\",\n",
    "            \"Jeux Olympiques 2024\": \"Sport & Coh√©sion\",\n",
    "            \"M√©dias et information\": \"Culture & Identit√©\",\n",
    "            \"March√© du travail\": \"Travail & Formation\",\n",
    "            \"Syst√®me √©ducatif\": \"Jeunesse & √âducation\",\n",
    "            \"Engagement associatif\": \"Solidarit√© & Engagement\",\n",
    "            \"Tensions politiques\": \"Politique & Gouvernance\",\n",
    "        }\n",
    "        \n",
    "        for libelle, desc in referentiels[\"theme\"]:\n",
    "            # Trouver la cat√©gorie correspondante\n",
    "            cat_libelle = theme_to_category.get(libelle, \"Soci√©t√© & Confiance\")  # D√©faut si non trouv√©\n",
    "            id_cat = conn.execute(text(\"\"\"\n",
    "                SELECT id_theme_cat FROM t23_theme_category WHERE libelle = :libelle\n",
    "            \"\"\"), {\"libelle\": cat_libelle}).scalar()\n",
    "            \n",
    "            if id_cat:\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO t24_theme (id_theme_cat, libelle, description)\n",
    "                    VALUES (:id_cat, :libelle, :desc)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                \"\"\"), {\"id_cat\": id_cat, \"libelle\": libelle, \"desc\": desc})\n",
    "        print(f\"‚úÖ theme (E1_v3) : {len(referentiels['theme'])} entr√©es avec mapping cat√©gories\")\n",
    "\n",
    "print(\"\\n‚úÖ Tous les r√©f√©rentiels ins√©r√©s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Contr√¥les : V√©rification des tables cr√©√©es\n",
    "\n",
    "Liste des tables et comptage des entr√©es par table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualisations : R√©partition des tables par domaine + Tables pandas\n",
    "\n",
    "print(\"\\nüìä LISTE DES TABLES E1_V3 (36/37 tables)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Lister toutes les tables (sch√©ma datasens + public)\n",
    "query_tables = \"\"\"\n",
    "SELECT \n",
    "    table_schema,\n",
    "    table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_type = 'BASE TABLE'\n",
    "  AND (table_schema = 'datasens' OR table_schema = 'public')\n",
    "  AND table_name LIKE 't%'\n",
    "ORDER BY table_name;\n",
    "\"\"\"\n",
    "\n",
    "df_tables = pd.read_sql(query_tables, engine)\n",
    "print(f\"\\n‚úÖ {len(df_tables)} tables d√©tect√©es :\\n\")\n",
    "\n",
    "# Afficher le DataFrame\n",
    "display(df_tables)\n",
    "\n",
    "# R√©partition par domaine (selon MPD)\n",
    "domaines = {\n",
    "    \"Collecte\": [\"t01_type_donnee\", \"t02_source\", \"t03_flux\", \"t37_archive_flux\"],\n",
    "    \"Documents & Annotations\": [\"t04_document\", \"t05_annotation\", \"t06_annotation_emotion\", \"t07_meta_annotation\", \n",
    "                                 \"t08_emotion\", \"t09_type_emotion\", \"t10_valence\", \"t11_modele_ia\", \"t12_utilisateur\"],\n",
    "    \"G√©ographie\": [\"t13_pays\", \"t14_region\", \"t15_departement\", \"t16_commune\", \"t17_territoire\"],\n",
    "    \"M√©t√©o\": [\"t18_type_meteo\", \"t19_meteo\"],\n",
    "    \"Indicateurs/Barom√®tres\": [\"t20_type_indicateur\", \"t21_source_indicateur\", \"t22_indicateur\", \n",
    "                               \"t28_source_barometre\", \"t29_document_baro\"],\n",
    "    \"Th√®mes & √âv√©nements\": [\"t23_theme_category\", \"t24_theme\", \"t25_evenement\", \"t26_document_theme\", \"t27_document_evenement\"],\n",
    "    \"Pipeline & Qualit√©\": [\"t30_pipeline\", \"t31_etape_etl\", \"t32_exec_etape\", \"t33_qc_rule\", \"t34_qc_result\"],\n",
    "    \"Audit/Versionning\": [\"t35_table_audit\", \"t36_table_version\"]\n",
    "}\n",
    "\n",
    "# Compter par domaine\n",
    "counts_domaines = {}\n",
    "for domaine, tables in domaines.items():\n",
    "    counts_domaines[domaine] = len(tables)\n",
    "\n",
    "df_domaines = pd.DataFrame(list(counts_domaines.items()), columns=[\"Domaine\", \"Nb tables\"])\n",
    "print(\"\\nüìã R√©partition par domaine :\")\n",
    "display(df_domaines)\n",
    "\n",
    "# Graphique r√©partition par domaine\n",
    "if len(df_domaines) > 0:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    bars = plt.barh(df_domaines[\"Domaine\"], df_domaines[\"Nb tables\"], color=plt.cm.Set3(range(len(df_domaines))))\n",
    "    for bar, value in zip(bars, df_domaines[\"Nb tables\"]):\n",
    "        plt.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "                str(value), ha='left', va='center', fontweight='bold', fontsize=11)\n",
    "    plt.title(\"üìä R√©partition des 36/37 tables par domaine (E1_v3)\", fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Nombre de tables\", fontsize=12)\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compter les entr√©es par table (seulement les tables non-vides)\n",
    "print(\"\\nüìà Nombre d'entr√©es par table (r√©f√©rentiels) :\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "counts = {}\n",
    "for _, row in df_tables.iterrows():\n",
    "    schema = row['table_schema']\n",
    "    table = row['table_name']\n",
    "    full_name = f\"{schema}.{table}\" if schema != 'public' else table\n",
    "    try:\n",
    "        count = pd.read_sql(text(f\"SELECT COUNT(*) as count FROM {full_name}\"), engine).iloc[0]['count']\n",
    "        if count > 0:  # Afficher seulement les tables avec donn√©es\n",
    "            counts[table] = count\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "if counts:\n",
    "    df_counts = pd.DataFrame(list(counts.items()), columns=['Table', 'Nb entr√©es'])\n",
    "    df_counts = df_counts.sort_values('Nb entr√©es', ascending=False)\n",
    "    display(df_counts)\n",
    "else:\n",
    "    print(\"   ‚ÑπÔ∏è Aucune donn√©e dans les tables (bootstrap √† venir)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Sch√©ma PostgreSQL E1_v3 cr√©√© avec succ√®s !\")\n",
    "print(f\"   üìä {len(df_tables)} tables cr√©√©es (architecture compl√®te)\")\n",
    "print(f\"   üìÇ Sch√©ma : datasens + public\")\n",
    "print(\"\\n   ‚û°Ô∏è Passez au notebook 03_ingest_sources.ipynb pour collecter les donn√©es\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
