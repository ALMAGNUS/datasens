{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb27fe87",
   "metadata": {},
   "source": [
    "# üîÑ DataSens E1 ‚Äî Notebook 4 : Tests CRUD Complets\n",
    "\n",
    "**üéØ Objectif** : D√©montrer les op√©rations CRUD (Create, Read, Update, Delete) sur les tables principales\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Contenu de ce notebook\n",
    "\n",
    "1. **CRUD \"C\" (Create)** : Insertion de documents, m√©t√©o, indicateurs\n",
    "2. **CRUD \"R\" (Read)** : Requ√™tes jointes complexes\n",
    "3. **CRUD \"U\" (Update)** : Mise √† jour de champs\n",
    "4. **CRUD \"D\" (Delete)** : Suppression contr√¥l√©e (ON DELETE)\n",
    "5. **Contr√¥les qualit√©** : D√©tection doublons, %NULL par colonne\n",
    "6. **KPIs** : Counts par source/type_donnee, par th√®me/√©v√©nement\n",
    "\n",
    "---\n",
    "\n",
    "## üîí RGPD & Gouvernance\n",
    "\n",
    "‚ö†Ô∏è **Rappel** : Suppressions avec ON DELETE CASCADE pour int√©grit√© r√©f√©rentielle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa33cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (r√©utiliser depuis notebooks pr√©c√©dents)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == \"notebooks\" else NOTEBOOK_DIR\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "PG_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.getenv(\"POSTGRES_PORT\", \"5432\"))\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\", \"datasens\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\", \"ds_user\")\n",
    "PG_PASS = os.getenv(\"POSTGRES_PASS\", \"ds_pass\")\n",
    "\n",
    "PG_URL = f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "engine = create_engine(PG_URL, future=True)\n",
    "\n",
    "print(\"‚úÖ Connexion PostgreSQL √©tablie\")\n",
    "print(f\"   üìç {PG_HOST}:{PG_PORT}/{PG_DB}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11607279",
   "metadata": {},
   "source": [
    "## ‚úÖ CRUD \"C\" (CREATE) : Insertion de donn√©es\n",
    "\n",
    "Insertion d'exemples pour tester les contraintes d'int√©grit√©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca54978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìù CRUD CREATE - Insertion d'exemples\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # 1. Cr√©er un document\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        INSERT INTO document (titre, texte, langue, hash_fingerprint)\n",
    "        VALUES (:titre, :texte, :langue, :hash)\n",
    "        RETURNING id_doc\n",
    "    \"\"\"), {\n",
    "        \"titre\": \"Test CRUD Create\",\n",
    "        \"texte\": \"Document de test pour d√©monstration CRUD\",\n",
    "        \"langue\": \"fr\",\n",
    "        \"hash\": \"test_hash_1234567890abcdef\"\n",
    "    })\n",
    "    id_doc = result.scalar()\n",
    "    print(f\"‚úÖ Document cr√©√© : id_doc = {id_doc}\")\n",
    "\n",
    "    # 2. Cr√©er un relev√© m√©t√©o\n",
    "    # D'abord s'assurer qu'un territoire existe\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        INSERT INTO territoire (ville, code_insee, lat, lon)\n",
    "        VALUES ('Paris', '75056', 48.8566, 2.3522)\n",
    "        ON CONFLICT (code_insee) DO UPDATE SET code_insee = EXCLUDED.code_insee\n",
    "        RETURNING id_territoire\n",
    "    \"\"\"))\n",
    "    id_territoire = result.scalar()\n",
    "\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        INSERT INTO meteo (id_territoire, date_obs, temperature, humidite, vent_kmh, pression, meteo_type)\n",
    "        VALUES (:t, NOW(), :temp, :hum, :vent, :pres, :type)\n",
    "        RETURNING id_meteo\n",
    "    \"\"\"), {\n",
    "        \"t\": id_territoire,\n",
    "        \"temp\": 18.5,\n",
    "        \"hum\": 65.0,\n",
    "        \"vent\": 15.0,\n",
    "        \"pres\": 1013.25,\n",
    "        \"type\": \"CLOUDS\"\n",
    "    })\n",
    "    id_meteo = result.scalar()\n",
    "    print(f\"‚úÖ Relev√© m√©t√©o cr√©√© : id_meteo = {id_meteo}\")\n",
    "\n",
    "    # 3. Cr√©er un indicateur\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT id_type_indic FROM type_indicateur WHERE code = 'POPULATION'\n",
    "    \"\"\")).scalar()\n",
    "\n",
    "    if result:\n",
    "        id_type_indic = result\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO indicateur (id_territoire, id_type_indic, valeur, annee)\n",
    "            VALUES (:t, :ti, :val, :annee)\n",
    "        \"\"\"), {\n",
    "            \"t\": id_territoire,\n",
    "            \"ti\": id_type_indic,\n",
    "            \"val\": 2161000.0,\n",
    "            \"annee\": 2023\n",
    "        })\n",
    "        print(\"‚úÖ Indicateur cr√©√© pour Paris (population 2023)\")\n",
    "\n",
    "print(\"\\n‚úÖ CRUD CREATE termin√© !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f97e7f",
   "metadata": {},
   "source": [
    "## üìñ CRUD \"R\" (READ) : Requ√™tes jointes\n",
    "\n",
    "Lecture des donn√©es avec jointures complexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a420b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìñ CRUD READ - Requ√™tes jointes\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Requ√™te 1 : Documents avec territoire et source\n",
    "query1 = \"\"\"\n",
    "SELECT\n",
    "    d.id_doc,\n",
    "    LEFT(d.titre, 50) as titre_extrait,\n",
    "    d.langue,\n",
    "    t.ville,\n",
    "    s.nom as source,\n",
    "    f.date_collecte\n",
    "FROM document d\n",
    "LEFT JOIN territoire t ON d.id_territoire = t.id_territoire\n",
    "LEFT JOIN flux f ON d.id_flux = f.id_flux\n",
    "LEFT JOIN source s ON f.id_source = s.id_source\n",
    "ORDER BY d.id_doc DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "df_read = pd.read_sql(query1, engine)\n",
    "print(f\"\\nüìÑ {len(df_read)} documents avec jointures :\\n\")\n",
    "print(df_read.to_string(index=False))\n",
    "\n",
    "# Requ√™te 2 : M√©t√©o avec territoire\n",
    "query2 = \"\"\"\n",
    "SELECT\n",
    "    t.ville,\n",
    "    m.date_obs,\n",
    "    m.temperature,\n",
    "    m.humidite,\n",
    "    m.meteo_type\n",
    "FROM meteo m\n",
    "JOIN territoire t ON m.id_territoire = t.id_territoire\n",
    "ORDER BY m.date_obs DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "df_meteo = pd.read_sql(query2, engine)\n",
    "print(\"\\nüå¶Ô∏è Derniers relev√©s m√©t√©o :\\n\")\n",
    "print(df_meteo.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ CRUD READ termin√© !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884717ac",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è CRUD \"U\" (UPDATE) : Mise √† jour\n",
    "\n",
    "Modification de champs existants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úèÔ∏è CRUD UPDATE - Mise √† jour\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # Mettre √† jour un document\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        UPDATE document\n",
    "        SET langue = :langue, titre = :titre\n",
    "        WHERE id_doc = (\n",
    "            SELECT id_doc FROM document\n",
    "            WHERE titre LIKE '%CRUD%'\n",
    "            LIMIT 1\n",
    "        )\n",
    "        RETURNING id_doc, titre, langue\n",
    "    \"\"\"), {\n",
    "        \"langue\": \"fr\",\n",
    "        \"titre\": \"Test CRUD Update - Modifi√©\"\n",
    "    })\n",
    "\n",
    "    row = result.fetchone()\n",
    "    if row:\n",
    "        print(f\"‚úÖ Document mis √† jour : id_doc={row[0]}, titre='{row[1]}', langue='{row[2]}'\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucun document √† mettre √† jour\")\n",
    "\n",
    "print(\"\\n‚úÖ CRUD UPDATE termin√© !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d341ef",
   "metadata": {},
   "source": [
    "## üóëÔ∏è CRUD \"D\" (DELETE) : Suppression contr√¥l√©e\n",
    "\n",
    "Suppression avec v√©rification des contraintes ON DELETE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca39208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üóëÔ∏è CRUD DELETE - Suppression contr√¥l√©e\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # Compter avant suppression\n",
    "    count_before = conn.execute(text(\"SELECT COUNT(*) FROM document WHERE titre LIKE '%CRUD%'\")).scalar()\n",
    "    print(f\"üìä Documents 'CRUD' avant suppression : {count_before}\")\n",
    "\n",
    "    # Supprimer un document (ON DELETE SET NULL pour id_flux)\n",
    "    conn.execute(text(\"\"\"\n",
    "        DELETE FROM document\n",
    "        WHERE titre LIKE '%CRUD%' AND id_doc IN (\n",
    "            SELECT id_doc FROM document\n",
    "            WHERE titre LIKE '%CRUD%'\n",
    "            LIMIT 1\n",
    "        )\n",
    "    \"\"\"))\n",
    "\n",
    "    count_after = conn.execute(text(\"SELECT COUNT(*) FROM document WHERE titre LIKE '%CRUD%'\")).scalar()\n",
    "    print(f\"üìä Documents 'CRUD' apr√®s suppression : {count_after}\")\n",
    "    print(f\"   ‚úÖ {count_before - count_after} document(s) supprim√©(s)\")\n",
    "\n",
    "print(\"\\n‚úÖ CRUD DELETE termin√© !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cfe1e",
   "metadata": {},
   "source": [
    "## üîç Contr√¥les qualit√©\n",
    "\n",
    "D√©tection des doublons et v√©rification des valeurs NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eeca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Contr√¥les qualit√©\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Doublons fingerprint\n",
    "    dup_query = \"\"\"\n",
    "    SELECT hash_fingerprint, COUNT(*) as c\n",
    "    FROM document\n",
    "    WHERE hash_fingerprint IS NOT NULL\n",
    "    GROUP BY hash_fingerprint\n",
    "    HAVING COUNT(*) > 1;\n",
    "    \"\"\"\n",
    "    df_dup = pd.read_sql(dup_query, conn)\n",
    "    print(f\"\\nüîé Doublons fingerprint : {len(df_dup)}\")\n",
    "    if len(df_dup) > 0:\n",
    "        print(df_dup.head())\n",
    "    else:\n",
    "        print(\"   ‚úÖ Aucun doublon d√©tect√©\")\n",
    "\n",
    "    # %NULL par colonne\n",
    "    null_query = \"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN titre IS NULL THEN 1 ELSE 0 END)::float / COUNT(*) * 100 as pct_null_titre,\n",
    "        SUM(CASE WHEN texte IS NULL THEN 1 ELSE 0 END)::float / COUNT(*) * 100 as pct_null_texte,\n",
    "        SUM(CASE WHEN langue IS NULL THEN 1 ELSE 0 END)::float / COUNT(*) * 100 as pct_null_langue\n",
    "    FROM document;\n",
    "    \"\"\"\n",
    "    df_null = pd.read_sql(null_query, conn)\n",
    "    print(\"\\nüìä Pourcentage NULL par colonne :\")\n",
    "    print(df_null.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ Contr√¥les qualit√© termin√©s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf46dd",
   "metadata": {},
   "source": [
    "## üìä KPIs : Statistiques par source/type/th√®me\n",
    "\n",
    "Comptages et agr√©gations pour visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä KPIs - Statistiques\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # KPI 1 : Counts par type_donnee\n",
    "    kpi1 = \"\"\"\n",
    "    SELECT\n",
    "        td.libelle as type_source,\n",
    "        COUNT(DISTINCT d.id_doc) as nb_documents,\n",
    "        COUNT(DISTINCT s.id_source) as nb_sources\n",
    "    FROM document d\n",
    "    LEFT JOIN flux f ON d.id_flux = f.id_flux\n",
    "    LEFT JOIN source s ON f.id_source = s.id_source\n",
    "    LEFT JOIN type_donnee td ON s.id_type_donnee = td.id_type_donnee\n",
    "    GROUP BY td.libelle\n",
    "    ORDER BY nb_documents DESC;\n",
    "    \"\"\"\n",
    "    df_kpi1 = pd.read_sql(kpi1, conn)\n",
    "    print(\"\\nüì¶ Documents par type de source :\")\n",
    "    print(df_kpi1.to_string(index=False))\n",
    "\n",
    "    # KPI 2 : Counts par th√®me\n",
    "    kpi2 = \"\"\"\n",
    "    SELECT\n",
    "        t.libelle as theme,\n",
    "        COUNT(DISTINCT e.id_event) as nb_evenements,\n",
    "        COUNT(DISTINCT de.id_doc) as nb_documents_associes\n",
    "    FROM theme t\n",
    "    LEFT JOIN evenement e ON t.id_theme = e.id_theme\n",
    "    LEFT JOIN document_evenement de ON e.id_event = de.id_event\n",
    "    GROUP BY t.libelle\n",
    "    ORDER BY nb_evenements DESC;\n",
    "    \"\"\"\n",
    "    df_kpi2 = pd.read_sql(kpi2, conn)\n",
    "    print(\"\\nüè∑Ô∏è √âv√©nements par th√®me :\")\n",
    "    print(df_kpi2.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ CRUD complet test√© avec succ√®s !\")\n",
    "print(\"   ‚û°Ô∏è Passez au notebook 05_snapshot_and_readme.ipynb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
