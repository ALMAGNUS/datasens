{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb27fe87",
   "metadata": {},
   "source": [
    "# DataSens E1_v3 ‚Äî 04_quality_checks\n",
    "\n",
    "- Objectifs: Contr√¥les qualit√© PostgreSQL + MinIO pour architecture 36/37 tables\n",
    "- Pr√©requis: 03_ingest_sources ex√©cut√©\n",
    "- Sortie: Rapports QA avec visualisations + tables pandas\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md\n",
    "\n",
    "> **E1_v3** : Contr√¥les qualit√© complets (tables t01-t37)\n",
    "> - Volumes par table\n",
    "> - D√©tection doublons (hash_fingerprint)\n",
    "> - Valeurs NULL critiques\n",
    "> - Int√©grit√© r√©f√©rentielle (FK)\n",
    "> - MinIO DataLake (objets, taille)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üé¨ DASHBOARD NARRATIF - O√ô SOMMES-NOUS ?\n",
    "# ============================================================\n",
    "# Ce dashboard vous guide √† travers le pipeline DataSens E1\n",
    "# Il montre la progression et l'√©tat actuel des donn√©es\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üé¨ FIL D'ARIANE VISUEL - PIPELINE DATASENS E1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er figure dashboard\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.axis('off')\n",
    "\n",
    "# √âtapes du pipeline\n",
    "etapes = [\n",
    "    {\"nom\": \"üì• COLLECTE\", \"status\": \"‚úÖ\", \"desc\": \"Sources brutes\"},\n",
    "    {\"nom\": \"‚òÅÔ∏è DATALAKE\", \"status\": \"‚úÖ\", \"desc\": \"MinIO Raw\"},\n",
    "    {\"nom\": \"üßπ NETTOYAGE\", \"status\": \"üîÑ\", \"desc\": \"D√©duplication\"},\n",
    "    {\"nom\": \"üíæ ETL\", \"status\": \"‚è≥\", \"desc\": \"PostgreSQL\"},\n",
    "    {\"nom\": \"üìä ANNOTATION\", \"status\": \"‚è≥\", \"desc\": \"Enrichissement\"},\n",
    "    {\"nom\": \"üì¶ EXPORT\", \"status\": \"‚è≥\", \"desc\": \"Dataset IA\"}\n",
    "]\n",
    "\n",
    "# Couleurs selon statut\n",
    "colors = {\n",
    "    \"‚úÖ\": \"#4ECDC4\",\n",
    "    \"üîÑ\": \"#FECA57\", \n",
    "    \"‚è≥\": \"#E8E8E8\"\n",
    "}\n",
    "\n",
    "# Dessiner timeline\n",
    "y_pos = 4\n",
    "x_start = 1\n",
    "x_spacing = 1.4\n",
    "\n",
    "for i, etape in enumerate(etapes):\n",
    "    x_pos = x_start + i * x_spacing\n",
    "    \n",
    "    # Cercle √©tape\n",
    "    circle = plt.Circle((x_pos, y_pos), 0.25, color=colors[etape[\"status\"]], zorder=3)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(x_pos, y_pos, etape[\"status\"], ha='center', va='center', fontsize=14, fontweight='bold', zorder=4)\n",
    "    \n",
    "    # Nom √©tape\n",
    "    ax.text(x_pos, y_pos - 0.6, etape[\"nom\"], ha='center', va='top', fontsize=11, fontweight='bold')\n",
    "    ax.text(x_pos, y_pos - 0.85, etape[\"desc\"], ha='center', va='top', fontsize=9, style='italic')\n",
    "    \n",
    "    # Fl√®che vers prochaine √©tape\n",
    "    if i < len(etapes) - 1:\n",
    "        ax.arrow(x_pos + 0.3, y_pos, x_spacing - 0.6, 0, \n",
    "                head_width=0.1, head_length=0.15, fc='gray', ec='gray', zorder=2)\n",
    "\n",
    "# Titre narratif\n",
    "ax.text(5, 5.5, \"üéØ PROGRESSION DU PIPELINE E1\", ha='center', va='center', \n",
    "        fontsize=16, fontweight='bold', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# L√©gende\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor='#4ECDC4', label='Termin√©'),\n",
    "    mpatches.Patch(facecolor='#FECA57', label='En cours'),\n",
    "    mpatches.Patch(facecolor='#E8E8E8', label='√Ä venir')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=10)\n",
    "\n",
    "# Statistiques rapides (si disponibles)\n",
    "stats_text = \"\\nüìä SNAPSHOT ACTUEL :\\n\"\n",
    "try:\n",
    "    # Essayer de charger des stats si base disponible\n",
    "    stats_text += \"   ‚Ä¢ Pipeline en cours d'ex√©cution...\\n\"\n",
    "except:\n",
    "    stats_text += \"   ‚Ä¢ D√©marrage du pipeline...\\n\"\n",
    "\n",
    "ax.text(5, 1.5, stats_text, ha='center', va='center', fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.title(\"üé¨ FIL D'ARIANE VISUEL - Accompagnement narratif du jury\", \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Le fil d'Ariane vous guide √©tape par √©tape √† travers le pipeline\")\n",
    "print(\"   Chaque visualisation s'inscrit dans cette progression narrative\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa33cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "> Notes:\n",
    "> - **Contr√¥les PostgreSQL** : Volumes, doublons, NULL, int√©grit√© FK (tables t01-t37)\n",
    "> - **Contr√¥les MinIO** : Objets, taille totale, r√©partition par pr√©fixe\n",
    "> - **Visualisations** : Graphiques + tables pandas √† chaque √©tape\n",
    "> - **Tables E1_v3** : Utilisation des tables t01-t37 selon MPD.sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11607279",
   "metadata": {},
   "source": [
    "# DataSens E1_v3 - 04_quality_checks\n",
    "# üîç Contr√¥les qualit√© PostgreSQL + MinIO avec visualisations (tables t01-t37)\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from minio import Minio\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# R√©cup√©rer variables notebook 01\n",
    "if 'PROJECT_ROOT' not in globals():\n",
    "    current = Path.cwd()\n",
    "    PROJECT_ROOT = None\n",
    "    while current != current.parent:\n",
    "        if (current / \"notebooks\").exists() and (current / \"docs\").exists():\n",
    "            PROJECT_ROOT = current\n",
    "            break\n",
    "        current = current.parent\n",
    "    else:\n",
    "        PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "if 'PG_URL' not in globals():\n",
    "    PG_URL = os.getenv(\"DATASENS_PG_URL\", \"postgresql+psycopg2://postgres:postgres@localhost:5433/postgres\")\n",
    "\n",
    "if 'MINIO_ENDPOINT' not in globals():\n",
    "    MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"http://localhost:9002\")\n",
    "    MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", \"admin\")\n",
    "    MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", \"admin123\")\n",
    "    MINIO_BUCKET = os.getenv(\"MINIO_BUCKET\", \"datasens-raw\")\n",
    "\n",
    "engine = create_engine(PG_URL, future=True)\n",
    "\n",
    "print(\"üîç CONTROLES QUALITE E1_V3 (36/37 tables)\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca54978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. VOLUMES PostgreSQL (tables principales t01-t37)\n",
    "# ============================================================\n",
    "print(\"\\nüìä 1. VOLUMES PostgreSQL\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    stats = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            't04_document' AS table_name, COUNT(*) AS nb_lignes\n",
    "        FROM t04_document\n",
    "        UNION ALL\n",
    "        SELECT 't03_flux', COUNT(*) FROM t03_flux\n",
    "        UNION ALL\n",
    "        SELECT 't02_source', COUNT(*) FROM t02_source\n",
    "        UNION ALL\n",
    "        SELECT 't19_meteo', COUNT(*) FROM t19_meteo\n",
    "        UNION ALL\n",
    "        SELECT 't17_territoire', COUNT(*) FROM t17_territoire\n",
    "        UNION ALL\n",
    "        SELECT 't01_type_donnee', COUNT(*) FROM t01_type_donnee\n",
    "    \"\"\", conn)\n",
    "\n",
    "print(\"\\nüìã Table des volumes :\")\n",
    "display(stats)\n",
    "\n",
    "# Graphique volumes\n",
    "if len(stats) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(stats[\"table_name\"], stats[\"nb_lignes\"], color=plt.cm.Pastel1(range(len(stats))))\n",
    "    for bar, value in zip(bars, stats[\"nb_lignes\"]):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(stats[\"nb_lignes\"]) * 0.01,\n",
    "                f\"{int(value):,}\", ha='center', va='bottom', fontweight='bold')\n",
    "    plt.title(\"üìä Volumes par table PostgreSQL (E1_v3)\", fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Nombre de lignes\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "total_docs = stats[stats['table_name'] == 't04_document']['nb_lignes'].iloc[0] if len(stats[stats['table_name'] == 't04_document']) > 0 else 0\n",
    "print(f\"\\n‚úÖ Total documents (t04_document) : {total_docs:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f97e7f",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 2. DOUBLONS (hash_fingerprint)\n",
    "# ============================================================\n",
    "print(\"\\nüîé 2. DETECTION DOUBLONS\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a420b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    dup_query = text(\"\"\"\n",
    "        SELECT hash_fingerprint, COUNT(*) AS nb_occurrences\n",
    "        FROM t04_document\n",
    "        WHERE hash_fingerprint IS NOT NULL\n",
    "        GROUP BY hash_fingerprint\n",
    "        HAVING COUNT(*) > 1\n",
    "        ORDER BY nb_occurrences DESC\n",
    "    \"\"\")\n",
    "    df_doublons = pd.read_sql_query(dup_query, conn)\n",
    "\n",
    "if len(df_doublons) == 0:\n",
    "    print(\"‚úÖ Aucun doublon d√©tect√© (hash_fingerprint unique)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {len(df_doublons)} doublons d√©tect√©s !\")\n",
    "    display(df_doublons)\n",
    "    \n",
    "    # Graphique doublons si pr√©sents\n",
    "    if len(df_doublons) > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.barh(range(len(df_doublons)), df_doublons[\"nb_occurrences\"], color='#FF6B6B')\n",
    "        plt.yticks(range(len(df_doublons)), [f\"{hash[:16]}...\" for hash in df_doublons[\"hash_fingerprint\"]])\n",
    "        plt.xlabel(\"Nombre d'occurrences\", fontsize=11)\n",
    "        plt.title(\"‚ö†Ô∏è Doublons d√©tect√©s par hash_fingerprint\", fontsize=12, fontweight='bold')\n",
    "        plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 3. VALEURS NULL CRITIQUES\n",
    "# ============================================================\n",
    "print(\"\\nüîç 3. VALEURS NULL CRITIQUES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    nulls = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            'titre' AS champ, COUNT(*) FILTER (WHERE titre IS NULL) AS nb_nulls,\n",
    "            COUNT(*) AS nb_total,\n",
    "            ROUND(100.0 * COUNT(*) FILTER (WHERE titre IS NULL) / COUNT(*), 2) AS pct_null\n",
    "        FROM t04_document\n",
    "        UNION ALL\n",
    "        SELECT 'texte', COUNT(*) FILTER (WHERE texte IS NULL), COUNT(*),\n",
    "               ROUND(100.0 * COUNT(*) FILTER (WHERE texte IS NULL) / COUNT(*), 2)\n",
    "        FROM t04_document\n",
    "        UNION ALL\n",
    "        SELECT 'hash_fingerprint', COUNT(*) FILTER (WHERE hash_fingerprint IS NULL), COUNT(*),\n",
    "               ROUND(100.0 * COUNT(*) FILTER (WHERE hash_fingerprint IS NULL) / COUNT(*), 2)\n",
    "        FROM t04_document\n",
    "    \"\"\", conn)\n",
    "\n",
    "print(\"\\nüìã Taux de NULL par champ critique :\")\n",
    "display(nulls)\n",
    "\n",
    "if len(nulls) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(nulls[\"champ\"], nulls[\"pct_null\"], color=['#FF6B6B' if p > 20 else '#4ECDC4' for p in nulls[\"pct_null\"]])\n",
    "    for bar, value in zip(bars, nulls[\"pct_null\"]):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f\"{value}%\", ha='center', va='bottom', fontweight='bold')\n",
    "    plt.axhline(y=20, color='r', linestyle='--', label='Seuil 20%')\n",
    "    plt.title(\"üìä Taux de valeurs NULL par champ (t04_document)\", fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(\"Pourcentage NULL (%)\", fontsize=11)\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884717ac",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 4. INTEGRITE REFERENCES (Foreign Keys)\n",
    "# ============================================================\n",
    "print(\"\\nüîó 4. INTEGRITE REFERENCES (Foreign Keys)\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    integrity = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            't04_document ‚Üí t03_flux' AS relation,\n",
    "            COUNT(*) FILTER (WHERE d.id_flux NOT IN (SELECT id_flux FROM t03_flux)) AS orphelins\n",
    "        FROM t04_document d\n",
    "        UNION ALL\n",
    "        SELECT 't03_flux ‚Üí t02_source',\n",
    "               COUNT(*) FILTER (WHERE f.id_source NOT IN (SELECT id_source FROM t02_source))\n",
    "        FROM t03_flux f\n",
    "        UNION ALL\n",
    "        SELECT 't19_meteo ‚Üí t17_territoire',\n",
    "               COUNT(*) FILTER (WHERE m.id_territoire NOT IN (SELECT id_territoire FROM t17_territoire))\n",
    "        FROM t19_meteo m\n",
    "    \"\"\", conn)\n",
    "\n",
    "print(\"\\nüìã V√©rification int√©grit√© r√©f√©rentielle :\")\n",
    "display(integrity)\n",
    "\n",
    "orphelins_total = integrity['orphelins'].sum()\n",
    "if orphelins_total == 0:\n",
    "    print(\"‚úÖ Int√©grit√© r√©f√©rentielle : OK (aucun orphelin)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {orphelins_total} orphelins d√©tect√©s !\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. MINIO DATALAKE\n",
    "# ============================================================\n",
    "print(\"\\n‚òÅÔ∏è 5. MINIO DATALAKE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    minio_client = Minio(\n",
    "        MINIO_ENDPOINT.replace(\"http://\", \"\").replace(\"https://\", \"\"),\n",
    "        access_key=MINIO_ACCESS_KEY,\n",
    "        secret_key=MINIO_SECRET_KEY,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    objects = list(minio_client.list_objects(MINIO_BUCKET, recursive=True))\n",
    "    total_size = sum(obj.size for obj in objects)\n",
    "    \n",
    "    print(f\"\\nüìä Bucket '{MINIO_BUCKET}' :\")\n",
    "    print(f\"   ‚Ä¢ {len(objects)} objets\")\n",
    "    print(f\"   ‚Ä¢ Taille totale : {total_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # R√©partition par pr√©fixe (type de source)\n",
    "    prefixes = {}\n",
    "    for obj in objects:\n",
    "        prefix = obj.object_name.split('/')[0] if '/' in obj.object_name else 'root'\n",
    "        prefixes[prefix] = prefixes.get(prefix, 0) + 1\n",
    "    \n",
    "    if prefixes:\n",
    "        df_minio = pd.DataFrame(list(prefixes.items()), columns=[\"Pr√©fixe\", \"Nb objets\"])\n",
    "        display(df_minio)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        bars = plt.bar(df_minio[\"Pr√©fixe\"], df_minio[\"Nb objets\"], color='#45B7D1')\n",
    "        for bar, value in zip(bars, df_minio[\"Nb objets\"]):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    str(value), ha='center', va='bottom', fontweight='bold')\n",
    "        plt.title(\"üìä R√©partition des objets MinIO par type de source (E1_v3)\", fontsize=12, fontweight='bold')\n",
    "        plt.ylabel(\"Nombre d'objets\", fontsize=11)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MinIO non accessible : {e}\")\n",
    "    objects = []\n",
    "\n",
    "# ============================================================\n",
    "# 6. BILAN QA GLOBAL\n",
    "# ============================================================\n",
    "print(\"\\n‚úÖ 6. BILAN QA GLOBAL E1_V3\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "qa_summary = {\n",
    "    \"Volumes\": f\"{total_docs:,} documents\",\n",
    "    \"Doublons\": \"‚úÖ OK\" if len(df_doublons) == 0 else f\"‚ö†Ô∏è {len(df_doublons)} doublons\",\n",
    "    \"NULL critiques\": \"‚úÖ OK\" if nulls['pct_null'].max() < 20 else f\"‚ö†Ô∏è {nulls['pct_null'].max()}% max\",\n",
    "    \"Int√©grit√© FK\": \"‚úÖ OK\" if orphelins_total == 0 else f\"‚ö†Ô∏è {orphelins_total} orphelins\",\n",
    "    \"MinIO\": f\"‚úÖ {len(objects)} objets\"\n",
    "}\n",
    "\n",
    "df_qa = pd.DataFrame(list(qa_summary.items()), columns=[\"Check\", \"R√©sultat\"])\n",
    "display(df_qa)\n",
    "\n",
    "print(\"\\n‚úÖ Contr√¥les qualit√© E1_v3 termin√©s !\")\n",
    "print(\"   üìä Architecture : 36/37 tables (t01-t37) valid√©es\")\n",
    "print(\"   ‚û°Ô∏è Passez au notebook 05_snapshot_and_readme.ipynb pour finaliser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d341ef",
   "metadata": {},
   "source": [
    "## üóëÔ∏è CRUD \"D\" (DELETE) : Suppression contr√¥l√©e\n",
    "\n",
    "Suppression avec v√©rification des contraintes ON DELETE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca39208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üóëÔ∏è CRUD DELETE - Suppression contr√¥l√©e\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # Compter avant suppression (corrig√© avec pr√©fixe t04_)\n",
    "    count_before = conn.execute(text(\"SELECT COUNT(*) FROM t04_document WHERE titre LIKE '%CRUD%'\")).scalar()\n",
    "    print(f\"üìä Documents 'CRUD' avant suppression : {count_before}\")\n",
    "    \n",
    "    # Afficher les documents avant suppression\n",
    "    df_before = pd.read_sql_query(\"\"\"\n",
    "        SELECT id_doc, LEFT(titre, 50) AS titre_apercu, langue, date_publication\n",
    "        FROM t04_document\n",
    "        WHERE titre LIKE '%CRUD%'\n",
    "        LIMIT 5\n",
    "    \"\"\", engine)\n",
    "    if len(df_before) > 0:\n",
    "        print(\"\\nüìã Documents avant suppression (aper√ßu) :\")\n",
    "        display(df_before)\n",
    "\n",
    "    # Supprimer un document (ON DELETE SET NULL pour id_flux)\n",
    "    conn.execute(text(\"\"\"\n",
    "        DELETE FROM t04_document\n",
    "        WHERE titre LIKE '%CRUD%' AND id_doc IN (\n",
    "            SELECT id_doc FROM t04_document\n",
    "            WHERE titre LIKE '%CRUD%'\n",
    "            LIMIT 1\n",
    "        )\n",
    "    \"\"\"))\n",
    "\n",
    "    count_after = conn.execute(text(\"SELECT COUNT(*) FROM t04_document WHERE titre LIKE '%CRUD%'\")).scalar()\n",
    "    print(f\"\\nüìä Documents 'CRUD' apr√®s suppression : {count_after}\")\n",
    "    print(f\"   ‚úÖ {count_before - count_after} document(s) supprim√©(s)\")\n",
    "    \n",
    "    # Visualisation avant/apr√®s\n",
    "    if count_before > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        categories = ['Avant DELETE', 'Apr√®s DELETE']\n",
    "        values = [count_before, count_after]\n",
    "        colors = ['#FF6B6B', '#4ECDC4']\n",
    "        bars = plt.bar(categories, values, color=colors)\n",
    "        for bar, value in zip(bars, values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values) * 0.02,\n",
    "                    f\"{int(value)}\", ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "        plt.title(\"üóëÔ∏è Impact de l'op√©ration DELETE (CRUD)\", fontsize=12, fontweight='bold')\n",
    "        plt.ylabel(\"Nombre de documents\", fontsize=11)\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ CRUD DELETE termin√© !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cfe1e",
   "metadata": {},
   "source": [
    "## üîç Contr√¥les qualit√©\n",
    "\n",
    "D√©tection des doublons et v√©rification des valeurs NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eeca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Contr√¥les qualit√© avec Visualisations\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Doublons fingerprint (corrig√© avec pr√©fixe t04_)\n",
    "    dup_query = \"\"\"\n",
    "    SELECT hash_fingerprint, COUNT(*) as c\n",
    "    FROM t04_document\n",
    "    WHERE hash_fingerprint IS NOT NULL\n",
    "    GROUP BY hash_fingerprint\n",
    "    HAVING COUNT(*) > 1;\n",
    "    \"\"\"\n",
    "    df_dup = pd.read_sql(dup_query, conn)\n",
    "    print(f\"\\nüîé Doublons fingerprint : {len(df_dup)}\")\n",
    "    if len(df_dup) > 0:\n",
    "        display(df_dup.head(10))\n",
    "    else:\n",
    "        print(\"   ‚úÖ Aucun doublon d√©tect√©\")\n",
    "\n",
    "    # %NULL par colonne (corrig√© avec pr√©fixe t04_)\n",
    "    null_query = \"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN titre IS NULL THEN 1 ELSE 0 END)::float / COUNT(*) * 100 as pct_null_titre,\n",
    "        SUM(CASE WHEN texte IS NULL THEN 1 ELSE 0 END)::float / COUNT(*) * 100 as pct_null_texte,\n",
    "        SUM(CASE WHEN langue IS NULL THEN 1 ELSE 0 END)::float / COUNT(*) * 100 as pct_null_langue\n",
    "    FROM t04_document;\n",
    "    \"\"\"\n",
    "    df_null = pd.read_sql(null_query, conn)\n",
    "    print(\"\\nüìä Pourcentage NULL par colonne :\")\n",
    "    display(df_null)\n",
    "    \n",
    "    # Visualisation NULL\n",
    "    if len(df_null) > 0 and df_null.iloc[0]['total'] > 0:\n",
    "        row = df_null.iloc[0]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        columns = ['titre', 'texte', 'langue']\n",
    "        pct_nulls = [row['pct_null_titre'], row['pct_null_texte'], row['pct_null_langue']]\n",
    "        colors = ['#FF6B6B' if p > 10 else '#4ECDC4' for p in pct_nulls]\n",
    "        bars = plt.bar(columns, pct_nulls, color=colors)\n",
    "        for bar, value in zip(bars, pct_nulls):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    f\"{value:.1f}%\", ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "        plt.axhline(y=10, color='red', linestyle='--', linewidth=2, label='Seuil critique (10%)')\n",
    "        plt.title(\"üìä Pourcentage de valeurs NULL par colonne (E1_v3)\", fontsize=12, fontweight='bold')\n",
    "        plt.ylabel(\"Pourcentage NULL (%)\", fontsize=11)\n",
    "        plt.legend()\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Contr√¥les qualit√© termin√©s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf46dd",
   "metadata": {},
   "source": [
    "## üìä KPIs : Statistiques par source/type/th√®me\n",
    "\n",
    "Comptages et agr√©gations pour visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä KPIs - Statistiques avec Visualisations CRUD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # KPI 1 : Counts par type_donnee (corrig√© avec pr√©fixes tXX_)\n",
    "    kpi1 = \"\"\"\n",
    "    SELECT\n",
    "        td.libelle as type_source,\n",
    "        COUNT(DISTINCT d.id_doc) as nb_documents,\n",
    "        COUNT(DISTINCT s.id_source) as nb_sources\n",
    "    FROM t04_document d\n",
    "    LEFT JOIN t03_flux f ON d.id_flux = f.id_flux\n",
    "    LEFT JOIN t02_source s ON f.id_source = s.id_source\n",
    "    LEFT JOIN t01_type_donnee td ON s.id_type_donnee = td.id_type_donnee\n",
    "    GROUP BY td.libelle\n",
    "    ORDER BY nb_documents DESC;\n",
    "    \"\"\"\n",
    "    df_kpi1 = pd.read_sql(kpi1, conn)\n",
    "    print(\"\\nüì¶ Documents par type de source :\")\n",
    "    display(df_kpi1)\n",
    "    \n",
    "    # Graphique documents par type\n",
    "    if len(df_kpi1) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        bars = plt.bar(df_kpi1[\"type_source\"], df_kpi1[\"nb_documents\"], color=plt.cm.Set2(range(len(df_kpi1))))\n",
    "        for bar, value in zip(bars, df_kpi1[\"nb_documents\"]):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(df_kpi1[\"nb_documents\"]) * 0.02,\n",
    "                    f\"{int(value):,}\", ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "        plt.title(\"üìä Documents par type de source (E1_v3)\", fontsize=12, fontweight='bold')\n",
    "        plt.ylabel(\"Nombre de documents\", fontsize=11)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        bars = plt.bar(df_kpi1[\"type_source\"], df_kpi1[\"nb_sources\"], color=plt.cm.Pastel1(range(len(df_kpi1))))\n",
    "        for bar, value in zip(bars, df_kpi1[\"nb_sources\"]):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(df_kpi1[\"nb_sources\"]) * 0.02,\n",
    "                    str(int(value)), ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "        plt.title(\"üìä Sources par type de donn√©e (E1_v3)\", fontsize=12, fontweight='bold')\n",
    "        plt.ylabel(\"Nombre de sources\", fontsize=11)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # KPI 2 : Counts par th√®me (corrig√© avec pr√©fixes tXX_)\n",
    "    kpi2 = \"\"\"\n",
    "    SELECT\n",
    "        t.libelle as theme,\n",
    "        COUNT(DISTINCT e.id_event) as nb_evenements,\n",
    "        COUNT(DISTINCT de.id_doc) as nb_documents_associes\n",
    "    FROM t24_theme t\n",
    "    LEFT JOIN t25_evenement e ON t.id_theme = e.id_theme\n",
    "    LEFT JOIN t27_document_evenement de ON e.id_event = de.id_event\n",
    "    GROUP BY t.libelle\n",
    "    ORDER BY nb_evenements DESC;\n",
    "    \"\"\"\n",
    "    df_kpi2 = pd.read_sql(kpi2, conn)\n",
    "    print(\"\\nüè∑Ô∏è √âv√©nements par th√®me :\")\n",
    "    display(df_kpi2)\n",
    "    \n",
    "    # Graphique √©v√©nements par th√®me\n",
    "    if len(df_kpi2) > 0 and df_kpi2['nb_evenements'].sum() > 0:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        top_themes = df_kpi2.nlargest(10, \"nb_evenements\")\n",
    "        bars = plt.barh(top_themes[\"theme\"], top_themes[\"nb_evenements\"], color=plt.cm.Pastel2(range(len(top_themes))))\n",
    "        for i, (bar, value) in enumerate(zip(bars, top_themes[\"nb_evenements\"])):\n",
    "            plt.text(bar.get_width() + max(top_themes[\"nb_evenements\"]) * 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{int(value)}\", ha='left', va='center', fontweight='bold', fontsize=9)\n",
    "        plt.title(\"üè∑Ô∏è √âv√©nements par th√®me (Top 10)\", fontsize=12, fontweight='bold')\n",
    "        plt.xlabel(\"Nombre d'√©v√©nements\", fontsize=11)\n",
    "        plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        top_docs = df_kpi2.nlargest(10, \"nb_documents_associes\")\n",
    "        bars = plt.barh(top_docs[\"theme\"], top_docs[\"nb_documents_associes\"], color='#4ECDC4')\n",
    "        for i, (bar, value) in enumerate(zip(bars, top_docs[\"nb_documents_associes\"])):\n",
    "            plt.text(bar.get_width() + max(top_docs[\"nb_documents_associes\"]) * 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{int(value)}\", ha='left', va='center', fontweight='bold', fontsize=9)\n",
    "        plt.title(\"üìÑ Documents associ√©s par th√®me (Top 10)\", fontsize=12, fontweight='bold')\n",
    "        plt.xlabel(\"Nombre de documents\", fontsize=11)\n",
    "        plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # KPI 3 : R√©sum√© CRUD op√©rations test√©es\n",
    "    print(\"\\nüìä R√©sum√© des op√©rations CRUD test√©es :\")\n",
    "    crud_summary = pd.DataFrame({\n",
    "        \"Op√©ration\": [\"CREATE (INSERT)\", \"READ (SELECT)\", \"UPDATE\", \"DELETE\"],\n",
    "        \"Statut\": [\"‚úÖ Test√©\", \"‚úÖ Test√©\", \"‚úÖ Test√©\", \"‚úÖ Test√©\"],\n",
    "        \"Tables utilis√©es\": [\"t04_document\", \"t04_document, t02_source, t03_flux\", \"t04_document\", \"t04_document\"]\n",
    "    })\n",
    "    display(crud_summary)\n",
    "    \n",
    "    # Graphique r√©sum√© CRUD\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "    bars = plt.bar(crud_summary[\"Op√©ration\"], [1, 1, 1, 1], color=colors)\n",
    "    for bar, op in zip(bars, crud_summary[\"Op√©ration\"]):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "                \"‚úÖ\", ha='center', va='bottom', fontweight='bold', fontsize=20)\n",
    "    plt.title(\"‚úÖ Op√©rations CRUD test√©es (E1_v3)\", fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Statut\", fontsize=12)\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ CRUD complet test√© avec succ√®s !\")\n",
    "print(\"   üìä Visualisations CRUD : Op√©rations CREATE, READ, UPDATE, DELETE valid√©es\")\n",
    "print(\"   ‚û°Ô∏è Passez au notebook 05_snapshot_and_readme.ipynb pour le dataset final annot√©\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}