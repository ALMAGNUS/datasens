{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSens E1_v3 ‚Äî 01_setup_env\n",
    "\n",
    "- Objectifs: Configuration compl√®te MinIO + PostgreSQL + arborescence + logging\n",
    "- Pr√©requis: Docker Compose lanc√© (MinIO + PostgreSQL), Python + venv, `pip install -r requirements.txt`\n",
    "- Ordre global E1_v3: 01 ‚Üí 02 ‚Üí 03 ‚Üí 04 ‚Üí 05\n",
    "- Guide: docs/GUIDE_TECHNIQUE_E1.md\n",
    "\n",
    "> **E1_v3** : Architecture compl√®te **36/37 tables** avec **TOUTES les sources r√©elles**\n",
    "> - Sources compl√®tes : Kaggle, OpenWeatherMap, RSS Multi, NewsAPI, Web Scraping (6 sources), GDELT Big Data\n",
    "> - Barom√®tres : 10 types de barom√®tres d'opinion et indicateurs sociaux\n",
    "> - Sch√©ma complet : T01-T36 + T37 (archive_flux) selon MPD.sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> Notes:\n",
    "> - Configuration des connexions **MinIO (DataLake)** et **PostgreSQL (SGBD)**\n",
    "> - Cr√©ation de l'arborescence `data/raw/` avec **tous les sous-dossiers** pour sources compl√®tes\n",
    "> - Syst√®me de logging pour tracer toutes les op√©rations\n",
    "> - Fonctions utilitaires (timestamp UTC, hash SHA256 pour d√©duplication)\n",
    "> - **R√©f√©rences** : docs/datasens_MPD.sql (36 tables), docs/datasens_sources_dictionary.md, docs/datasens_barometer_themes.md\n",
    "    ROOT = ROOT\n",
    "except NameError:\n",
    "    from pathlib import Path\n",
    "    ROOT = Path.cwd().resolve().parents[2]\n",
    "DATA_DIR = ROOT / 'data'\n",
    "DOCS_DIR = ROOT / 'docs'\n",
    "LOGS_DIR = ROOT / 'logs'\n",
    "print('ROOT=', ROOT)\n",
    "print('DATA_DIR=', DATA_DIR)\n",
    "print('DOCS_DIR=', DOCS_DIR)\n",
    "print('LOGS_DIR=', LOGS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSens E1_v3 - 01_setup_env\n",
    "# üîß Configuration environnement : MinIO + PostgreSQL + Arborescence + Logging\n",
    "# Architecture compl√®te : 36/37 tables + Toutes les sources\n",
    "\n",
    "import datetime as dt\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "from datetime import UTC, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# D√©tection robuste du dossier projet\n",
    "current = Path.cwd()\n",
    "PROJECT_ROOT = None\n",
    "while current != current.parent:\n",
    "    if (current / \"notebooks\").exists() and (current / \"docs\").exists():\n",
    "        PROJECT_ROOT = current\n",
    "        break\n",
    "    current = current.parent\n",
    "else:\n",
    "    PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "print(f\"üìÇ Racine projet d√©tect√©e : {PROJECT_ROOT}\")\n",
    "\n",
    "# Chargement .env\n",
    "env_path = PROJECT_ROOT / '.env'\n",
    "loaded = load_dotenv(env_path)\n",
    "if loaded:\n",
    "    print(f'‚úÖ .env charg√©: {env_path}')\n",
    "else:\n",
    "    print(f'‚ö†Ô∏è .env non trouv√©: {env_path}')\n",
    "    # Cr√©er .env.example si absent\n",
    "    env_example = PROJECT_ROOT / '.env.example'\n",
    "    if not env_example.exists():\n",
    "        env_example.write_text(\"\"\"\n",
    "# PostgreSQL\n",
    "POSTGRES_HOST=localhost\n",
    "POSTGRES_PORT=5433\n",
    "POSTGRES_DB=postgres\n",
    "POSTGRES_USER=postgres\n",
    "POSTGRES_PASS=postgres\n",
    "\n",
    "# MinIO\n",
    "MINIO_ENDPOINT=http://localhost:9002\n",
    "MINIO_ACCESS_KEY=admin\n",
    "MINIO_SECRET_KEY=admin123\n",
    "MINIO_BUCKET=datasens-raw\n",
    "\n",
    "# API Keys (pour toutes les sources E1_v3)\n",
    "OWM_API_KEY=\n",
    "NEWSAPI_KEY=\n",
    "KAGGLE_USERNAME=\n",
    "KAGGLE_KEY=\n",
    "GDELT_BASE=http://data.gdeltproject.org/gkg/\n",
    "\"\"\".strip() + \"\\n\", encoding='utf-8')\n",
    "        print(f'üìÑ .env.example cr√©√©: {env_example}')\n",
    "\n",
    "# Configuration MinIO (DataLake)\n",
    "MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"http://localhost:9002\")\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", \"admin\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", \"admin123\")\n",
    "MINIO_BUCKET = os.getenv(\"MINIO_BUCKET\", \"datasens-raw\")\n",
    "\n",
    "# Configuration PostgreSQL (SGBD) - 36/37 tables E1_v3\n",
    "PG_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.getenv(\"POSTGRES_PORT\", \"5433\"))\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\", \"postgres\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\", \"postgres\")\n",
    "PG_PASS = os.getenv(\"POSTGRES_PASS\", \"postgres\")\n",
    "PG_URL = f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "\n",
    "# Cl√©s API (pour toutes les sources E1_v3)\n",
    "KAGGLE_USERNAME = os.getenv(\"KAGGLE_USERNAME\")\n",
    "KAGGLE_KEY = os.getenv(\"KAGGLE_KEY\")\n",
    "OWM_API_KEY = os.getenv(\"OWM_API_KEY\")\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "GDELT_BASE = os.getenv(\"GDELT_BASE\", \"http://data.gdeltproject.org/gkg/\")\n",
    "\n",
    "print(\"\\nüîê Configuration MinIO (DataLake) :\")\n",
    "print(f\"   ‚Ä¢ Endpoint : {MINIO_ENDPOINT}\")\n",
    "print(f\"   ‚Ä¢ Bucket   : {MINIO_BUCKET}\")\n",
    "\n",
    "print(\"\\nüóÑÔ∏è Configuration PostgreSQL (SGBD) :\")\n",
    "print(f\"   ‚Ä¢ Host     : {PG_HOST}:{PG_PORT}\")\n",
    "print(f\"   ‚Ä¢ Database : {PG_DB}\")\n",
    "print(f\"   ‚Ä¢ User     : {PG_USER}\")\n",
    "print(f\"   ‚Ä¢ Sch√©ma   : 36/37 tables (T01-T36 + T37) selon datasens_MPD.sql\")\n",
    "\n",
    "print(\"\\nüîë Cl√©s API (E1_v3 - Toutes les sources) :\")\n",
    "print(f\"   ‚Ä¢ Kaggle        : {'‚úÖ Configur√©e' if KAGGLE_USERNAME else '‚ùå Manquante'}\")\n",
    "print(f\"   ‚Ä¢ OpenWeatherMap: {'‚úÖ Configur√©e' if OWM_API_KEY else '‚ùå Manquante'}\")\n",
    "print(f\"   ‚Ä¢ NewsAPI       : {'‚úÖ Configur√©e' if NEWSAPI_KEY else '‚ùå Manquante'}\")\n",
    "\n",
    "# Arborescence compl√®te pour TOUTES les sources E1_v3\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "LOGS_DIR = PROJECT_ROOT / 'logs'\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Tous les sous-dossiers pour sources compl√®tes E1_v3 (selon docs)\n",
    "folders = [\n",
    "    \"kaggle\",                    # Source 1 : Fichier plat\n",
    "    \"api/owm\",                   # Source 2 : API OpenWeatherMap\n",
    "    \"api/newsapi\",               # Source 2 : API NewsAPI\n",
    "    \"rss\",                       # Source 3 : Flux RSS Multi-Sources\n",
    "    \"scraping/multi\",            # Source 4 : Web Scraping Multi (6 sources)\n",
    "    \"scraping/viepublique\",      # Source 4 : Vie-publique.fr\n",
    "    \"scraping/datagouv\",         # Source 4 : data.gouv.fr\n",
    "    \"gdelt\",                     # Source 5 : GDELT Big Data\n",
    "    \"manifests\"                  # Manifest JSON par run\n",
    "]\n",
    "for sub in folders:\n",
    "    (RAW_DIR / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Arborescence cr√©√©e: {RAW_DIR}\")\n",
    "print(f\"   ‚Ä¢ {len(folders)} sous-dossiers pr√™ts (toutes sources E1_v3)\")\n",
    "\n",
    "# Logging\n",
    "stamp = datetime.now(UTC).strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = LOGS_DIR / f\"collecte_{stamp}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logging.info(\"Syst√®me de logging initialis√© - E1_v3 (36/37 tables)\")\n",
    "print(f\"üìÑ Log: {log_file}\")\n",
    "\n",
    "# Fonctions utilitaires\n",
    "def ts() -> str:\n",
    "    \"\"\"Timestamp UTC ISO compact (YYYYMMDDTHHMMSSZ)\"\"\"\n",
    "    return dt.datetime.now(tz=dt.UTC).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "def sha256_hash(s: str) -> str:\n",
    "    \"\"\"Hash SHA256 pour d√©duplication\"\"\"\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "print(f\"\\nüîß Utilitaires : ts()={ts()}, sha256()={sha256_hash('test')[:16]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration E1_v3 termin√©e !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üé¨ DASHBOARD NARRATIF - O√ô SOMMES-NOUS ?\n",
    "# ============================================================\n",
    "# Ce dashboard vous guide √† travers le pipeline DataSens E1\n",
    "# Il montre la progression et l'√©tat actuel des donn√©es\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üé¨ FIL D'ARIANE VISUEL - PIPELINE DATASENS E1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er figure dashboard\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.axis('off')\n",
    "\n",
    "# √âtapes du pipeline\n",
    "etapes = [\n",
    "    {\"nom\": \"üì• COLLECTE\", \"status\": \"‚úÖ\", \"desc\": \"Sources brutes\"},\n",
    "    {\"nom\": \"‚òÅÔ∏è DATALAKE\", \"status\": \"‚úÖ\", \"desc\": \"MinIO Raw\"},\n",
    "    {\"nom\": \"üßπ NETTOYAGE\", \"status\": \"üîÑ\", \"desc\": \"D√©duplication\"},\n",
    "    {\"nom\": \"üíæ ETL\", \"status\": \"‚è≥\", \"desc\": \"PostgreSQL\"},\n",
    "    {\"nom\": \"üìä ANNOTATION\", \"status\": \"‚è≥\", \"desc\": \"Enrichissement\"},\n",
    "    {\"nom\": \"üì¶ EXPORT\", \"status\": \"‚è≥\", \"desc\": \"Dataset IA\"}\n",
    "]\n",
    "\n",
    "# Couleurs selon statut\n",
    "colors = {\n",
    "    \"‚úÖ\": \"#4ECDC4\",\n",
    "    \"üîÑ\": \"#FECA57\", \n",
    "    \"‚è≥\": \"#E8E8E8\"\n",
    "}\n",
    "\n",
    "# Dessiner timeline\n",
    "y_pos = 4\n",
    "x_start = 1\n",
    "x_spacing = 1.4\n",
    "\n",
    "for i, etape in enumerate(etapes):\n",
    "    x_pos = x_start + i * x_spacing\n",
    "    \n",
    "    # Cercle √©tape\n",
    "    circle = plt.Circle((x_pos, y_pos), 0.25, color=colors[etape[\"status\"]], zorder=3)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(x_pos, y_pos, etape[\"status\"], ha='center', va='center', fontsize=14, fontweight='bold', zorder=4)\n",
    "    \n",
    "    # Nom √©tape\n",
    "    ax.text(x_pos, y_pos - 0.6, etape[\"nom\"], ha='center', va='top', fontsize=11, fontweight='bold')\n",
    "    ax.text(x_pos, y_pos - 0.85, etape[\"desc\"], ha='center', va='top', fontsize=9, style='italic')\n",
    "    \n",
    "    # Fl√®che vers prochaine √©tape\n",
    "    if i < len(etapes) - 1:\n",
    "        ax.arrow(x_pos + 0.3, y_pos, x_spacing - 0.6, 0, \n",
    "                head_width=0.1, head_length=0.15, fc='gray', ec='gray', zorder=2)\n",
    "\n",
    "# Titre narratif\n",
    "ax.text(5, 5.5, \"üéØ PROGRESSION DU PIPELINE E1\", ha='center', va='center', \n",
    "        fontsize=16, fontweight='bold', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# L√©gende\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor='#4ECDC4', label='Termin√©'),\n",
    "    mpatches.Patch(facecolor='#FECA57', label='En cours'),\n",
    "    mpatches.Patch(facecolor='#E8E8E8', label='√Ä venir')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=10)\n",
    "\n",
    "# Statistiques rapides (si disponibles)\n",
    "stats_text = \"\\nüìä SNAPSHOT ACTUEL :\\n\"\n",
    "try:\n",
    "    # Essayer de charger des stats si base disponible\n",
    "    stats_text += \"   ‚Ä¢ Pipeline en cours d'ex√©cution...\\n\"\n",
    "except:\n",
    "    stats_text += \"   ‚Ä¢ D√©marrage du pipeline...\\n\"\n",
    "\n",
    "ax.text(5, 1.5, stats_text, ha='center', va='center', fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.title(\"üé¨ FIL D'ARIANE VISUEL - Accompagnement narratif du jury\", \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Le fil d'Ariane vous guide √©tape par √©tape √† travers le pipeline\")\n",
    "print(\"   Chaque visualisation s'inscrit dans cette progression narrative\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test des connexions MinIO et PostgreSQL\n",
    "\n",
    "print(\"üîå Test des connexions...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Connexion MinIO\n",
    "try:\n",
    "    from minio import Minio\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        MINIO_ENDPOINT.replace(\"http://\", \"\").replace(\"https://\", \"\"),\n",
    "        access_key=MINIO_ACCESS_KEY,\n",
    "        secret_key=MINIO_SECRET_KEY,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # Cr√©er le bucket s'il n'existe pas\n",
    "    if not minio_client.bucket_exists(MINIO_BUCKET):\n",
    "        minio_client.make_bucket(MINIO_BUCKET)\n",
    "        print(f\"‚úÖ MinIO : Bucket '{MINIO_BUCKET}' cr√©√©\")\n",
    "    else:\n",
    "        print(f\"‚úÖ MinIO : Bucket '{MINIO_BUCKET}' existe d√©j√†\")\n",
    "    \n",
    "    # Lister les objets existants\n",
    "    objects = list(minio_client.list_objects(MINIO_BUCKET, recursive=False))\n",
    "    print(f\"   ‚Ä¢ {len(list(objects))} objets existants dans le bucket\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå MinIO : Erreur de connexion - {e}\")\n",
    "    print(\"   üí° V√©rifiez que Docker Compose est lanc√© : docker compose up -d\")\n",
    "    minio_client = None\n",
    "\n",
    "# Connexion PostgreSQL\n",
    "try:\n",
    "    from sqlalchemy import create_engine, text\n",
    "    \n",
    "    engine = create_engine(PG_URL, future=True)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT 1 as test\"))\n",
    "        test_value = result.scalar()\n",
    "    \n",
    "    if test_value == 1:\n",
    "        print(f\"‚úÖ PostgreSQL : Connexion r√©ussie ({PG_HOST}:{PG_PORT}/{PG_DB})\")\n",
    "        \n",
    "        # Compter les tables existantes\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"\"\"\n",
    "                SELECT COUNT(*) FROM information_schema.tables \n",
    "                WHERE table_schema = 'public'\n",
    "            \"\"\"))\n",
    "            nb_tables = result.scalar()\n",
    "            print(f\"   ‚Ä¢ {nb_tables} tables existantes dans la base\")\n",
    "            print(f\"   ‚Ä¢ E1_v3 attend 36/37 tables (architecture compl√®te selon datasens_MPD.sql)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è PostgreSQL : Connexion OK mais test inattendu\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå PostgreSQL : Erreur de connexion - {e}\")\n",
    "    print(\"   üí° V√©rifiez que Docker Compose est lanc√© : docker compose up -d\")\n",
    "    engine = None\n",
    "\n",
    "print(\"\\n‚úÖ Tests de connexion termin√©s !\")\n",
    "print(\"   ‚û°Ô∏è Passez au notebook 02_schema_create.ipynb pour cr√©er les 36/37 tables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Introduction & Objectifs E1\n",
    "\n",
    "**DataSens E1** : Construction du socle data avec :\n",
    "- ‚úÖ Mod√©lisation Merise (MCD ‚Üí MLD ‚Üí MPD cibl√©)\n",
    "- ‚úÖ Cr√©ation et remplissage PostgreSQL (18 tables)\n",
    "- ‚úÖ CRUD complet test√© depuis le notebook\n",
    "- ‚úÖ Ingestion r√©elle des **5 types de sources** :\n",
    "  1. **Fichier plat** : Kaggle CSV\n",
    "  2. **Base de donn√©es** : Export Kaggle SQLite ‚Üí Postgres\n",
    "  3. **API** : OpenWeatherMap (m√©t√©o communes)\n",
    "  4. **Web Scraping** : MonAvisCitoyen (dry-run, robots.txt)\n",
    "  5. **Big Data** : GDELT GKG (√©chantillon journalier)\n",
    "- ‚úÖ Tra√ßabilit√© et gouvernance (flux, manifest, versionning Git)\n",
    "\n",
    "**Mode d'ex√©cution** : Cellule par cellule (pas √† pas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç V√©rification environnement Python\n",
      "================================================================================\n",
      "Python version : 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Python executable : c:\\Users\\Utilisateur\\Desktop\\Datasens_Project\\.venv\\Scripts\\python.exe\n",
      "‚úÖ Python 3.12.7 OK\n"
     ]
    }
   ],
   "source": [
    "# V√©rification environnement Python\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç V√©rification environnement Python\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Python version : {sys.version}\")\n",
    "print(f\"Python executable : {sys.executable}\")\n",
    "\n",
    "# V√©rifier version Python >= 3.11\n",
    "version_info = sys.version_info\n",
    "if version_info.major >= 3 and version_info.minor >= 11:\n",
    "    print(f\"‚úÖ Python {version_info.major}.{version_info.minor}.{version_info.micro} OK\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Python {version_info.major}.{version_info.minor} ‚Äî Recommand√© Python 3.11+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Packages Python install√©s\n",
      "================================================================================\n",
      "\n",
      "V√©rification packages critiques :\n",
      "\n",
      "  ‚úÖ pandas                   2.3.3\n",
      "  ‚úÖ SQLAlchemy               2.0.44\n",
      "  ‚úÖ psycopg2-binary          2.9.11\n",
      "  ‚úÖ requests                 2.32.5\n",
      "  ‚úÖ beautifulsoup4           4.14.2\n",
      "  ‚úÖ python-dotenv            1.2.1\n",
      "\n",
      "üìã Liste compl√®te (pip list) :\n",
      "Package                  Version\n",
      "------------------------ -----------\n",
      "annotated-types          0.7.0\n",
      "argon2-cffi              25.1.0\n",
      "argon2-cffi-bindings     25.1.0\n",
      "asttokens                3.0.0\n",
      "beautifulsoup4           4.14.2\n",
      "cachetools               6.2.1\n",
      "certifi                  2025.10.5\n",
      "cffi                     2.0.0\n",
      "charset-normalizer       3.4.4\n",
      "colorama                 0.4.6\n",
      "comm                     0.2.3\n",
      "contourpy                1.3.3\n",
      "cycler                   0.12.1\n",
      "debugpy            ...\n"
     ]
    }
   ],
   "source": [
    "# Liste des packages install√©s\n",
    "print(\"\\nüì¶ Packages Python install√©s\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "packages_to_check = [\n",
    "    \"pandas\",\n",
    "    \"sqlalchemy\",\n",
    "    \"psycopg2\",\n",
    "    \"requests\",\n",
    "    \"beautifulsoup4\",\n",
    "    \"python-dotenv\",\n",
    "]\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"list\"],\n",
    "    check=False, capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    installed_packages = result.stdout\n",
    "    print(\"\\nV√©rification packages critiques :\\n\")\n",
    "    for pkg in packages_to_check:\n",
    "        if pkg in installed_packages.lower():\n",
    "            version = [line for line in installed_packages.split(\"\\n\") if pkg.lower() in line.lower()]\n",
    "            if version:\n",
    "                print(f\"  ‚úÖ {version[0]}\")\n",
    "            else:\n",
    "                print(f\"  ‚úÖ {pkg} (version non d√©tect√©e)\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {pkg} - √Ä installer : pip install {pkg}\")\n",
    "\n",
    "    print(\"\\nüìã Liste compl√®te (pip list) :\")\n",
    "    print(installed_packages[:500] + \"...\" if len(installed_packages) > 500 else installed_packages)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Impossible d'ex√©cuter pip list\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Cr√©ation de l'arborescence projet\n",
    "\n",
    "Structure du projet selon les conventions DataSens :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Cr√©ation de l'arborescence projet\n",
      "================================================================================\n",
      "Racine projet : c:\\Users\\Utilisateur\\Desktop\\Datasens_Project\n",
      "\n",
      "üìÇ Dossiers cr√©√©s :\n",
      "‚úÖ data/\n",
      "   ‚úÖ data/raw/\n",
      "   ‚úÖ data/silver/\n",
      "   ‚úÖ data/gold/\n",
      "‚úÖ data/raw/\n",
      "   ‚úÖ data/raw/kaggle/\n",
      "   ‚úÖ data/raw/api/\n",
      "   ‚úÖ data/raw/scraping/\n",
      "   ‚úÖ data/raw/gdelt/\n",
      "   ‚úÖ data/raw/manifests/\n",
      "‚úÖ data/raw/api/\n",
      "   ‚úÖ data/raw/api/owm/\n",
      "‚úÖ data/raw/scraping/\n",
      "   ‚úÖ data/raw/scraping/mav/\n",
      "‚úÖ logs/\n",
      "‚úÖ docs/\n",
      "‚úÖ notebooks/\n",
      "\n",
      "‚úÖ Arborescence pr√™te ! (17 dossiers)\n"
     ]
    }
   ],
   "source": [
    "# D√©terminer la racine du projet (parent de notebooks/)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == \"notebooks\" else NOTEBOOK_DIR\n",
    "\n",
    "print(\"üìÅ Cr√©ation de l'arborescence projet\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Racine projet : {PROJECT_ROOT}\")\n",
    "\n",
    "# Arborescence √† cr√©er\n",
    "directories = {\n",
    "    \"data\": [\"raw\", \"silver\", \"gold\"],\n",
    "    \"data/raw\": [\"kaggle\", \"api\", \"scraping\", \"gdelt\", \"manifests\"],\n",
    "    \"data/raw/api\": [\"owm\"],\n",
    "    \"data/raw/scraping\": [\"mav\"],  # MonAvisCitoyen\n",
    "    \"logs\": [],\n",
    "    \"docs\": [],\n",
    "    \"notebooks\": [],\n",
    "}\n",
    "\n",
    "created = []\n",
    "for base_dir, subdirs in directories.items():\n",
    "    base_path = PROJECT_ROOT / base_dir\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    created.append(f\"‚úÖ {base_dir}/\")\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        sub_path = base_path / subdir\n",
    "        sub_path.mkdir(parents=True, exist_ok=True)\n",
    "        created.append(f\"   ‚úÖ {base_dir}/{subdir}/\")\n",
    "\n",
    "print(\"\\nüìÇ Dossiers cr√©√©s :\")\n",
    "for item in created:\n",
    "    print(item)\n",
    "\n",
    "print(f\"\\n‚úÖ Arborescence pr√™te ! ({len(created)} dossiers)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration .env\n",
    "\n",
    "Cr√©ation du fichier `.env` de d√©veloppement avec variables PostgreSQL et API keys.\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT** : Ce fichier ne doit JAMAIS √™tre commit√© (dans .gitignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier .env charg√© : c:\\Users\\Utilisateur\\Desktop\\Datasens_Project\\.env\n",
      "\n",
      "üîê Configuration charg√©e :\n",
      "   POSTGRES_HOST : localhost\n",
      "   POSTGRES_PORT : 5432\n",
      "   POSTGRES_DB   : datasens\n",
      "   POSTGRES_USER : ds_user\n",
      "   OWM_API_KEY   : ‚úÖ Configur√©e\n",
      "   KAGGLE_USERNAME: ‚úÖ Configur√©e\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charger .env s'il existe\n",
    "env_path = PROJECT_ROOT / \".env\"\n",
    "env_loaded = load_dotenv(env_path)\n",
    "\n",
    "if env_loaded:\n",
    "    print(f\"‚úÖ Fichier .env charg√© : {env_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Fichier .env non trouv√© : {env_path}\")\n",
    "    print(\"   Cr√©ation d'un .env.example pour r√©f√©rence...\")\n",
    "\n",
    "    # Cr√©er un .env.example\n",
    "    env_example = PROJECT_ROOT / \".env.example\"\n",
    "    env_example.write_text(\"\"\"\n",
    "# PostgreSQL\n",
    "POSTGRES_HOST=localhost\n",
    "POSTGRES_PORT=5432\n",
    "POSTGRES_DB=datasens\n",
    "POSTGRES_USER=ds_user\n",
    "POSTGRES_PASS=ds_pass\n",
    "\n",
    "# API Keys (optionnelles pour d√©mo)\n",
    "OWM_API_KEY=your_openweathermap_key_here\n",
    "KAGGLE_USERNAME=your_kaggle_username\n",
    "KAGGLE_KEY=your_kaggle_key\n",
    "\n",
    "# Git (optionnel)\n",
    "GIT_USER_NAME=Your Name\n",
    "GIT_USER_EMAIL=your.email@example.com\n",
    "\"\"\")\n",
    "    print(f\"   üìÑ Template cr√©√© : {env_example}\")\n",
    "\n",
    "# Afficher configuration (sans afficher les mots de passe)\n",
    "print(\"\\nüîê Configuration charg√©e :\")\n",
    "print(f\"   POSTGRES_HOST : {os.getenv('POSTGRES_HOST', 'localhost')}\")\n",
    "print(f\"   POSTGRES_PORT : {os.getenv('POSTGRES_PORT', '5432')}\")\n",
    "print(f\"   POSTGRES_DB   : {os.getenv('POSTGRES_DB', 'datasens')}\")\n",
    "print(f\"   POSTGRES_USER : {os.getenv('POSTGRES_USER', 'ds_user')}\")\n",
    "print(f\"   OWM_API_KEY   : {'‚úÖ Configur√©e' if os.getenv('OWM_API_KEY') else '‚ùå Manquante (optionnelle)'}\")\n",
    "print(f\"   KAGGLE_USERNAME: {'‚úÖ Configur√©e' if os.getenv('KAGGLE_USERNAME') else '‚ùå Manquante (optionnelle)'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Connexion PostgreSQL\n",
    "\n",
    "Test de connexion √† la base PostgreSQL (via Docker ou locale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Test connexion PostgreSQL\n",
      "================================================================================\n",
      "URL : postgresql://ds_user:***@localhost:5432/datasens\n",
      "‚úÖ Connexion PostgreSQL r√©ussie !\n",
      "   üóÑÔ∏è Base de donn√©es : datasens\n",
      "   üë§ Utilisateur : ds_user\n",
      "   üìç Serveur : localhost:5432\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# R√©cup√©rer variables d'environnement\n",
    "PG_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.getenv(\"POSTGRES_PORT\", \"5432\"))\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\", \"datasens\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\", \"ds_user\")\n",
    "PG_PASS = os.getenv(\"POSTGRES_PASS\", \"ds_pass\")\n",
    "\n",
    "# URL de connexion\n",
    "PG_URL = f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "\n",
    "print(\"üîå Test connexion PostgreSQL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"URL : postgresql://{PG_USER}:***@{PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "\n",
    "try:\n",
    "    engine = create_engine(PG_URL, future=True)\n",
    "\n",
    "    # Test simple : SELECT 1\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT 1 as test\"))\n",
    "        test_value = result.scalar()\n",
    "\n",
    "    if test_value == 1:\n",
    "        print(\"‚úÖ Connexion PostgreSQL r√©ussie !\")\n",
    "        print(f\"   üóÑÔ∏è Base de donn√©es : {PG_DB}\")\n",
    "        print(f\"   üë§ Utilisateur : {PG_USER}\")\n",
    "        print(f\"   üìç Serveur : {PG_HOST}:{PG_PORT}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Connexion OK mais test inattendu\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur de connexion : {e}\")\n",
    "    print(\"\\nüí° V√©rifications :\")\n",
    "    print(\"   1. Docker Compose est-il d√©marr√© ? ‚Üí docker-compose up -d\")\n",
    "    print(\"   2. PostgreSQL est-il accessible sur le port 5432 ?\")\n",
    "    print(\"   3. Les credentials dans .env sont-ils corrects ?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Initialisation Git\n",
    "\n",
    "Initialisation du d√©p√¥t Git (si ce n'est pas d√©j√† fait) et premier commit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ V√©rification Git\n",
      "================================================================================\n",
      "‚úÖ git version 2.49.0.windows.1\n",
      "\n",
      "‚úÖ D√©p√¥t Git d√©j√† initialis√© : c:\\Users\\Utilisateur\\Desktop\\Datasens_Project\n",
      "\n",
      "üìã Fichiers modifi√©s/non suivis :\n",
      " D docs/FIX_PDF_QUICK.md\n",
      " M docs/GUIDE_TECHNIQUE_JURY.md\n",
      " M docs/GUIDE_TECHNIQUE_JURY.pdf\n",
      " D docs/PDF_FORMATTING_INSTRUCTIONS.md\n",
      " D docs/fix_pdf_formatting.ps1\n",
      " M notebooks/datasens_E1_v2.ipynb\n",
      "?? docs/ARCHITECTURE_PIPELINE_E1.md\n",
      "?? docs/GUIDE_TECHNIQUE_JURY_V2.md\n",
      "?? docs/datasens_dictionary.md\n",
      "?? docs/e1_schema.sql\n",
      "?? notebooks/01_setup_env.ipynb\n",
      "?? notebooks/02_schema_create.ipynb\n",
      "?? notebooks/03_ingest_sources.ipynb\n",
      "?? notebooks/04_crud_tests.ipynb\n",
      "?? notebooks/05_snapshot_and_readme.ipynb\n",
      "?? notebooks/README_VERSIONNING.md\n",
      "?? notebooks/data/raw/api/\n",
      "?? notebooks/data/raw/gdelt/\n",
      "?? notebooks/data/raw/kaggle/\n",
      "?? notebooks/data/raw/manifests/\n",
      "?? notebooks/data/raw/rss/\n",
      "?? notebooks/data/raw/scraping/multi/scraping_multi_20251029T122841Z.csv\n",
      "\n",
      "\n",
      "‚úÖ Setup environnement termin√© !\n",
      "   ‚û°Ô∏è Passez au notebook 02_schema_create.ipynb\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"üîÑ V√©rification Git\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# V√©rifier si Git est install√©\n",
    "try:\n",
    "    git_version = subprocess.run(\n",
    "        [\"git\", \"--version\"],\n",
    "        check=False, capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(f\"‚úÖ {git_version.stdout.strip()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Git non install√© ‚Äî Installation requise : https://git-scm.com/\")\n",
    "    exit(1)\n",
    "\n",
    "# V√©rifier si le projet est d√©j√† un d√©p√¥t Git\n",
    "git_dir = PROJECT_ROOT / \".git\"\n",
    "if git_dir.exists():\n",
    "    print(f\"\\n‚úÖ D√©p√¥t Git d√©j√† initialis√© : {PROJECT_ROOT}\")\n",
    "\n",
    "    # Afficher git status\n",
    "    try:\n",
    "        status = subprocess.run(\n",
    "            [\"git\", \"status\", \"--short\"],\n",
    "            check=False, cwd=PROJECT_ROOT,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        if status.stdout.strip():\n",
    "            print(\"\\nüìã Fichiers modifi√©s/non suivis :\")\n",
    "            print(status.stdout)\n",
    "        else:\n",
    "            print(\"\\nüìã Aucun changement (working tree clean)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Impossible de lire git status : {e}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è D√©p√¥t Git non initialis√© dans {PROJECT_ROOT}\")\n",
    "    print(\"   üí° Initialisation manuelle recommand√©e :\")\n",
    "    print(f\"      cd {PROJECT_ROOT}\")\n",
    "    print(\"      git init\")\n",
    "    print(\"      git add .\")\n",
    "    print('      git commit -m \"Initial commit E1\"')\n",
    "\n",
    "print(\"\\n‚úÖ Setup environnement termin√© !\")\n",
    "print(\"   ‚û°Ô∏è Passez au notebook 02_schema_create.ipynb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}