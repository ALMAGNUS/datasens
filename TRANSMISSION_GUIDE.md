# ðŸ“¦ GUIDE TRANSMISSION - DataSens Project

## ðŸŽ¯ MÃ©thodes de Transmission

### Option 1: GitHub Repository (RecommandÃ©) âœ…

#### Ã‰tape 1: Nettoyer le repository
```powershell
# Supprimer fichiers temporaires
git clean -fd
git reset --hard HEAD

# Commit changements
git add .
git commit -m "feat: Phase 2 refactoring + GDELT BigData + ML Annotations"
```

#### Ã‰tape 2: Pousser vers GitHub
```powershell
# Si vous avez dÃ©jÃ  un remote origin
git push origin main

# Si remote n'existe pas, crÃ©er nouveau repo sur github.com puis:
git remote add origin https://github.com/VOTRE_USERNAME/DataSens.git
git branch -M main
git push -u origin main
```

#### Ã‰tape 3: Partager URL
```
Donner au client: https://github.com/VOTRE_USERNAME/DataSens
```

---

### Option 2: Archive Docker (Sans GitHub)

#### Ã‰tape 1: CrÃ©er archive propre
```powershell
# Nettoyer donnÃ©es temporaires
Remove-Item -Recurse -Force data/raw/*.csv, data/silver/*, data/gold/* -ErrorAction SilentlyContinue
Remove-Item -Recurse -Force logs/*.log, artifacts/*.json -ErrorAction SilentlyContinue

# CrÃ©er archive ZIP
Compress-Archive -Path . -DestinationPath ../DataSens_Production.zip -Force
```

#### Ã‰tape 2: Partager via cloud
- Google Drive / OneDrive / Dropbox
- WeTransfer (jusqu'Ã  2GB gratuit)
- Email (si < 25MB)

---

### Option 3: Docker Image (Production-Ready)

#### Ã‰tape 1: Build image Docker complÃ¨te
```powershell
# CrÃ©er Dockerfile production
docker build -t datasens:production -f Dockerfile.prod .

# Sauvegarder image
docker save datasens:production -o datasens_production.tar

# Compresser
gzip datasens_production.tar
```

#### Ã‰tape 2: Partager fichier .tar.gz
```
Fichier: datasens_production.tar.gz
Taille: ~500MB-1GB
Client peut charger avec: docker load -i datasens_production.tar.gz
```

---

## ðŸ§¹ Checklist Nettoyage Avant Transmission

### Fichiers Ã  Supprimer
```powershell
# Supprimer fichiers dev/debug
Remove-Item check_columns.py -ErrorAction SilentlyContinue
Remove-Item -Recurse docs/logs/ -ErrorAction SilentlyContinue
Remove-Item -Recurse notebooks/datasens_E1_v3/data/ -ErrorAction SilentlyContinue
Remove-Item -Recurse notebooks/datasens_E1_v3/logs/ -ErrorAction SilentlyContinue
```

### Fichiers Ã  Garder
```
âœ… README.md (documentation principale)
âœ… README_DEMO.md (guide dÃ©monstration)
âœ… requirements.txt (dÃ©pendances Python)
âœ… docker-compose.yml (infrastructure)
âœ… pyproject.toml (configuration projet)
âœ… .env.example (template configuration)
âœ… datasens/ (modules refactorisÃ©s)
âœ… notebooks/datasens_E1_v3/ (5 notebooks dÃ©mo)
âœ… docs/PHASE3_OPTIMISATIONS.md
âœ… docs/GUIDE_TECHNIQUE_E1.md
âœ… docs/datasens_MPD.sql (schÃ©ma DB)
```

### Dossiers Structure (vides OK)
```
âœ… data/raw/.gitkeep
âœ… data/silver/.gitkeep
âœ… data/gold/.gitkeep
âœ… data/dataset/.gitkeep
âœ… logs/.gitkeep
âœ… artifacts/.gitkeep
```

---

## ðŸ“‹ Fichiers de Configuration Requis

### 1. `.env.example` (template)
```bash
# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=datasens_user
POSTGRES_PASSWORD=CHANGE_ME
POSTGRES_DB=datasens

# MinIO Configuration
MINIO_ENDPOINT=http://localhost:9000
MINIO_ACCESS_KEY=admin
MINIO_SECRET_KEY=CHANGE_ME
MINIO_BUCKET=datasens-raw

# API Keys (optional)
OWM_API_KEY=your_openweathermap_key
NEWSAPI_KEY=your_newsapi_key
```

### 2. `INSTALLATION.md`
```markdown
# Installation DataSens

## PrÃ©requis
- Docker Desktop 4.25+
- Python 3.11+
- Git 2.40+

## Installation Rapide
1. Clone repository: `git clone <URL>`
2. Copy `.env.example` to `.env`
3. Update credentials in `.env`
4. Launch: `docker-compose up -d`
5. Install Python deps: `pip install -e .`
6. Open notebooks: `notebooks/datasens_E1_v3/`

## Validation
Run notebook `01_setup_env.ipynb` to verify connections.
```

---

## ðŸš€ Commandes de Transmission

### MÃ©thode Rapide: Git Push
```powershell
# Nettoyage + Commit + Push (3 commandes)
git add .
git commit -m "feat: Production-ready DataSens ETL Pipeline"
git push origin main

# Partager URL: https://github.com/VOTRE_USERNAME/DataSens
```

### MÃ©thode Archive ZIP
```powershell
# CrÃ©er archive propre (exclut .git, __pycache__, etc.)
$exclude = @('*.pyc', '__pycache__', '.git', '.venv', 'data/raw/*.csv')
Compress-Archive -Path @(
    'datasens',
    'notebooks/datasens_E1_v3',
    'docs',
    'docker-compose.yml',
    'requirements.txt',
    'pyproject.toml',
    'README.md',
    'README_DEMO.md',
    '.env.example'
) -DestinationPath ../DataSens_Production.zip -Force
```

---

## ðŸ“§ Message de Transmission

### Email Template
```
Objet: DataSens ETL Pipeline - Livraison Production

Bonjour,

Voici le projet DataSens ETL Pipeline finalisÃ©.

ðŸ”— GitHub Repository: https://github.com/USERNAME/DataSens
ðŸ“– Documentation: README.md + README_DEMO.md
ðŸš€ Quick Start: docker-compose up -d

Architecture:
- 5 collectors (Kaggle, RSS, OWM, WebScraping, GDELT)
- 2 annotators (SpaCy NER, YAKE Keywords)
- PostgreSQL (36 tables Medallion)
- MinIO S3-compatible storage
- Phase 3 optimizations (retry, pooling, cache)

Demo:
- Notebooks: datasens_E1_v3/ (01 â†’ 05)
- Guide: README_DEMO.md
- Duration: 25 minutes

Credentials:
- PostgreSQL: datasens_user / voir .env
- MinIO: admin / voir .env
- Config: .env.example Ã  copier en .env

Support:
- Documentation: docs/GUIDE_TECHNIQUE_E1.md
- Schema DB: docs/datasens_MPD.sql
- Optimisations: docs/PHASE3_OPTIMISATIONS.md

Cordialement,
```

---

## âœ… Validation Finale

### Test Avant Transmission
```powershell
# 1. VÃ©rifier structure
tree /F datasens
tree /F notebooks/datasens_E1_v3

# 2. VÃ©rifier dÃ©pendances
pip install -e .
python -c "import datasens; print('OK')"

# 3. VÃ©rifier Docker
docker-compose up -d
docker ps  # Voir postgres + minio

# 4. Tester notebook
# Ouvrir 01_setup_env.ipynb â†’ ExÃ©cuter cellules 1-3
```

### Checklist
- [ ] .env.example prÃ©sent (pas de credentials hardcodÃ©s)
- [ ] README.md Ã  jour avec instructions
- [ ] README_DEMO.md prÃ©sent
- [ ] requirements.txt complet
- [ ] docker-compose.yml fonctionnel
- [ ] Notebooks exÃ©cutables (pas d'erreurs)
- [ ] Module datasens importable
- [ ] Documentation technique prÃ©sente
- [ ] Pas de fichiers sensibles (.env, logs, data)
- [ ] .gitignore configurÃ©

---

## ðŸŽ¯ Recommandation Finale

**GitHub (Option 1)** = Meilleur choix:
- Version control
- Collaboration facile
- Clone en 1 commande
- Issues/PRs disponibles
- CI/CD intÃ©grable

**Commandes finales:**
```powershell
git add .
git commit -m "feat: DataSens Production Ready - Phase 2 Complete"
git push origin main
```

**Partager:** `https://github.com/VOTRE_USERNAME/DataSens`

Le client peut cloner en 1 commande:
```bash
git clone https://github.com/VOTRE_USERNAME/DataSens.git
cd DataSens
cp .env.example .env
# Modifier .env avec credentials
docker-compose up -d
pip install -e .
```

âœ… **Ready for Production!**
