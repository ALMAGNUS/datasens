# ğŸ”„ PIPELINE ETL DATASENS - Architecture ComplÃ¨te

## âœ… Oui, votre architecture est un ETL classique !

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ”µ EXTRACT (E)                               â”‚
â”‚                    Collecte Multi-Sources                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ“ SOURCE 1 : Fichier Plat                                         â”‚
â”‚  â”œâ”€ Kaggle CSV (Sentiment140)           â†’ 24,683 documents          â”‚
â”‚  â””â”€ Ã‰vÃ©nements Historiques CSV (1995-2025) â†’ 37 Ã©vÃ©nements          â”‚
â”‚                                                                      â”‚
â”‚  ğŸ—„ï¸ SOURCE 2 : Base de DonnÃ©es                                      â”‚
â”‚  â””â”€ Kaggle CSV â†’ PostgreSQL (50%)       â†’ 24,683 documents          â”‚
â”‚                                                                      â”‚
â”‚  ğŸŒ SOURCE 3 : Web Scraping                                          â”‚
â”‚  â”œâ”€ Reddit (r/france)                    â†’ ~50 posts                â”‚
â”‚  â”œâ”€ YouTube Comments                     â†’ ~50 comments             â”‚
â”‚  â”œâ”€ SignalConso                          â†’ ~50 signalements         â”‚
â”‚  â”œâ”€ Trustpilot                           â†’ ~50 avis                 â”‚
â”‚  â”œâ”€ Vie-publique.fr                      â†’ ~30 consultations        â”‚
â”‚  â””â”€ data.gouv.fr                         â†’ ~35 datasets             â”‚
â”‚                                          TOTAL: 265 documents        â”‚
â”‚                                                                      â”‚
â”‚  ğŸ”Œ SOURCE 4 : API                                                   â”‚
â”‚  â”œâ”€ RSS Multi-Sources (3 flux)           â†’ 99 articles              â”‚
â”‚  â”‚   â€¢ Franceinfo                                                    â”‚
â”‚  â”‚   â€¢ 20 Minutes                                                    â”‚
â”‚  â”‚   â€¢ Le Monde                                                      â”‚
â”‚  â””â”€ OpenWeatherMap (4 villes)           â†’ 8 relevÃ©s mÃ©tÃ©o           â”‚
â”‚                                                                      â”‚
â”‚  ğŸ’¾ SOURCE 5 : Big Data                                              â”‚
â”‚  â””â”€ GDELT GKG France (agrÃ©gÃ©)           â†’ 57 Ã©vÃ©nements             â”‚
â”‚                                                                      â”‚
â”‚  ğŸ“œ SOURCE BONUS : DonnÃ©es Historiques                               â”‚
â”‚  â””â”€ Ã‰vÃ©nements France (CSV)              â†’ 37 Ã©vÃ©nements            â”‚
â”‚      â€¢ 8 attentats (2012-2020)                                       â”‚
â”‚      â€¢ 5 grÃ¨ves nationales (1995-2023)                               â”‚
â”‚      â€¢ 4 catastrophes naturelles (1999-2022)                         â”‚
â”‚      â€¢ 11 changements politiques (2007-2024)                         â”‚
â”‚      â€¢ 3 crises Ã©conomiques (2008-2022)                              â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â¬‡ï¸ FLUX DE DONNÃ‰ES
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸŸ¡ TRANSFORM (T)                             â”‚
â”‚                    Nettoyage & Enrichissement                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ” 1. VALIDATION                                                    â”‚
â”‚  â”œâ”€ VÃ©rification format (CSV, JSON, XML, HTML)                      â”‚
â”‚  â”œâ”€ Gestion erreurs HTTP (403, 404, 500...)                         â”‚
â”‚  â””â”€ DÃ©tection encoding (UTF-8, Latin-1, CP1252)                     â”‚
â”‚                                                                      â”‚
â”‚  ğŸ§¹ 2. NETTOYAGE                                                     â”‚
â”‚  â”œâ”€ Suppression HTML tags (BeautifulSoup)                           â”‚
â”‚  â”œâ”€ Normalisation espaces/newlines                                  â”‚
â”‚  â”œâ”€ Troncature texte (200 caractÃ¨res titre, illimitÃ© texte)         â”‚
â”‚  â””â”€ Gestion valeurs NULL (remplacement par dÃ©fauts)                 â”‚
â”‚                                                                      â”‚
â”‚  ğŸ” 3. DÃ‰DUPLICATION                                                 â”‚
â”‚  â”œâ”€ Hash SHA256 sur le texte complet                                â”‚
â”‚  â”œâ”€ Stockage dans hash_fingerprint (UNIQUE)                         â”‚
â”‚  â””â”€ INSERT ... ON CONFLICT DO NOTHING (PostgreSQL UPSERT)           â”‚
â”‚                                                                      â”‚
â”‚  ğŸ“… 4. NORMALISATION TEMPORELLE                                      â”‚
â”‚  â”œâ”€ Conversion dates â†’ datetime Python                              â”‚
â”‚  â”œâ”€ Format ISO 8601 (YYYY-MM-DD HH:MM:SS)                           â”‚
â”‚  â””â”€ Timezone UTC pour cohÃ©rence                                     â”‚
â”‚                                                                      â”‚
â”‚  ğŸŒ 5. ENRICHISSEMENT GÃ‰OGRAPHIQUE                                   â”‚
â”‚  â”œâ”€ DÃ©tection langue (fr, en, auto)                                 â”‚
â”‚  â”œâ”€ GDELT : Filtrage France (#FR# dans V2Locations)                 â”‚
â”‚  â””â”€ OWM : GÃ©olocalisation villes (Paris, Lyon, Marseille, Lille)    â”‚
â”‚                                                                      â”‚
â”‚  ğŸ“Š 6. EXTRACTION MÃ‰TADONNÃ‰ES                                        â”‚
â”‚  â”œâ”€ GDELT : TonalitÃ© Ã©motionnelle (V2Tone: -100 Ã  +100)             â”‚
â”‚  â”œâ”€ GDELT : ThÃ¨mes (PROTEST, HEALTH, ECONOMY...)                    â”‚
â”‚  â”œâ”€ RSS : CatÃ©gorie source (presse, institutions)                   â”‚
â”‚  â””â”€ Ã‰vÃ©nements : Type (attentat, grÃ¨ve, catastrophe...)             â”‚
â”‚                                                                      â”‚
â”‚  ğŸ”„ 7. AGRÃ‰GATION                                                    â”‚
â”‚  â”œâ”€ Fusion 3 flux RSS â†’ source unique "RSS Multi-Sources"           â”‚
â”‚  â”œâ”€ Fusion 6 sites Web Scraping â†’ source unique                     â”‚
â”‚  â””â”€ GDELT : 10 fichiers 15min â†’ batch agrÃ©gÃ© France                 â”‚
â”‚                                                                      â”‚
â”‚  ğŸ›¡ï¸ 8. RGPD & SÃ‰CURITÃ‰                                              â”‚
â”‚  â”œâ”€ Pseudonymisation noms propres (non implÃ©mentÃ© MVP)              â”‚
â”‚  â”œâ”€ Anonymisation emails/tÃ©lÃ©phones (non implÃ©mentÃ© MVP)            â”‚
â”‚  â””â”€ Droit Ã  l'oubli via DELETE CASCADE (schÃ©ma Merise)              â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â¬‡ï¸ DONNÃ‰ES PROPRES
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸŸ¢ LOAD (L)                                  â”‚
â”‚                    Stockage Dual Layer                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ—„ï¸ LAYER 1 : POSTGRESQL (DonnÃ©es StructurÃ©es)                      â”‚
â”‚  â”œâ”€ ModÃ¨le Merise normalisÃ© (3NF)                                   â”‚
â”‚  â”œâ”€ Tables :                                                         â”‚
â”‚  â”‚   â€¢ source (9 sources)                                            â”‚
â”‚  â”‚   â€¢ flux (12 flux collectÃ©s)                                      â”‚
â”‚  â”‚   â€¢ document (25,141 documents)                                   â”‚
â”‚  â”‚   â€¢ territoire (4 villes)                                         â”‚
â”‚  â”‚   â€¢ meteo (8 relevÃ©s)                                             â”‚
â”‚  â”œâ”€ Contraintes d'intÃ©gritÃ© :                                        â”‚
â”‚  â”‚   â€¢ PRIMARY KEY auto-incrÃ©mentÃ©es                                 â”‚
â”‚  â”‚   â€¢ FOREIGN KEY avec ON DELETE CASCADE                            â”‚
â”‚  â”‚   â€¢ UNIQUE sur hash_fingerprint (dÃ©duplication)                   â”‚
â”‚  â”œâ”€ Indexes :                                                        â”‚
â”‚  â”‚   â€¢ date_publication (requÃªtes temporelles)                       â”‚
â”‚  â”‚   â€¢ hash_fingerprint (recherche doublons)                         â”‚
â”‚  â””â”€ Backup quotidien :                                               â”‚
â”‚      â€¢ pg_dump via Docker                                            â”‚
â”‚      â€¢ Versioning datasens/versions/datasens_pg_vXXXX.sql           â”‚
â”‚                                                                      â”‚
â”‚  â˜ï¸ LAYER 2 : MINIO (DataLake Fichiers Bruts)                       â”‚
â”‚  â”œâ”€ Bucket : datasens-raw                                            â”‚
â”‚  â”œâ”€ Structure :                                                      â”‚
â”‚  â”‚   â€¢ /kaggle/*.csv (fichiers CSV originaux)                        â”‚
â”‚  â”‚   â€¢ /rss/*.json (flux RSS bruts)                                  â”‚
â”‚  â”‚   â€¢ /scraping/*.json (donnÃ©es Web Scraping)                       â”‚
â”‚  â”‚   â€¢ /gdelt/*.csv.zip (fichiers GDELT)                             â”‚
â”‚  â”‚   â€¢ /meteo/*.json (relevÃ©s OWM)                                   â”‚
â”‚  â”‚   â€¢ /historique/*.csv (Ã©vÃ©nements historiques)                    â”‚
â”‚  â”œâ”€ Manifests JSON :                                                 â”‚
â”‚  â”‚   â€¢ MÃ©tadonnÃ©es : date_collecte, source, format, taille           â”‚
â”‚  â”‚   â€¢ TraÃ§abilitÃ© : origine, transformations appliquÃ©es             â”‚
â”‚  â”‚   â€¢ Versioning : hash MD5, URI MinIO                              â”‚
â”‚  â””â”€ Retention : IllimitÃ©e (coÃ»t faible S3-compatible)               â”‚
â”‚                                                                      â”‚
â”‚  ğŸ“Š LAYER 3 : VERSIONING (Git-like Data)                             â”‚
â”‚  â”œâ”€ Snapshots PostgreSQL horodatÃ©s                                  â”‚
â”‚  â”œâ”€ Logs dans README_VERSIONNING.md                                 â”‚
â”‚  â””â”€ Format : "YYYY-MM-DD HH:MM:SS UTC | ACTION | DÃ©tails"           â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š STATISTIQUES FINALES

### DonnÃ©es CollectÃ©es
```
TOTAL : 25,141 documents
â”œâ”€ Kaggle CSV               : 24,683 (98.2%)
â”œâ”€ Web Scraping             :    265 (1.1%)
â”œâ”€ RSS Multi-Sources        :     99 (0.4%)
â”œâ”€ GDELT Big Data           :     57 (0.2%)
â”œâ”€ Ã‰vÃ©nements Historiques   :     37 (0.1%)
â””â”€ MÃ©tÃ©o (table sÃ©parÃ©e)    :      8 relevÃ©s
```

### Couverture Temporelle
```
KAGGLE        : 2009-2009 (tweets Sentiment140)
RSS           : 2025-10-28 (temps rÃ©el)
WEB SCRAPING  : 2025-10-28 (temps rÃ©el)
GDELT         : 2025-10-28 (derniÃ¨res 2h30)
MÃ‰TÃ‰O         : 2025-10-28 (temps rÃ©el)
HISTORIQUE    : 1995-2024 (30 ans d'Ã©vÃ©nements France)
```

### Types d'Ã‰vÃ©nements Historiques
```
ATTENTATS            :  8 Ã©vÃ©nements (Charlie Hebdo, Bataclan, Nice...)
GRÃˆVES               :  5 Ã©vÃ©nements (1995, 2010, 2016, 2019, 2023)
CHANGEMENTS POLITIQUES : 11 Ã©vÃ©nements (Ã©lections, gouvernements)
CATASTROPHES         :  4 Ã©vÃ©nements (Xynthia, Klaus, canicules...)
CRISES Ã‰CONOMIQUES   :  3 Ã©vÃ©nements (2008, 2011, 2020)
SANITAIRE            :  2 Ã©vÃ©nements (COVID confinements)
INTERNATIONAL        :  2 Ã©vÃ©nements (George Floyd, Guerre Ukraine)
AUTRES               :  2 Ã©vÃ©nements (Notre-Dame, Gilets Jaunes)
```

---

## ğŸ”„ CARACTÃ‰RISTIQUES ETL

### âœ… Ce qui fait de DataSens un vrai ETL

1. **EXTRACT** :
   - âœ… Multi-sources (5 types diffÃ©rents)
   - âœ… Multi-formats (CSV, JSON, XML, HTML)
   - âœ… Multi-protocoles (HTTP, API REST, Scraping)
   - âœ… Gestion erreurs et retry (tenacity)
   - âœ… Rate limiting (respect robots.txt)

2. **TRANSFORM** :
   - âœ… DÃ©duplication (SHA256 hash)
   - âœ… Nettoyage (nulls, espaces, HTML)
   - âœ… Normalisation (dates, langues)
   - âœ… Enrichissement (tonalitÃ© GDELT, gÃ©olocalisation)
   - âœ… Filtrage (France only pour GDELT)
   - âœ… AgrÃ©gation (multi-sources â†’ source unique)

3. **LOAD** :
   - âœ… Dual Layer (PostgreSQL + MinIO)
   - âœ… SchÃ©ma normalisÃ© (Merise 3NF)
   - âœ… Contraintes d'intÃ©gritÃ© (PK, FK, UNIQUE)
   - âœ… Indexes optimisÃ©s
   - âœ… Versioning (snapshots quotidiens)
   - âœ… TraÃ§abilitÃ© (manifests JSON)

### ğŸ†š Comparaison ETL vs ELT

Votre pipeline est **ETL** (pas ELT) car :
- âœ… Transformation **AVANT** chargement PostgreSQL
- âœ… DÃ©duplication appliquÃ©e **AVANT** insertion
- âœ… Nettoyage/Normalisation **AVANT** base
- âŒ Pas de "data lake d'abord, transformation aprÃ¨s"

---

## ğŸ¯ PROCHAINES Ã‰TAPES

### Court Terme (Jury E1)
- âœ… 5 types de sources collectÃ©es
- âœ… 25,141 documents en base
- âœ… Ã‰vÃ©nements historiques France (1995-2025)
- âœ… Pipeline ETL complet documentÃ©

### Moyen Terme (E2 - Analyse)
- ğŸ“Š Analyse sentiments (NLP sur textes)
- ğŸ“ˆ CorrÃ©lations Ã©vÃ©nements/sentiments
- ğŸ—ºï¸ Visualisations gÃ©ographiques
- ğŸ“‰ SÃ©ries temporelles (impact grÃ¨ves/attentats)

### Long Terme (E3 - Production)
- ğŸ”„ Automatisation collecte (GitHub Actions)
- ğŸ“Š Dashboard Grafana temps rÃ©el
- ğŸ¤– Machine Learning (prÃ©diction sentiments)
- ğŸŒ Extension internationale (Europe)

---

## ğŸ“ DÃ‰MONSTRATION JURY

**Argumentaire ETL** :

> "DataSens implÃ©mente un pipeline **ETL classique** avec :
>
> 1. **EXTRACT** : 5 types de sources (fichier plat, BDD, web scraping, API, big data)
> 2. **TRANSFORM** : DÃ©duplication SHA256, nettoyage, normalisation, enrichissement gÃ©olocalisation
> 3. **LOAD** : Architecture dual layer PostgreSQL (structurÃ©) + MinIO (DataLake)
>
> CaractÃ©ristiques :
> - âœ… 25,141 documents collectÃ©s
> - âœ… 37 Ã©vÃ©nements historiques France (1995-2025)
> - âœ… DÃ©duplication automatique (0 doublons)
> - âœ… Versioning quotidien (snapshots PostgreSQL)
> - âœ… TraÃ§abilitÃ© complÃ¨te (manifests JSON)
> - âœ… PrÃªt pour collecte automatisÃ©e quotidienne (GitHub Actions)"

---

**Votre pipeline est maintenant complet avec donnÃ©es historiques ! ğŸ‰**
