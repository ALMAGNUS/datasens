# üîß Am√©liorations v1/v2 bas√©es sur v3

**Date** : 2025-11-01  
**Objectif** : Appliquer les meilleures pratiques de v3 aux versions v1 et v2

---

## ‚úÖ Am√©liorations Prioritaires

### 1. **S√©curit√© SQL (Priorit√© 1)**

#### v2 : `notebooks/datasens_E1_v2/03_ingest_sources.ipynb`

**Ajouter dans la section "Fonctions utilitaires" (apr√®s `insert_documents`) :**

```python
# =====================================================
# FONCTIONS UTILITAIRES DE S√âCURIT√â
# =====================================================
def assert_valid_identifier(name: str) -> None:
    """
    Valide qu'un identifiant SQL (nom de table, colonne) est s√ªr.
    L√®ve une ValueError si l'identifiant contient des caract√®res non autoris√©s.
    """
    if not isinstance(name, str):
        raise ValueError("L'identifiant doit √™tre une cha√Æne de caract√®res.")
    # Autorise lettres, chiffres, underscores, et points (pour sch√©mas.tables)
    if not name.replace('_', '').replace('.', '').isalnum():
        raise ValueError(f"Identifiant SQL invalide : {name}. Seuls les caract√®res alphanum√©riques, underscores et points sont autoris√©s.")

def load_whitelist_tables(conn, schema: str = 'public') -> set[str]:
    """
    Charge une liste blanche des noms de tables valides depuis information_schema.
    Retourne un set des noms de tables pour validation.
    """
    try:
        result = conn.execute(text(f"""
            SELECT table_name FROM information_schema.tables
            WHERE table_schema = :schema_name
        """), {"schema_name": schema}).fetchall()
        return {row[0] for row in result}
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du chargement de la whitelist des tables: {e}")
        return set()  # Retourne un set vide en cas d'erreur

print("‚úÖ Fonctions de s√©curit√© (assert_valid_identifier, load_whitelist_tables) charg√©es.")
```

**R√©f√©rence** : Voir `notebooks/datasens_E1_v3/03_ingest_sources.ipynb` cellule 4 (lignes 437-464)

#### v2 : `notebooks/datasens_E1_v2/02_schema_create.ipynb`

**Ajouter apr√®s la cr√©ation de `engine` :**

```python
# =====================================================
# FONCTIONS UTILITAIRES DE S√âCURIT√â
# =====================================================
def assert_valid_identifier(name: str) -> None:
    """
    Valide qu'un identifiant SQL (nom de table, colonne) est s√ªr.
    L√®ve une ValueError si l'identifiant contient des caract√®res non autoris√©s.
    """
    if not isinstance(name, str):
        raise ValueError("L'identifiant doit √™tre une cha√Æne de caract√®res.")
    # Autorise lettres, chiffres, underscores, et points (pour sch√©mas.tables)
    if not name.replace('_', '').replace('.', '').isalnum():
        raise ValueError(f"Identifiant SQL invalide : {name}. Seuls les caract√®res alphanum√©riques, underscores et points sont autoris√©s.")

print("‚úÖ Fonctions de s√©curit√© charg√©es")
```

**Si des DROP TABLE sont pr√©sents**, valider avant utilisation :
```python
for table in drop_order:
    assert_valid_identifier(table)  # Protection anti-injection SQL
    conn.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))
```

#### v1 : `notebooks/datasens_E1_v1/02_schema_create.ipynb`

**Ajouter apr√®s la connexion SQLite** :

```python
# =====================================================
# FONCTIONS UTILITAIRES DE S√âCURIT√â
# =====================================================
def assert_valid_identifier(name: str) -> None:
    """
    Valide qu'un identifiant SQL (nom de table, colonne) est s√ªr.
    Bien que SQLite soit moins sensible, la validation est une bonne pratique.
    """
    if not isinstance(name, str):
        raise ValueError("L'identifiant doit √™tre une cha√Æne de caract√®res.")
    if not name.replace('_', '').replace('.', '').isalnum():
        raise ValueError(f"Identifiant SQL invalide : {name}")

print("‚úÖ Fonctions de s√©curit√© charg√©es")
```

**Valider les noms de tables avant cr√©ation** :
```python
for name, sql in TABLES_SQL.items():
    assert_valid_identifier(name)  # Validation avant cr√©ation
    cur.execute(sql)
    tables_created.append(name)
```

---

### 2. **Visualisations Am√©lior√©es (Priorit√© 2)**

#### v1 : `notebooks/datasens_E1_v1/03_ingest_sources.ipynb`

**Ajouter des tables pandas apr√®s chaque collecte** :

```python
# Apr√®s insertion de documents
with engine.connect() as conn:
    df_docs = pd.read_sql_query("""
        SELECT d.id_doc, d.titre, d.langue, d.date_publication
        FROM document d
        JOIN flux f ON d.id_flux = f.id_flux
        JOIN source s ON f.id_source = s.id_source
        WHERE s.nom = :nom_source
        ORDER BY d.id_doc DESC
        LIMIT 10
    """, conn, params={"nom_source": "Nom Source"})
    
    print("\nüìã Table 'document' - Documents ins√©r√©s (aper√ßu 10 premiers) :")
    display(df_docs)  # Afficher le DataFrame
```

**R√©f√©rence** : Voir `notebooks/datasens_E1_v3/03_ingest_sources.ipynb` pour exemples complets

#### v1/v2 : `04_crud_tests.ipynb`

**Am√©liorer les visualisations de qualit√©** :

```python
# Apr√®s v√©rification des doublons
if nb_doublons > 0:
    plt.figure(figsize=(10, 6))
    categories = ['Documents uniques', 'Doublons d√©tect√©s']
    values = [nb_docs_uniques, nb_doublons]
    colors = ['#4ECDC4', '#FECA57']
    bars = plt.bar(categories, values, color=colors)
    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values) * 0.02,
                f"{int(value):,}", ha='center', va='bottom', fontweight='bold')
    plt.title("üßπ D√©tection des doublons (SHA256)", fontsize=12, fontweight='bold')
    plt.ylabel("Nombre de documents", fontsize=11)
    plt.grid(axis="y", linestyle="--", alpha=0.3)
    plt.tight_layout()
    plt.show()
```

---

### 3. **Documentation et Coh√©rence (Priorit√© 3)**

#### V√©rifier `README_VERSIONNING.md`

- ‚úÖ V√©rifier que les entr√©es sont coh√©rentes entre v1/v2/v3
- ‚úÖ Format uniforme : `YYYY-MM-DD HH:MM:SS | Action | D√©tail`

#### Commentaires inline

- ‚úÖ Ajouter des commentaires expliquant les choix techniques
- ‚úÖ R√©f√©rencer `docs/GUIDE_TECHNIQUE_E1.md` pour plus de d√©tails

---

## üìã Checklist d'Application

### v2 (PostgreSQL)
- [ ] Ajouter fonctions s√©curit√© dans `03_ingest_sources.ipynb`
- [ ] Ajouter fonctions s√©curit√© dans `02_schema_create.ipynb` (si DROP TABLE)
- [ ] V√©rifier visualisations dans `03_ingest_sources.ipynb` (d√©j√† bon, peut am√©liorer)
- [ ] Am√©liorer visualisations dans `04_crud_tests.ipynb`
- [ ] V√©rifier coh√©rence `README_VERSIONNING.md`

### v1 (SQLite)
- [ ] Ajouter fonctions s√©curit√© dans `02_schema_create.ipynb`
- [ ] Ajouter tables pandas dans `03_ingest_sources.ipynb` (apr√®s chaque collecte)
- [ ] Am√©liorer visualisations dans `04_crud_tests.ipynb`
- [ ] V√©rifier coh√©rence `README_VERSIONNING.md`

---

## üîó R√©f√©rences

- **Code source v3** : `notebooks/datasens_E1_v3/03_ingest_sources.ipynb` (cellule 4)
- **Guide technique** : `docs/GUIDE_TECHNIQUE_E1.md`
- **Documentation s√©curit√©** : `docs/SECURITY.md`
- **Audit s√©curit√©** : `docs/AUDIT_SECURITE_DOCS.md`

---

## üí° Notes

1. **Format JSON des notebooks** : L'√©dition automatique via `edit_notebook` peut √©chouer si le formatage diff√®re. En cas d'√©chec, ajouter manuellement les fonctions en s'inspirant de v3.

2. **Compatibilit√©** : Les fonctions de s√©curit√© sont identiques entre v1 (SQLite), v2 (PostgreSQL) et v3 (PostgreSQL), seule la validation des sch√©mas diff√®re.

3. **Tests** : Apr√®s ajout des fonctions, tester que les notebooks s'ex√©cutent sans erreur.

---

**Derni√®re mise √† jour** : 2025-11-01

